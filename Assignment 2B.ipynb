{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "486233ec36e89e593aaf58fa015ac03d",
     "grade": false,
     "grade_id": "cell-8662c8f983b4ba91",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# ELEC 400M / EECE 571M Assignment 2: Neural networks\n",
    "(This assignment is a modified version of an assignment used in ECE 421 at the University of Toronto and kindly made available to us by the instructor.)\n",
    "\n",
    "In this assignment, you will implement a neural network model for multi-class classification. The purpose is to demonstrate an understanding of the basic elements including training of neural network models. Hence, your implementation will be from scratch only using functions from the NumPy library.\n",
    "\n",
    "The neural network you will be implementing has the following structure:\n",
    "* 3 layers: 1 input layer, 1 hidden layer with ReLU activation and 1 output layer with Softmax function ô´£ \n",
    "* The loss function is the Cross Entropy Loss.\n",
    "* Training will be done using Gradient Descent with Momentum. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5c4b1f777717d67e6a7011443bd46bbd",
     "grade": false,
     "grade_id": "cell-814d7b3a3145c5e2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Data Set\n",
    "We again consider the dataset of images of letters in different fonts contained in file notMNIST.npz (which btw is from http://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html). This time we consider 10 letters (\"A\" to \"J\"), which are all the letters contained in this data set, and we want to classfiy the images according to the letter they display. The figure below shows 30 randomly selected image samples for the letters.\n",
    "\n",
    "![](sample_images_2.eps)\n",
    "\n",
    "\n",
    "You will apply the function `loadData` given below to load the data set, which includes 18720 images and their labels, which we also refer to as targets. This script organizes the data set into training, validation and test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4f49f3888f70a91913e98c176bf8c372",
     "grade": false,
     "grade_id": "cell-356f4913c5215d34",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3f63167b3b48ef91442fff9e52129cd2",
     "grade": false,
     "grade_id": "cell-378d369615cf7a6a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def loadData():\n",
    "    with np.load('notMNIST.npz') as data:\n",
    "        Data, Target = data['images'], data['labels']\n",
    "        np.random.seed(521)\n",
    "        randIndx = np.arange(len(Data))\n",
    "        np.random.shuffle(randIndx)\n",
    "        Data = Data[randIndx]/255.0\n",
    "        Target = Target[randIndx]\n",
    "        trainData, trainTarget = Data[:15000], Target[:15000]\n",
    "        validData, validTarget = Data[15000:16000], Target[15000:16000]\n",
    "        testData, testTarget = Data[16000:], Target[16000:]\n",
    "       \n",
    "    return trainData, validData, testData, trainTarget, validTarget, testTarget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6ed0feb46eaa25e44f926e48b595f0ea",
     "grade": false,
     "grade_id": "cell-596c5760ca09c8db",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Data preprocessing [5 points]\n",
    "\n",
    "Input data: The classification should be based on the $d=28\\times 28=784$ intensity values in an image (as for Assignment 1).\n",
    "\n",
    "Output data: Since you will be performing multi-class classification, the labels will be converted into a one-hot encoding format. \n",
    "\n",
    "Please first briefly explain the meaning of one-hot encoding and why it is used (instead of keeping the numerical label values provided by the data set). State an example for a one-hot encoded label for the data set considered in this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "636512a6eac1a6c967252bdabf4048f3",
     "grade": true,
     "grade_id": "cell-0faa91c6c088b233",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "Answer:\n",
    "\n",
    "A one-hot encoding is a representation of target labels as binary vectors.\n",
    "\n",
    "The labels must first be mapped to integer values. In this case, the letters are mapped to the sequence they are indexed in the alphabet. A = 0, B = 1, C = 2 ... J = 9.\n",
    "\n",
    "Each integer value is represented as a binary vector that is all zero values except the index of the integer, which is marked with a 1. The 1 is the \"hot\" value.\n",
    "\n",
    "One-hot is used in machine learning so that the machine can work with ordinal or categorical data. \n",
    "\n",
    "One example for this data set: A: Target = 0; One-hot = [1,0,0,0,0,0,0,0,0,0];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "42bbfcec6879baf85a7898fe88c21da2",
     "grade": false,
     "grade_id": "cell-846dfc32b30e8ce1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now implement a function that one-hot encodes the labels (or targets) for the training, validation and test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b4c0e881d76334eebce0a44913ba46ae",
     "grade": true,
     "grade_id": "cell-924299df80c3f9aa",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "def convertOneHot(trainTarget, validTarget, testTarget):\n",
    "    newTrainTarget = np.zeros((trainTarget.shape[0], 10))\n",
    "    newValidTarget = np.zeros((validTarget.shape[0], 10))\n",
    "    newTestTarget = np.zeros((testTarget.shape[0], 10))\n",
    "    \n",
    "    #loop through train, test, and valid targets\n",
    "    for item in range(0, trainTarget.shape[0]):\n",
    "        newTrainTarget[item][trainTarget[item]] = 1\n",
    "    for item in range(0, validTarget.shape[0]):\n",
    "        newValidTarget[item][validTarget[item]] = 1\n",
    "    for item in range(0, testTarget.shape[0]):\n",
    "        newTestTarget[item][testTarget[item]] = 1\n",
    "    return newTrainTarget, newValidTarget, newTestTarget\n",
    "\n",
    "#assign targets as one-hot\n",
    "trainData, validData, testData, trainTarget, validTarget, testTarget = loadData()\n",
    "TrainTarget, ValidTarget, testTarget = convertOneHot(trainTarget, validTarget, testTarget)\n",
    "\n",
    "\n",
    "#confirm shape\n",
    "print(trainData.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1536f677686b7036d2c66d620209e82c",
     "grade": false,
     "grade_id": "cell-7d791d9661633428",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Structure of the network [2 points]\n",
    "\n",
    "Sketch the structure of the network to classify the letters from the data set. Identify the dimensions of the network layers, include the activation functions, and do not forget the bias nodes. (You may sketch this by hand and upload a photo of your sketch.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9b18743021e27e8876becc2b4db99451",
     "grade": true,
     "grade_id": "cell-f90c510b0f8ee6ec",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "Answer:\n",
    "\n",
    "Please find the diagram attached to this repository if not being displayed here below. I've been having problems uploading pictures into the JupyterHub repository. All the diagrams in this assignment have also been uploaded to Google Drive, which can be found here:\n",
    "\n",
    "https://drive.google.com/open?id=1hVfllsCnZKxbo9pf_uatfMKBwXMyhV4W\n",
    "\n",
    "Network Diagram for 1000 Hidden Nodes:\n",
    "\n",
    "Please refer to the diagram in the submission repository if graph is not displaying here.\n",
    "\n",
    "![network_diagram](\"network_diagram.png![network_diagram.png]\")\n",
    "(network_diagram.png)\n",
    "\n",
    "If it isn't in the repo, please see the diagram I uploaded in the Google Drive link.\n",
    "\n",
    "Diagram: https://drive.google.com/open?id=1R-ayCAbJ5RmQTDYc-amQVsDfgAvWCOdS\n",
    "\n",
    "Google Drive for Diagrams: https://drive.google.com/open?id=1hVfllsCnZKxbo9pf_uatfMKBwXMyhV4W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9ac40fb48e772f9387b11d5675789736",
     "grade": false,
     "grade_id": "cell-59f9a2eba4fddf51",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Helper functions [6 points]\n",
    "To give the implementation of the network some structure, you will first implement five helper functions. \n",
    "\n",
    "Use Numpy arrays for your implementations, and organize data in vectors and matrices as appropriate for compact programming.\n",
    "\n",
    "1. `relu`: This function will accept one argument and return the ReLU activation: \n",
    "    $$\\mathrm{ReLU}(x)=\\max(0,x).$$\n",
    "    \n",
    "2. `softmax`: This function will accept one argument and return the softmax activations:\n",
    "    $$ [\\sigma(\\mathbf{z})]_j = \\frac{\\mathrm{e}^{z_j}}{\\sum\\limits_{k=1}^K\\mathrm{e}^{z_k}},$$ $j=1,2,\\ldots, K$,  for $K$ classes.\n",
    "\n",
    "3. `computeLayer`: This function will accept two arguments, the input vector $\\mathbf{x}$ for a layer and the weight matrix $\\mathbf{W}$, and return a vector $\\mathbf{s}=\\mathbf{W}^T\\mathbf{x}$, i.e., the input to the activation function of the layer (the notation for variables from the textbook is used). Don't forget to account for the bias term (which can be included in an augmented vector $\\mathbf{x}$ as in the textbook).\n",
    "\n",
    "4. `CE`: This function will accept two arguments, the one-hot encoded labels $\\mathbf{y}_n$ and the inputs $\\mathbf{s}_n$ to the softmax function, $n=1,2,\\ldots N$. It will return the cross entropy loss\n",
    "$$\\mathrm{E}_{\\mathrm{in}}=-\\frac{1}{N}\\sum\\limits_{n=1}^N\\sum\\limits_{k=1}^Ky_{n,k}\\log([\\sigma(\\mathbf{s}_n)]_k)$$\n",
    "\n",
    "5. `gradCE`: This function will accept two arguments, the labels and the inputs to the softmax function. It will return the gradient of the cross entropy loss with respect to the inputs (i.e., it returns the sensivity vector for the output layer as introduced in the textbook). \n",
    "\n",
    "First state the analytical expression for the gradient used in `gradCE` and then implement the five helper functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "38319a28929fddb9aeec63a7618aa2c0",
     "grade": true,
     "grade_id": "cell-eb49a8ec15080221",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "Answer:\n",
    "\n",
    "The following is the analytical expression for the average gradient used in gradCE:\n",
    "\n",
    "$$\\frac{\\partial (CE)}{\\partial \\mathbf{\\underline x}} = -\\frac{1}{N}\\sum\\limits_{n \\epsilon N}\\sum\\limits_{k \\epsilon K} (t_{k}^{(n)} \\cdot \\frac{1}{x_{k}^{(n)}})$$\n",
    "\n",
    "In this expression, the term $\\underline t$ is the target and the term $\\underline x$ is the softmax of the predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bd4f5743110984029942f592638733ce",
     "grade": true,
     "grade_id": "cell-d0044385d52cffcf",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(x, 0)\n",
    "\n",
    "def grad_relu(x):\n",
    "    return (1 * (x > 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "43bb7356ae073f92680f32f0fe49ea76",
     "grade": true,
     "grade_id": "cell-ae7dedf13bb4066f",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def softmax(x):    \n",
    "    return np.exp(x)/(np.sum(np.exp(x), axis = 1, keepdims = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2d5b2370f78ee83853fb13f1308e5329",
     "grade": true,
     "grade_id": "cell-8df181fa3a88e489",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def computeLayer(x,W):\n",
    "    return np.matmul(x, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "119836341edec3cd046d15b6359f3aa7",
     "grade": true,
     "grade_id": "cell-9b34ab1477a6a5da",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def CE(target, prediction):\n",
    "    return -1 * (np.mean(np.sum(target * np.log(softmax(prediction)), axis = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4067e14fdfd9fe7938309d994ad3436b",
     "grade": true,
     "grade_id": "cell-7da4a6821dc7e0ac",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def gradCE(target, prediction):\n",
    "    return prediction - target\n",
    "\n",
    "def gradCE_softmax(target, prediction):\n",
    "    return -1 * ((target - softmax(prediction)) / len(target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7e3c25a1bd38eb37acace72f3c0a78c2",
     "grade": false,
     "grade_id": "cell-37acd78048c1b219",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Backpropagation [2 points]\n",
    "\n",
    "The training of the network will be done via backpropagation. First derive the following gradients:\n",
    "1. $\\frac{\\partial E_{\\mathrm{in}}}{\\partial \\mathbf{W}^{\\mathrm{o}}}$, where $\\mathbf{W}^{\\mathrm{o}}$ is the weight matrix of the output layer.\n",
    "\n",
    "2. $\\frac{\\partial E_{\\mathrm{in}}}{\\partial \\mathbf{W}^{\\mathrm{h}}}$, where $\\mathbf{W}^{\\mathrm{h}}$ is the weight matrix of the hidden layer.\n",
    "\n",
    "Write the results using the steps and notation used in the textbook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6f519d4da4c6b663b42fa12c0082ee3c",
     "grade": true,
     "grade_id": "cell-ac7e24b5b1eee343",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "Answer:\n",
    "\n",
    "#1. \n",
    "\n",
    "Result after derivation: \n",
    "\n",
    "$$\\frac{\\partial E_{\\mathrm{in}}}{\\partial \\mathbf{W}^{\\mathrm{o}}} = -\\frac{1}{N}\\cdot\\underline{x}^h\\cdot(\\underline{t}^L - \\underline{x}^L)^T$$\n",
    "\n",
    "$$\\frac{\\partial E_{\\mathrm{in}}}{\\partial \\mathbf{b_o}} = -\\frac{1}{N}\\cdot\\underline{1}^h\\cdot(\\underline{t}^L - \\underline{x}^L)^T$$\n",
    "\n",
    "#2. \n",
    "\n",
    "Result after derivation:\n",
    "\n",
    "$$\\frac{\\partial E_{\\mathrm{in}}}{\\partial \\mathbf{W}^{\\mathrm{h}}} = \\underline{x}^o \\cdot ((W_o \\cdot (\\delta^L)^T) \\bigotimes\\theta^\\prime (\\underline{s}^h))^T$$\n",
    "\n",
    "$$\\frac{\\partial E_{\\mathrm{in}}}{\\partial \\mathbf{W}^{\\mathrm{h}}} = \\underline{1}^o \\cdot ((W_o \\cdot (\\delta^L)^T) \\bigotimes\\theta^\\prime (\\underline{s}^h))^T$$\n",
    "\n",
    "where $\\theta^\\prime ({s_i}^h$): \n",
    "\n",
    "= 1 if (${s_i}^h$ > 0); \n",
    "\n",
    "= 0 else\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7e11084bb8f343b86fd223436e42eed9",
     "grade": false,
     "grade_id": "cell-ca564be205805d5c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Network training [8 points]\n",
    "\n",
    "Implement a function to train the network. The function uses the helper functions from above. The optimization technique for backpropagation will be Gradient Descent with Momentum:\n",
    "$$\\mathbf{V}(t)=\\alpha \\mathbf{V}(t-1)-\\eta\\frac{\\partial E_{\\mathrm{in}}}{\\partial \\mathbf{W}(t)}$$\n",
    "and \n",
    "$$\\mathbf{W}(t+1)=\\mathbf{W}(t)+\\mathbf{V}(t),$$\n",
    "where $\\eta$ is the learning rate and $\\alpha$ is the momentum hyperparameter.\n",
    "\n",
    "The training function accepts the following inputs:  training data (features), training labels, weight matrix of the hidden layer, weight matrix of the output layer, number of iterations, parameters $\\eta$ and $\\alpha$, validation data, validation labels, test data, test labels. The validation and test inputs are initialized to \"None\" and need not be passed on. You will also need to initialize the velocity matrices $\\mathbf{V}$ for both hidden layer and output layer weights to small values, e.g. $10^{-5}%$.\n",
    "\n",
    "The function outputs the updated weight matrices, the losses and classification accuracies for the training data, and if validation and test inputs were provided, then it also outputs the classification accuracies for the validation and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "58dcb68f57a14d8a1375ea4f625ea7b6",
     "grade": true,
     "grade_id": "cell-f1fd1f8de32bae42",
     "locked": false,
     "points": 8,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def forward_propagate(data_input, w_hid, w_out):\n",
    "    \n",
    "    #propagate through relu and softmax\n",
    "    z1 = computeLayer(data_input, w_hid)\n",
    "    \n",
    "    a1 = relu(z1)\n",
    "    a1 = np.insert(a1, 0, np.ones(a1.shape[0]), axis = 1)\n",
    "    \n",
    "    z2 = computeLayer(a1, w_out)\n",
    "    a2 = softmax(z2) \n",
    "\n",
    "    return z1, a1, z2, a2\n",
    "\n",
    "def back_propagate(data_input, target, z1, a1, a2, w_out):\n",
    "    \n",
    "    #take softmax gradient\n",
    "    softmax_grad = gradCE(target, a2)\n",
    "    \n",
    "    #output gradient\n",
    "    grad_w_out = np.matmul(a1.T, softmax_grad)\n",
    "\n",
    "    #hidden gradient\n",
    "    grad_hid = np.multiply(grad_relu(z1), np.matmul(softmax_grad, w_out[1:].T))\n",
    "    \n",
    "    #hidden gradient\n",
    "    grad_w_hid = np.matmul(data_input.T, grad_hid)\n",
    "    \n",
    "    return grad_w_out, grad_w_hid\n",
    "\n",
    "def network_training(data_in, target_in, w_hid, w_out, iterations, learning_rate, alpha, v_out, v_hid):\n",
    "    \n",
    "    #initialize lists to track accuracy and loss\n",
    "    accuracy_train, accuracy_valid, accuracy_test = [], [], []\n",
    "    loss_train, loss_valid, loss_test = [], [], []\n",
    "    \n",
    "    print(\"###### TRAINING BEGINNING #######\")\n",
    "    print(\"     \")\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        \n",
    "        ###\n",
    "        #forward prop\n",
    "        z1, a1, z2, a2 = forward_propagate(data_in[0], w_hid, w_out)\n",
    "        \n",
    "        #train accuracy\n",
    "        accuracytrain = np.mean(np.argmax(a2, axis = 1) == np.argmax(target_in[0], axis = 1))\n",
    "        accuracy_train.append(accuracytrain)\n",
    "        \n",
    "        #train loss\n",
    "        losstrain = CE(target_in[0], a2)\n",
    "        loss_train.append(losstrain)\n",
    "        dw_out, dw_hid = back_propagate(data_in[0], target_in[0], z1, a1, a2, w_out)\n",
    "        ###\n",
    "        \n",
    "        ###\n",
    "        #momentum equations\n",
    "        v_hid = (v_hid * alpha) - (learning_rate * dw_hid)\n",
    "        w_hid = (w_hid + v_hid)\n",
    "        \n",
    "        v_out = (v_out * alpha) - (learning_rate * dw_out)\n",
    "        w_out = (w_out + v_out)\n",
    "        ###\n",
    "        \n",
    "        #forward prop for validation and test data\n",
    "        \n",
    "        ###\n",
    "        #forward prop validation\n",
    "        z1, a1, z2, a2 = forward_propagate(data_in[1], w_hid, w_out)\n",
    "        #validation accuracy\n",
    "        accuracyvalid = np.mean(np.argmax(a2, axis = 1) == np.argmax(target_in[1], axis = 1))\n",
    "        accuracy_valid.append(accuracyvalid)\n",
    "        #validation loss\n",
    "        lossvalid = CE(target_in[1], a2)\n",
    "        loss_valid.append(lossvalid)\n",
    "        \n",
    "        ###\n",
    "        #forward prop test\n",
    "        z1, a1, z2, a2 = forward_propagate(data_in[2], w_hid, w_out)\n",
    "        #test accuracy\n",
    "        accuracytest = np.mean(np.argmax(a2, axis = 1) == np.argmax(target_in[2], axis = 1))\n",
    "        accuracy_test.append(accuracytest)\n",
    "        #test loss\n",
    "        losstest = CE(target_in[2], a2)\n",
    "        loss_test.append(loss_test)\n",
    "        ###\n",
    "        \n",
    "        ###\n",
    "        #print data and updates\n",
    "        print('Epoch: {:.0f} of {:.0f} || Train Accuracy: {:.4f} % || Validation Accuracy: {:.4f} % || Test Accuracy: {:.4f} %'.format(i+1, iterations, accuracytrain*100, accuracyvalid*100, accuracytest*100))\n",
    "        print('Train Loss: {:.4f} || Validation Loss: {:.4f} || Test Loss: {:.4f}'.format(losstrain, lossvalid, losstest))\n",
    "        print(\"     \")\n",
    "        ###\n",
    "        \n",
    "    print(\"###### TRAINING COMPLETED #######\") \n",
    "    \n",
    "    return accuracy_train, accuracy_valid, accuracy_test, dw_out, dw_hid, loss_train, loss_valid, loss_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e5aa8cd9678c46a432c9946a317bbdb3",
     "grade": false,
     "grade_id": "cell-8f062bae545cfea3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Network test [4 points]\n",
    "\n",
    "Write a script that constructs the neural network.\n",
    "\n",
    "Initialize your weight matrices by drawing the elements i.i.d. at random from a zero-mean Gaussian distribution with variance equal to $$\\sigma_w^2=\\frac{2}{\\mbox{# of input nodes + # of output nodes}}$$ (Xavier normalization http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf) \n",
    "\n",
    "Build a network with 1000 hidden units and train it for 200 epochs using $\\alpha=0.9$ and $\\eta=10^{-5}$. Plot the training, validation and testing accuracy curves. State the training, validation and testing accuracies after training. Show the plot and the accuracies in the next markdown cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "46b789c7c5c35a54f544d8157558b0cf",
     "grade": true,
     "grade_id": "cell-69365489da7f9c07",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### TRAINING BEGINNING #######\n",
      "     \n",
      "Epoch: 0 of 200 || Train Accuracy: 12.5600 % || Validation Accuracy: 28.8000 % || Test Accuracy: 29.9192 %\n",
      "Train Loss: 2.2999 || Validation Loss: 2.2412 || Test Loss: 2.2360\n",
      "     \n",
      "Epoch: 1 of 200 || Train Accuracy: 29.1867 % || Validation Accuracy: 46.5000 % || Test Accuracy: 46.8429 %\n",
      "Train Loss: 2.2390 || Validation Loss: 2.0917 || Test Loss: 2.0878\n",
      "     \n",
      "Epoch: 2 of 200 || Train Accuracy: 48.1800 % || Validation Accuracy: 55.0000 % || Test Accuracy: 55.1395 %\n",
      "Train Loss: 2.0820 || Validation Loss: 1.9834 || Test Loss: 1.9792\n",
      "     \n",
      "Epoch: 3 of 200 || Train Accuracy: 54.1933 % || Validation Accuracy: 60.3000 % || Test Accuracy: 62.0411 %\n",
      "Train Loss: 1.9814 || Validation Loss: 1.8892 || Test Loss: 1.8788\n",
      "     \n",
      "Epoch: 4 of 200 || Train Accuracy: 60.4533 % || Validation Accuracy: 75.1000 % || Test Accuracy: 76.4317 %\n",
      "Train Loss: 1.8881 || Validation Loss: 1.7921 || Test Loss: 1.7872\n",
      "     \n",
      "Epoch: 5 of 200 || Train Accuracy: 75.5067 % || Validation Accuracy: 77.3000 % || Test Accuracy: 78.3040 %\n",
      "Train Loss: 1.7888 || Validation Loss: 1.7761 || Test Loss: 1.7680\n",
      "     \n",
      "Epoch: 6 of 200 || Train Accuracy: 78.1000 % || Validation Accuracy: 74.7000 % || Test Accuracy: 75.9545 %\n",
      "Train Loss: 1.7668 || Validation Loss: 1.7863 || Test Loss: 1.7720\n",
      "     \n",
      "Epoch: 7 of 200 || Train Accuracy: 74.8867 % || Validation Accuracy: 84.2000 % || Test Accuracy: 85.0954 %\n",
      "Train Loss: 1.7771 || Validation Loss: 1.7051 || Test Loss: 1.6976\n",
      "     \n",
      "Epoch: 8 of 200 || Train Accuracy: 84.4533 % || Validation Accuracy: 85.4000 % || Test Accuracy: 85.4626 %\n",
      "Train Loss: 1.7010 || Validation Loss: 1.6958 || Test Loss: 1.6948\n",
      "     \n",
      "Epoch: 9 of 200 || Train Accuracy: 84.6933 % || Validation Accuracy: 83.6000 % || Test Accuracy: 83.0764 %\n",
      "Train Loss: 1.6949 || Validation Loss: 1.6982 || Test Loss: 1.6996\n",
      "     \n",
      "Epoch: 10 of 200 || Train Accuracy: 82.8800 % || Validation Accuracy: 84.8000 % || Test Accuracy: 84.2144 %\n",
      "Train Loss: 1.6996 || Validation Loss: 1.6758 || Test Loss: 1.6777\n",
      "     \n",
      "Epoch: 11 of 200 || Train Accuracy: 84.4067 % || Validation Accuracy: 86.7000 % || Test Accuracy: 87.1145 %\n",
      "Train Loss: 1.6772 || Validation Loss: 1.6504 || Test Loss: 1.6493\n",
      "     \n",
      "Epoch: 12 of 200 || Train Accuracy: 86.3333 % || Validation Accuracy: 86.9000 % || Test Accuracy: 87.3348 %\n",
      "Train Loss: 1.6496 || Validation Loss: 1.6480 || Test Loss: 1.6437\n",
      "     \n",
      "Epoch: 13 of 200 || Train Accuracy: 86.8133 % || Validation Accuracy: 85.9000 % || Test Accuracy: 85.8297 %\n",
      "Train Loss: 1.6443 || Validation Loss: 1.6581 || Test Loss: 1.6511\n",
      "     \n",
      "Epoch: 14 of 200 || Train Accuracy: 85.6600 % || Validation Accuracy: 86.2000 % || Test Accuracy: 86.6740 %\n",
      "Train Loss: 1.6524 || Validation Loss: 1.6462 || Test Loss: 1.6406\n",
      "     \n",
      "Epoch: 15 of 200 || Train Accuracy: 86.6133 % || Validation Accuracy: 86.7000 % || Test Accuracy: 86.8943 %\n",
      "Train Loss: 1.6412 || Validation Loss: 1.6355 || Test Loss: 1.6317\n",
      "     \n",
      "Epoch: 16 of 200 || Train Accuracy: 86.8200 % || Validation Accuracy: 87.2000 % || Test Accuracy: 87.7386 %\n",
      "Train Loss: 1.6312 || Validation Loss: 1.6264 || Test Loss: 1.6241\n",
      "     \n",
      "Epoch: 17 of 200 || Train Accuracy: 87.5333 % || Validation Accuracy: 87.8000 % || Test Accuracy: 88.4361 %\n",
      "Train Loss: 1.6229 || Validation Loss: 1.6216 || Test Loss: 1.6211\n",
      "     \n",
      "Epoch: 18 of 200 || Train Accuracy: 88.2467 % || Validation Accuracy: 88.4000 % || Test Accuracy: 88.6564 %\n",
      "Train Loss: 1.6196 || Validation Loss: 1.6242 || Test Loss: 1.6243\n",
      "     \n",
      "Epoch: 19 of 200 || Train Accuracy: 88.5533 % || Validation Accuracy: 88.8000 % || Test Accuracy: 88.4361 %\n",
      "Train Loss: 1.6234 || Validation Loss: 1.6257 || Test Loss: 1.6262\n",
      "     \n",
      "Epoch: 20 of 200 || Train Accuracy: 88.3267 % || Validation Accuracy: 88.3000 % || Test Accuracy: 88.5463 %\n",
      "Train Loss: 1.6255 || Validation Loss: 1.6209 || Test Loss: 1.6215\n",
      "     \n",
      "Epoch: 21 of 200 || Train Accuracy: 88.5067 % || Validation Accuracy: 88.1000 % || Test Accuracy: 88.7298 %\n",
      "Train Loss: 1.6199 || Validation Loss: 1.6148 || Test Loss: 1.6148\n",
      "     \n",
      "Epoch: 22 of 200 || Train Accuracy: 88.8933 % || Validation Accuracy: 87.9000 % || Test Accuracy: 88.9134 %\n",
      "Train Loss: 1.6121 || Validation Loss: 1.6117 || Test Loss: 1.6111\n",
      "     \n",
      "Epoch: 23 of 200 || Train Accuracy: 88.9467 % || Validation Accuracy: 88.8000 % || Test Accuracy: 88.8032 %\n",
      "Train Loss: 1.6080 || Validation Loss: 1.6098 || Test Loss: 1.6090\n",
      "     \n",
      "Epoch: 24 of 200 || Train Accuracy: 89.1933 % || Validation Accuracy: 89.2000 % || Test Accuracy: 89.2070 %\n",
      "Train Loss: 1.6064 || Validation Loss: 1.6109 || Test Loss: 1.6098\n",
      "     \n",
      "Epoch: 25 of 200 || Train Accuracy: 89.3667 % || Validation Accuracy: 88.8000 % || Test Accuracy: 89.3172 %\n",
      "Train Loss: 1.6080 || Validation Loss: 1.6136 || Test Loss: 1.6119\n",
      "     \n",
      "Epoch: 26 of 200 || Train Accuracy: 89.4667 % || Validation Accuracy: 88.7000 % || Test Accuracy: 89.2070 %\n",
      "Train Loss: 1.6106 || Validation Loss: 1.6110 || Test Loss: 1.6094\n",
      "     \n",
      "Epoch: 27 of 200 || Train Accuracy: 89.5933 % || Validation Accuracy: 88.9000 % || Test Accuracy: 89.3539 %\n",
      "Train Loss: 1.6080 || Validation Loss: 1.6066 || Test Loss: 1.6055\n",
      "     \n",
      "Epoch: 28 of 200 || Train Accuracy: 89.5800 % || Validation Accuracy: 89.3000 % || Test Accuracy: 89.8311 %\n",
      "Train Loss: 1.6035 || Validation Loss: 1.6038 || Test Loss: 1.6032\n",
      "     \n",
      "Epoch: 29 of 200 || Train Accuracy: 89.8267 % || Validation Accuracy: 89.6000 % || Test Accuracy: 89.8678 %\n",
      "Train Loss: 1.6003 || Validation Loss: 1.6020 || Test Loss: 1.6021\n",
      "     \n",
      "Epoch: 30 of 200 || Train Accuracy: 90.0667 % || Validation Accuracy: 89.5000 % || Test Accuracy: 89.7944 %\n",
      "Train Loss: 1.5983 || Validation Loss: 1.6013 || Test Loss: 1.6021\n",
      "     \n",
      "Epoch: 31 of 200 || Train Accuracy: 90.2933 % || Validation Accuracy: 89.8000 % || Test Accuracy: 89.7944 %\n",
      "Train Loss: 1.5978 || Validation Loss: 1.6012 || Test Loss: 1.6026\n",
      "     \n",
      "Epoch: 32 of 200 || Train Accuracy: 90.5200 % || Validation Accuracy: 90.1000 % || Test Accuracy: 90.0147 %\n",
      "Train Loss: 1.5981 || Validation Loss: 1.5994 || Test Loss: 1.6015\n",
      "     \n",
      "Epoch: 33 of 200 || Train Accuracy: 90.7333 % || Validation Accuracy: 90.0000 % || Test Accuracy: 90.3451 %\n",
      "Train Loss: 1.5967 || Validation Loss: 1.5965 || Test Loss: 1.5990\n",
      "     \n",
      "Epoch: 34 of 200 || Train Accuracy: 90.8933 % || Validation Accuracy: 90.2000 % || Test Accuracy: 90.2349 %\n",
      "Train Loss: 1.5938 || Validation Loss: 1.5945 || Test Loss: 1.5971\n",
      "     \n",
      "Epoch: 35 of 200 || Train Accuracy: 90.9067 % || Validation Accuracy: 90.1000 % || Test Accuracy: 90.1615 %\n",
      "Train Loss: 1.5917 || Validation Loss: 1.5931 || Test Loss: 1.5955\n",
      "     \n",
      "Epoch: 36 of 200 || Train Accuracy: 90.9400 % || Validation Accuracy: 90.2000 % || Test Accuracy: 90.1248 %\n",
      "Train Loss: 1.5901 || Validation Loss: 1.5919 || Test Loss: 1.5940\n",
      "     \n",
      "Epoch: 37 of 200 || Train Accuracy: 90.9533 % || Validation Accuracy: 90.1000 % || Test Accuracy: 90.3451 %\n",
      "Train Loss: 1.5888 || Validation Loss: 1.5913 || Test Loss: 1.5932\n",
      "     \n",
      "Epoch: 38 of 200 || Train Accuracy: 90.9600 % || Validation Accuracy: 90.2000 % || Test Accuracy: 90.3818 %\n",
      "Train Loss: 1.5880 || Validation Loss: 1.5905 || Test Loss: 1.5926\n",
      "     \n",
      "Epoch: 39 of 200 || Train Accuracy: 91.1467 % || Validation Accuracy: 90.2000 % || Test Accuracy: 90.4919 %\n",
      "Train Loss: 1.5871 || Validation Loss: 1.5891 || Test Loss: 1.5916\n",
      "     \n",
      "Epoch: 40 of 200 || Train Accuracy: 91.3067 % || Validation Accuracy: 90.3000 % || Test Accuracy: 90.5653 %\n",
      "Train Loss: 1.5858 || Validation Loss: 1.5877 || Test Loss: 1.5907\n",
      "     \n",
      "Epoch: 41 of 200 || Train Accuracy: 91.4133 % || Validation Accuracy: 90.7000 % || Test Accuracy: 90.6021 %\n",
      "Train Loss: 1.5845 || Validation Loss: 1.5866 || Test Loss: 1.5902\n",
      "     \n",
      "Epoch: 42 of 200 || Train Accuracy: 91.4533 % || Validation Accuracy: 90.7000 % || Test Accuracy: 90.6021 %\n",
      "Train Loss: 1.5836 || Validation Loss: 1.5859 || Test Loss: 1.5899\n",
      "     \n",
      "Epoch: 43 of 200 || Train Accuracy: 91.5600 % || Validation Accuracy: 90.8000 % || Test Accuracy: 90.6755 %\n",
      "Train Loss: 1.5830 || Validation Loss: 1.5855 || Test Loss: 1.5897\n",
      "     \n",
      "Epoch: 44 of 200 || Train Accuracy: 91.7200 % || Validation Accuracy: 90.9000 % || Test Accuracy: 90.7489 %\n",
      "Train Loss: 1.5825 || Validation Loss: 1.5853 || Test Loss: 1.5895\n",
      "     \n",
      "Epoch: 45 of 200 || Train Accuracy: 91.8133 % || Validation Accuracy: 90.8000 % || Test Accuracy: 90.7856 %\n",
      "Train Loss: 1.5819 || Validation Loss: 1.5850 || Test Loss: 1.5891\n",
      "     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46 of 200 || Train Accuracy: 91.9067 % || Validation Accuracy: 91.1000 % || Test Accuracy: 90.7122 %\n",
      "Train Loss: 1.5811 || Validation Loss: 1.5845 || Test Loss: 1.5885\n",
      "     \n",
      "Epoch: 47 of 200 || Train Accuracy: 91.9600 % || Validation Accuracy: 91.2000 % || Test Accuracy: 90.6021 %\n",
      "Train Loss: 1.5801 || Validation Loss: 1.5840 || Test Loss: 1.5878\n",
      "     \n",
      "Epoch: 48 of 200 || Train Accuracy: 91.9733 % || Validation Accuracy: 91.1000 % || Test Accuracy: 90.6388 %\n",
      "Train Loss: 1.5792 || Validation Loss: 1.5835 || Test Loss: 1.5873\n",
      "     \n",
      "Epoch: 49 of 200 || Train Accuracy: 92.0000 % || Validation Accuracy: 91.1000 % || Test Accuracy: 90.7122 %\n",
      "Train Loss: 1.5784 || Validation Loss: 1.5830 || Test Loss: 1.5868\n",
      "     \n",
      "Epoch: 50 of 200 || Train Accuracy: 92.1333 % || Validation Accuracy: 91.1000 % || Test Accuracy: 90.7489 %\n",
      "Train Loss: 1.5778 || Validation Loss: 1.5825 || Test Loss: 1.5863\n",
      "     \n",
      "Epoch: 51 of 200 || Train Accuracy: 92.1200 % || Validation Accuracy: 91.3000 % || Test Accuracy: 90.7489 %\n",
      "Train Loss: 1.5773 || Validation Loss: 1.5818 || Test Loss: 1.5858\n",
      "     \n",
      "Epoch: 52 of 200 || Train Accuracy: 92.2000 % || Validation Accuracy: 91.2000 % || Test Accuracy: 90.8223 %\n",
      "Train Loss: 1.5766 || Validation Loss: 1.5810 || Test Loss: 1.5853\n",
      "     \n",
      "Epoch: 53 of 200 || Train Accuracy: 92.3333 % || Validation Accuracy: 91.3000 % || Test Accuracy: 90.8590 %\n",
      "Train Loss: 1.5758 || Validation Loss: 1.5802 || Test Loss: 1.5847\n",
      "     \n",
      "Epoch: 54 of 200 || Train Accuracy: 92.4200 % || Validation Accuracy: 91.4000 % || Test Accuracy: 90.9325 %\n",
      "Train Loss: 1.5748 || Validation Loss: 1.5796 || Test Loss: 1.5843\n",
      "     \n",
      "Epoch: 55 of 200 || Train Accuracy: 92.5067 % || Validation Accuracy: 91.5000 % || Test Accuracy: 91.0059 %\n",
      "Train Loss: 1.5740 || Validation Loss: 1.5792 || Test Loss: 1.5840\n",
      "     \n",
      "Epoch: 56 of 200 || Train Accuracy: 92.5600 % || Validation Accuracy: 91.5000 % || Test Accuracy: 91.0059 %\n",
      "Train Loss: 1.5733 || Validation Loss: 1.5789 || Test Loss: 1.5837\n",
      "     \n",
      "Epoch: 57 of 200 || Train Accuracy: 92.6133 % || Validation Accuracy: 91.5000 % || Test Accuracy: 90.9692 %\n",
      "Train Loss: 1.5727 || Validation Loss: 1.5787 || Test Loss: 1.5835\n",
      "     \n",
      "Epoch: 58 of 200 || Train Accuracy: 92.6400 % || Validation Accuracy: 91.5000 % || Test Accuracy: 90.8957 %\n",
      "Train Loss: 1.5722 || Validation Loss: 1.5786 || Test Loss: 1.5832\n",
      "     \n",
      "Epoch: 59 of 200 || Train Accuracy: 92.7267 % || Validation Accuracy: 91.4000 % || Test Accuracy: 90.8223 %\n",
      "Train Loss: 1.5717 || Validation Loss: 1.5782 || Test Loss: 1.5828\n",
      "     \n",
      "Epoch: 60 of 200 || Train Accuracy: 92.7600 % || Validation Accuracy: 91.5000 % || Test Accuracy: 90.8957 %\n",
      "Train Loss: 1.5711 || Validation Loss: 1.5777 || Test Loss: 1.5823\n",
      "     \n",
      "Epoch: 61 of 200 || Train Accuracy: 92.8200 % || Validation Accuracy: 91.6000 % || Test Accuracy: 90.9692 %\n",
      "Train Loss: 1.5704 || Validation Loss: 1.5771 || Test Loss: 1.5819\n",
      "     \n",
      "Epoch: 62 of 200 || Train Accuracy: 92.8800 % || Validation Accuracy: 91.7000 % || Test Accuracy: 90.8957 %\n",
      "Train Loss: 1.5697 || Validation Loss: 1.5766 || Test Loss: 1.5815\n",
      "     \n",
      "Epoch: 63 of 200 || Train Accuracy: 92.9133 % || Validation Accuracy: 91.7000 % || Test Accuracy: 90.9325 %\n",
      "Train Loss: 1.5691 || Validation Loss: 1.5762 || Test Loss: 1.5812\n",
      "     \n",
      "Epoch: 64 of 200 || Train Accuracy: 92.9800 % || Validation Accuracy: 91.7000 % || Test Accuracy: 90.9325 %\n",
      "Train Loss: 1.5686 || Validation Loss: 1.5759 || Test Loss: 1.5810\n",
      "     \n",
      "Epoch: 65 of 200 || Train Accuracy: 93.1200 % || Validation Accuracy: 91.7000 % || Test Accuracy: 91.0059 %\n",
      "Train Loss: 1.5682 || Validation Loss: 1.5756 || Test Loss: 1.5807\n",
      "     \n",
      "Epoch: 66 of 200 || Train Accuracy: 93.1933 % || Validation Accuracy: 91.6000 % || Test Accuracy: 91.0059 %\n",
      "Train Loss: 1.5677 || Validation Loss: 1.5754 || Test Loss: 1.5805\n",
      "     \n",
      "Epoch: 67 of 200 || Train Accuracy: 93.2267 % || Validation Accuracy: 91.6000 % || Test Accuracy: 91.0426 %\n",
      "Train Loss: 1.5671 || Validation Loss: 1.5751 || Test Loss: 1.5802\n",
      "     \n",
      "Epoch: 68 of 200 || Train Accuracy: 93.2867 % || Validation Accuracy: 91.6000 % || Test Accuracy: 91.0059 %\n",
      "Train Loss: 1.5666 || Validation Loss: 1.5749 || Test Loss: 1.5800\n",
      "     \n",
      "Epoch: 69 of 200 || Train Accuracy: 93.3400 % || Validation Accuracy: 91.6000 % || Test Accuracy: 91.0059 %\n",
      "Train Loss: 1.5661 || Validation Loss: 1.5746 || Test Loss: 1.5798\n",
      "     \n",
      "Epoch: 70 of 200 || Train Accuracy: 93.3333 % || Validation Accuracy: 91.6000 % || Test Accuracy: 91.0059 %\n",
      "Train Loss: 1.5656 || Validation Loss: 1.5742 || Test Loss: 1.5795\n",
      "     \n",
      "Epoch: 71 of 200 || Train Accuracy: 93.4067 % || Validation Accuracy: 91.6000 % || Test Accuracy: 90.9325 %\n",
      "Train Loss: 1.5651 || Validation Loss: 1.5739 || Test Loss: 1.5793\n",
      "     \n",
      "Epoch: 72 of 200 || Train Accuracy: 93.4400 % || Validation Accuracy: 91.6000 % || Test Accuracy: 90.9692 %\n",
      "Train Loss: 1.5646 || Validation Loss: 1.5735 || Test Loss: 1.5790\n",
      "     \n",
      "Epoch: 73 of 200 || Train Accuracy: 93.4867 % || Validation Accuracy: 91.7000 % || Test Accuracy: 91.0059 %\n",
      "Train Loss: 1.5640 || Validation Loss: 1.5731 || Test Loss: 1.5786\n",
      "     \n",
      "Epoch: 74 of 200 || Train Accuracy: 93.5200 % || Validation Accuracy: 91.8000 % || Test Accuracy: 91.0059 %\n",
      "Train Loss: 1.5635 || Validation Loss: 1.5727 || Test Loss: 1.5783\n",
      "     \n",
      "Epoch: 75 of 200 || Train Accuracy: 93.5800 % || Validation Accuracy: 91.8000 % || Test Accuracy: 90.9692 %\n",
      "Train Loss: 1.5630 || Validation Loss: 1.5724 || Test Loss: 1.5780\n",
      "     \n",
      "Epoch: 76 of 200 || Train Accuracy: 93.6333 % || Validation Accuracy: 91.8000 % || Test Accuracy: 90.9692 %\n",
      "Train Loss: 1.5625 || Validation Loss: 1.5722 || Test Loss: 1.5778\n",
      "     \n",
      "Epoch: 77 of 200 || Train Accuracy: 93.7067 % || Validation Accuracy: 91.8000 % || Test Accuracy: 90.9692 %\n",
      "Train Loss: 1.5620 || Validation Loss: 1.5719 || Test Loss: 1.5775\n",
      "     \n",
      "Epoch: 78 of 200 || Train Accuracy: 93.7933 % || Validation Accuracy: 91.8000 % || Test Accuracy: 90.9692 %\n",
      "Train Loss: 1.5615 || Validation Loss: 1.5717 || Test Loss: 1.5773\n",
      "     \n",
      "Epoch: 79 of 200 || Train Accuracy: 93.7933 % || Validation Accuracy: 91.8000 % || Test Accuracy: 90.9692 %\n",
      "Train Loss: 1.5610 || Validation Loss: 1.5714 || Test Loss: 1.5771\n",
      "     \n",
      "Epoch: 80 of 200 || Train Accuracy: 93.8067 % || Validation Accuracy: 91.8000 % || Test Accuracy: 90.9692 %\n",
      "Train Loss: 1.5605 || Validation Loss: 1.5711 || Test Loss: 1.5769\n",
      "     \n",
      "Epoch: 81 of 200 || Train Accuracy: 93.8600 % || Validation Accuracy: 91.8000 % || Test Accuracy: 91.0059 %\n",
      "Train Loss: 1.5601 || Validation Loss: 1.5708 || Test Loss: 1.5767\n",
      "     \n",
      "Epoch: 82 of 200 || Train Accuracy: 93.9333 % || Validation Accuracy: 91.8000 % || Test Accuracy: 91.0059 %\n",
      "Train Loss: 1.5596 || Validation Loss: 1.5706 || Test Loss: 1.5765\n",
      "     \n",
      "Epoch: 83 of 200 || Train Accuracy: 93.9667 % || Validation Accuracy: 91.8000 % || Test Accuracy: 91.0426 %\n",
      "Train Loss: 1.5592 || Validation Loss: 1.5704 || Test Loss: 1.5763\n",
      "     \n",
      "Epoch: 84 of 200 || Train Accuracy: 94.0467 % || Validation Accuracy: 91.8000 % || Test Accuracy: 91.0426 %\n",
      "Train Loss: 1.5588 || Validation Loss: 1.5701 || Test Loss: 1.5760\n",
      "     \n",
      "Epoch: 85 of 200 || Train Accuracy: 94.0867 % || Validation Accuracy: 91.9000 % || Test Accuracy: 91.0059 %\n",
      "Train Loss: 1.5583 || Validation Loss: 1.5699 || Test Loss: 1.5758\n",
      "     \n",
      "Epoch: 86 of 200 || Train Accuracy: 94.1000 % || Validation Accuracy: 92.1000 % || Test Accuracy: 91.0059 %\n",
      "Train Loss: 1.5578 || Validation Loss: 1.5696 || Test Loss: 1.5755\n",
      "     \n",
      "Epoch: 87 of 200 || Train Accuracy: 94.1533 % || Validation Accuracy: 92.1000 % || Test Accuracy: 91.0426 %\n",
      "Train Loss: 1.5574 || Validation Loss: 1.5693 || Test Loss: 1.5753\n",
      "     \n",
      "Epoch: 88 of 200 || Train Accuracy: 94.1800 % || Validation Accuracy: 92.1000 % || Test Accuracy: 91.0426 %\n",
      "Train Loss: 1.5569 || Validation Loss: 1.5691 || Test Loss: 1.5751\n",
      "     \n",
      "Epoch: 89 of 200 || Train Accuracy: 94.2200 % || Validation Accuracy: 92.1000 % || Test Accuracy: 91.0793 %\n",
      "Train Loss: 1.5564 || Validation Loss: 1.5688 || Test Loss: 1.5748\n",
      "     \n",
      "Epoch: 90 of 200 || Train Accuracy: 94.2467 % || Validation Accuracy: 92.1000 % || Test Accuracy: 91.0793 %\n",
      "Train Loss: 1.5560 || Validation Loss: 1.5686 || Test Loss: 1.5746\n",
      "     \n",
      "Epoch: 91 of 200 || Train Accuracy: 94.3067 % || Validation Accuracy: 92.1000 % || Test Accuracy: 91.1160 %\n",
      "Train Loss: 1.5556 || Validation Loss: 1.5683 || Test Loss: 1.5744\n",
      "     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 92 of 200 || Train Accuracy: 94.3467 % || Validation Accuracy: 92.2000 % || Test Accuracy: 91.1160 %\n",
      "Train Loss: 1.5551 || Validation Loss: 1.5681 || Test Loss: 1.5742\n",
      "     \n",
      "Epoch: 93 of 200 || Train Accuracy: 94.4133 % || Validation Accuracy: 92.3000 % || Test Accuracy: 91.1160 %\n",
      "Train Loss: 1.5547 || Validation Loss: 1.5678 || Test Loss: 1.5740\n",
      "     \n",
      "Epoch: 94 of 200 || Train Accuracy: 94.4667 % || Validation Accuracy: 92.3000 % || Test Accuracy: 91.1894 %\n",
      "Train Loss: 1.5542 || Validation Loss: 1.5676 || Test Loss: 1.5738\n",
      "     \n",
      "Epoch: 95 of 200 || Train Accuracy: 94.5267 % || Validation Accuracy: 92.3000 % || Test Accuracy: 91.1894 %\n",
      "Train Loss: 1.5537 || Validation Loss: 1.5674 || Test Loss: 1.5736\n",
      "     \n",
      "Epoch: 96 of 200 || Train Accuracy: 94.5400 % || Validation Accuracy: 92.4000 % || Test Accuracy: 91.1894 %\n",
      "Train Loss: 1.5533 || Validation Loss: 1.5672 || Test Loss: 1.5734\n",
      "     \n",
      "Epoch: 97 of 200 || Train Accuracy: 94.5867 % || Validation Accuracy: 92.4000 % || Test Accuracy: 91.1894 %\n",
      "Train Loss: 1.5529 || Validation Loss: 1.5670 || Test Loss: 1.5732\n",
      "     \n",
      "Epoch: 98 of 200 || Train Accuracy: 94.6467 % || Validation Accuracy: 92.4000 % || Test Accuracy: 91.1894 %\n",
      "Train Loss: 1.5525 || Validation Loss: 1.5667 || Test Loss: 1.5729\n",
      "     \n",
      "Epoch: 99 of 200 || Train Accuracy: 94.7200 % || Validation Accuracy: 92.4000 % || Test Accuracy: 91.2261 %\n",
      "Train Loss: 1.5521 || Validation Loss: 1.5665 || Test Loss: 1.5727\n",
      "     \n",
      "Epoch: 100 of 200 || Train Accuracy: 94.7933 % || Validation Accuracy: 92.5000 % || Test Accuracy: 91.2261 %\n",
      "Train Loss: 1.5516 || Validation Loss: 1.5663 || Test Loss: 1.5725\n",
      "     \n",
      "Epoch: 101 of 200 || Train Accuracy: 94.8400 % || Validation Accuracy: 92.5000 % || Test Accuracy: 91.1894 %\n",
      "Train Loss: 1.5512 || Validation Loss: 1.5661 || Test Loss: 1.5723\n",
      "     \n",
      "Epoch: 102 of 200 || Train Accuracy: 94.9067 % || Validation Accuracy: 92.5000 % || Test Accuracy: 91.1894 %\n",
      "Train Loss: 1.5508 || Validation Loss: 1.5659 || Test Loss: 1.5721\n",
      "     \n",
      "Epoch: 103 of 200 || Train Accuracy: 94.9467 % || Validation Accuracy: 92.5000 % || Test Accuracy: 91.2261 %\n",
      "Train Loss: 1.5504 || Validation Loss: 1.5657 || Test Loss: 1.5720\n",
      "     \n",
      "Epoch: 104 of 200 || Train Accuracy: 95.0067 % || Validation Accuracy: 92.5000 % || Test Accuracy: 91.1894 %\n",
      "Train Loss: 1.5499 || Validation Loss: 1.5655 || Test Loss: 1.5718\n",
      "     \n",
      "Epoch: 105 of 200 || Train Accuracy: 95.0467 % || Validation Accuracy: 92.5000 % || Test Accuracy: 91.2261 %\n",
      "Train Loss: 1.5495 || Validation Loss: 1.5653 || Test Loss: 1.5716\n",
      "     \n",
      "Epoch: 106 of 200 || Train Accuracy: 95.0933 % || Validation Accuracy: 92.5000 % || Test Accuracy: 91.2261 %\n",
      "Train Loss: 1.5491 || Validation Loss: 1.5651 || Test Loss: 1.5714\n",
      "     \n",
      "Epoch: 107 of 200 || Train Accuracy: 95.1333 % || Validation Accuracy: 92.5000 % || Test Accuracy: 91.2261 %\n",
      "Train Loss: 1.5487 || Validation Loss: 1.5649 || Test Loss: 1.5712\n",
      "     \n",
      "Epoch: 108 of 200 || Train Accuracy: 95.1467 % || Validation Accuracy: 92.5000 % || Test Accuracy: 91.2261 %\n",
      "Train Loss: 1.5483 || Validation Loss: 1.5647 || Test Loss: 1.5710\n",
      "     \n",
      "Epoch: 109 of 200 || Train Accuracy: 95.1667 % || Validation Accuracy: 92.5000 % || Test Accuracy: 91.2628 %\n",
      "Train Loss: 1.5478 || Validation Loss: 1.5644 || Test Loss: 1.5708\n",
      "     \n",
      "Epoch: 110 of 200 || Train Accuracy: 95.2267 % || Validation Accuracy: 92.5000 % || Test Accuracy: 91.2628 %\n",
      "Train Loss: 1.5474 || Validation Loss: 1.5642 || Test Loss: 1.5706\n",
      "     \n",
      "Epoch: 111 of 200 || Train Accuracy: 95.2600 % || Validation Accuracy: 92.5000 % || Test Accuracy: 91.2996 %\n",
      "Train Loss: 1.5470 || Validation Loss: 1.5640 || Test Loss: 1.5704\n",
      "     \n",
      "Epoch: 112 of 200 || Train Accuracy: 95.3200 % || Validation Accuracy: 92.5000 % || Test Accuracy: 91.3730 %\n",
      "Train Loss: 1.5466 || Validation Loss: 1.5638 || Test Loss: 1.5702\n",
      "     \n",
      "Epoch: 113 of 200 || Train Accuracy: 95.3400 % || Validation Accuracy: 92.5000 % || Test Accuracy: 91.3730 %\n",
      "Train Loss: 1.5462 || Validation Loss: 1.5636 || Test Loss: 1.5700\n",
      "     \n",
      "Epoch: 114 of 200 || Train Accuracy: 95.3667 % || Validation Accuracy: 92.5000 % || Test Accuracy: 91.3730 %\n",
      "Train Loss: 1.5458 || Validation Loss: 1.5634 || Test Loss: 1.5699\n",
      "     \n",
      "Epoch: 115 of 200 || Train Accuracy: 95.4067 % || Validation Accuracy: 92.5000 % || Test Accuracy: 91.3363 %\n",
      "Train Loss: 1.5454 || Validation Loss: 1.5632 || Test Loss: 1.5697\n",
      "     \n",
      "Epoch: 116 of 200 || Train Accuracy: 95.4600 % || Validation Accuracy: 92.4000 % || Test Accuracy: 91.3730 %\n",
      "Train Loss: 1.5450 || Validation Loss: 1.5630 || Test Loss: 1.5695\n",
      "     \n",
      "Epoch: 117 of 200 || Train Accuracy: 95.5133 % || Validation Accuracy: 92.4000 % || Test Accuracy: 91.3730 %\n",
      "Train Loss: 1.5446 || Validation Loss: 1.5628 || Test Loss: 1.5693\n",
      "     \n",
      "Epoch: 118 of 200 || Train Accuracy: 95.5600 % || Validation Accuracy: 92.5000 % || Test Accuracy: 91.3730 %\n",
      "Train Loss: 1.5442 || Validation Loss: 1.5626 || Test Loss: 1.5692\n",
      "     \n",
      "Epoch: 119 of 200 || Train Accuracy: 95.5933 % || Validation Accuracy: 92.5000 % || Test Accuracy: 91.4097 %\n",
      "Train Loss: 1.5438 || Validation Loss: 1.5625 || Test Loss: 1.5690\n",
      "     \n",
      "Epoch: 120 of 200 || Train Accuracy: 95.6200 % || Validation Accuracy: 92.5000 % || Test Accuracy: 91.4464 %\n",
      "Train Loss: 1.5434 || Validation Loss: 1.5623 || Test Loss: 1.5688\n",
      "     \n",
      "Epoch: 121 of 200 || Train Accuracy: 95.6333 % || Validation Accuracy: 92.5000 % || Test Accuracy: 91.4831 %\n",
      "Train Loss: 1.5430 || Validation Loss: 1.5621 || Test Loss: 1.5686\n",
      "     \n",
      "Epoch: 122 of 200 || Train Accuracy: 95.6667 % || Validation Accuracy: 92.5000 % || Test Accuracy: 91.4831 %\n",
      "Train Loss: 1.5426 || Validation Loss: 1.5619 || Test Loss: 1.5685\n",
      "     \n",
      "Epoch: 123 of 200 || Train Accuracy: 95.7400 % || Validation Accuracy: 92.5000 % || Test Accuracy: 91.4831 %\n",
      "Train Loss: 1.5422 || Validation Loss: 1.5617 || Test Loss: 1.5683\n",
      "     \n",
      "Epoch: 124 of 200 || Train Accuracy: 95.7533 % || Validation Accuracy: 92.5000 % || Test Accuracy: 91.5198 %\n",
      "Train Loss: 1.5418 || Validation Loss: 1.5615 || Test Loss: 1.5681\n",
      "     \n",
      "Epoch: 125 of 200 || Train Accuracy: 95.7667 % || Validation Accuracy: 92.5000 % || Test Accuracy: 91.5198 %\n",
      "Train Loss: 1.5414 || Validation Loss: 1.5613 || Test Loss: 1.5679\n",
      "     \n",
      "Epoch: 126 of 200 || Train Accuracy: 95.7867 % || Validation Accuracy: 92.5000 % || Test Accuracy: 91.5932 %\n",
      "Train Loss: 1.5410 || Validation Loss: 1.5611 || Test Loss: 1.5678\n",
      "     \n",
      "Epoch: 127 of 200 || Train Accuracy: 95.8200 % || Validation Accuracy: 92.5000 % || Test Accuracy: 91.5565 %\n",
      "Train Loss: 1.5406 || Validation Loss: 1.5610 || Test Loss: 1.5676\n",
      "     \n",
      "Epoch: 128 of 200 || Train Accuracy: 95.8600 % || Validation Accuracy: 92.5000 % || Test Accuracy: 91.5565 %\n",
      "Train Loss: 1.5403 || Validation Loss: 1.5608 || Test Loss: 1.5675\n",
      "     \n",
      "Epoch: 129 of 200 || Train Accuracy: 95.9267 % || Validation Accuracy: 92.5000 % || Test Accuracy: 91.5565 %\n",
      "Train Loss: 1.5399 || Validation Loss: 1.5606 || Test Loss: 1.5673\n",
      "     \n",
      "Epoch: 130 of 200 || Train Accuracy: 95.9600 % || Validation Accuracy: 92.5000 % || Test Accuracy: 91.5565 %\n",
      "Train Loss: 1.5395 || Validation Loss: 1.5604 || Test Loss: 1.5671\n",
      "     \n",
      "Epoch: 131 of 200 || Train Accuracy: 95.9867 % || Validation Accuracy: 92.5000 % || Test Accuracy: 91.5198 %\n",
      "Train Loss: 1.5391 || Validation Loss: 1.5603 || Test Loss: 1.5670\n",
      "     \n",
      "Epoch: 132 of 200 || Train Accuracy: 96.0267 % || Validation Accuracy: 92.5000 % || Test Accuracy: 91.5198 %\n",
      "Train Loss: 1.5388 || Validation Loss: 1.5601 || Test Loss: 1.5668\n",
      "     \n",
      "Epoch: 133 of 200 || Train Accuracy: 96.0400 % || Validation Accuracy: 92.8000 % || Test Accuracy: 91.5198 %\n",
      "Train Loss: 1.5384 || Validation Loss: 1.5599 || Test Loss: 1.5667\n",
      "     \n",
      "Epoch: 134 of 200 || Train Accuracy: 96.0933 % || Validation Accuracy: 92.9000 % || Test Accuracy: 91.5932 %\n",
      "Train Loss: 1.5380 || Validation Loss: 1.5597 || Test Loss: 1.5665\n",
      "     \n",
      "Epoch: 135 of 200 || Train Accuracy: 96.1333 % || Validation Accuracy: 93.0000 % || Test Accuracy: 91.5932 %\n",
      "Train Loss: 1.5376 || Validation Loss: 1.5596 || Test Loss: 1.5663\n",
      "     \n",
      "Epoch: 136 of 200 || Train Accuracy: 96.1533 % || Validation Accuracy: 93.1000 % || Test Accuracy: 91.6300 %\n",
      "Train Loss: 1.5372 || Validation Loss: 1.5594 || Test Loss: 1.5662\n",
      "     \n",
      "Epoch: 137 of 200 || Train Accuracy: 96.1867 % || Validation Accuracy: 93.1000 % || Test Accuracy: 91.6667 %\n",
      "Train Loss: 1.5369 || Validation Loss: 1.5593 || Test Loss: 1.5661\n",
      "     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 138 of 200 || Train Accuracy: 96.2200 % || Validation Accuracy: 93.0000 % || Test Accuracy: 91.6667 %\n",
      "Train Loss: 1.5365 || Validation Loss: 1.5591 || Test Loss: 1.5659\n",
      "     \n",
      "Epoch: 139 of 200 || Train Accuracy: 96.2533 % || Validation Accuracy: 93.0000 % || Test Accuracy: 91.7034 %\n",
      "Train Loss: 1.5362 || Validation Loss: 1.5589 || Test Loss: 1.5658\n",
      "     \n",
      "Epoch: 140 of 200 || Train Accuracy: 96.2667 % || Validation Accuracy: 93.0000 % || Test Accuracy: 91.7034 %\n",
      "Train Loss: 1.5358 || Validation Loss: 1.5588 || Test Loss: 1.5656\n",
      "     \n",
      "Epoch: 141 of 200 || Train Accuracy: 96.3067 % || Validation Accuracy: 93.0000 % || Test Accuracy: 91.7768 %\n",
      "Train Loss: 1.5354 || Validation Loss: 1.5586 || Test Loss: 1.5655\n",
      "     \n",
      "Epoch: 142 of 200 || Train Accuracy: 96.3400 % || Validation Accuracy: 93.1000 % || Test Accuracy: 91.7768 %\n",
      "Train Loss: 1.5351 || Validation Loss: 1.5585 || Test Loss: 1.5654\n",
      "     \n",
      "Epoch: 143 of 200 || Train Accuracy: 96.3800 % || Validation Accuracy: 93.1000 % || Test Accuracy: 91.7768 %\n",
      "Train Loss: 1.5347 || Validation Loss: 1.5583 || Test Loss: 1.5652\n",
      "     \n",
      "Epoch: 144 of 200 || Train Accuracy: 96.4333 % || Validation Accuracy: 93.1000 % || Test Accuracy: 91.7768 %\n",
      "Train Loss: 1.5344 || Validation Loss: 1.5582 || Test Loss: 1.5651\n",
      "     \n",
      "Epoch: 145 of 200 || Train Accuracy: 96.4800 % || Validation Accuracy: 93.1000 % || Test Accuracy: 91.7768 %\n",
      "Train Loss: 1.5340 || Validation Loss: 1.5580 || Test Loss: 1.5649\n",
      "     \n",
      "Epoch: 146 of 200 || Train Accuracy: 96.5267 % || Validation Accuracy: 93.1000 % || Test Accuracy: 91.7768 %\n",
      "Train Loss: 1.5337 || Validation Loss: 1.5578 || Test Loss: 1.5648\n",
      "     \n",
      "Epoch: 147 of 200 || Train Accuracy: 96.5400 % || Validation Accuracy: 93.1000 % || Test Accuracy: 91.7768 %\n",
      "Train Loss: 1.5333 || Validation Loss: 1.5577 || Test Loss: 1.5647\n",
      "     \n",
      "Epoch: 148 of 200 || Train Accuracy: 96.5933 % || Validation Accuracy: 93.1000 % || Test Accuracy: 91.7768 %\n",
      "Train Loss: 1.5330 || Validation Loss: 1.5575 || Test Loss: 1.5645\n",
      "     \n",
      "Epoch: 149 of 200 || Train Accuracy: 96.6267 % || Validation Accuracy: 93.1000 % || Test Accuracy: 91.7768 %\n",
      "Train Loss: 1.5326 || Validation Loss: 1.5574 || Test Loss: 1.5644\n",
      "     \n",
      "Epoch: 150 of 200 || Train Accuracy: 96.6400 % || Validation Accuracy: 93.1000 % || Test Accuracy: 91.8135 %\n",
      "Train Loss: 1.5323 || Validation Loss: 1.5572 || Test Loss: 1.5643\n",
      "     \n",
      "Epoch: 151 of 200 || Train Accuracy: 96.7000 % || Validation Accuracy: 93.1000 % || Test Accuracy: 91.8502 %\n",
      "Train Loss: 1.5319 || Validation Loss: 1.5570 || Test Loss: 1.5641\n",
      "     \n",
      "Epoch: 152 of 200 || Train Accuracy: 96.7333 % || Validation Accuracy: 93.1000 % || Test Accuracy: 91.8502 %\n",
      "Train Loss: 1.5316 || Validation Loss: 1.5569 || Test Loss: 1.5640\n",
      "     \n",
      "Epoch: 153 of 200 || Train Accuracy: 96.7733 % || Validation Accuracy: 93.1000 % || Test Accuracy: 91.8502 %\n",
      "Train Loss: 1.5312 || Validation Loss: 1.5567 || Test Loss: 1.5639\n",
      "     \n",
      "Epoch: 154 of 200 || Train Accuracy: 96.7733 % || Validation Accuracy: 93.1000 % || Test Accuracy: 91.8869 %\n",
      "Train Loss: 1.5309 || Validation Loss: 1.5566 || Test Loss: 1.5637\n",
      "     \n",
      "Epoch: 155 of 200 || Train Accuracy: 96.8133 % || Validation Accuracy: 93.1000 % || Test Accuracy: 91.8869 %\n",
      "Train Loss: 1.5306 || Validation Loss: 1.5565 || Test Loss: 1.5636\n",
      "     \n",
      "Epoch: 156 of 200 || Train Accuracy: 96.8400 % || Validation Accuracy: 93.1000 % || Test Accuracy: 91.8869 %\n",
      "Train Loss: 1.5302 || Validation Loss: 1.5563 || Test Loss: 1.5635\n",
      "     \n",
      "Epoch: 157 of 200 || Train Accuracy: 96.8600 % || Validation Accuracy: 93.1000 % || Test Accuracy: 91.8869 %\n",
      "Train Loss: 1.5299 || Validation Loss: 1.5562 || Test Loss: 1.5634\n",
      "     \n",
      "Epoch: 158 of 200 || Train Accuracy: 96.8800 % || Validation Accuracy: 93.1000 % || Test Accuracy: 91.8869 %\n",
      "Train Loss: 1.5296 || Validation Loss: 1.5560 || Test Loss: 1.5632\n",
      "     \n",
      "Epoch: 159 of 200 || Train Accuracy: 96.9133 % || Validation Accuracy: 93.1000 % || Test Accuracy: 91.8869 %\n",
      "Train Loss: 1.5292 || Validation Loss: 1.5559 || Test Loss: 1.5631\n",
      "     \n",
      "Epoch: 160 of 200 || Train Accuracy: 96.9600 % || Validation Accuracy: 93.1000 % || Test Accuracy: 91.8869 %\n",
      "Train Loss: 1.5289 || Validation Loss: 1.5557 || Test Loss: 1.5630\n",
      "     \n",
      "Epoch: 161 of 200 || Train Accuracy: 96.9933 % || Validation Accuracy: 93.1000 % || Test Accuracy: 91.8869 %\n",
      "Train Loss: 1.5286 || Validation Loss: 1.5556 || Test Loss: 1.5629\n",
      "     \n",
      "Epoch: 162 of 200 || Train Accuracy: 97.0267 % || Validation Accuracy: 93.1000 % || Test Accuracy: 91.8869 %\n",
      "Train Loss: 1.5282 || Validation Loss: 1.5554 || Test Loss: 1.5628\n",
      "     \n",
      "Epoch: 163 of 200 || Train Accuracy: 97.0667 % || Validation Accuracy: 93.1000 % || Test Accuracy: 91.8869 %\n",
      "Train Loss: 1.5279 || Validation Loss: 1.5553 || Test Loss: 1.5626\n",
      "     \n",
      "Epoch: 164 of 200 || Train Accuracy: 97.0800 % || Validation Accuracy: 93.1000 % || Test Accuracy: 91.8869 %\n",
      "Train Loss: 1.5276 || Validation Loss: 1.5551 || Test Loss: 1.5625\n",
      "     \n",
      "Epoch: 165 of 200 || Train Accuracy: 97.1200 % || Validation Accuracy: 93.1000 % || Test Accuracy: 91.8869 %\n",
      "Train Loss: 1.5273 || Validation Loss: 1.5550 || Test Loss: 1.5624\n",
      "     \n",
      "Epoch: 166 of 200 || Train Accuracy: 97.1267 % || Validation Accuracy: 93.1000 % || Test Accuracy: 91.8869 %\n",
      "Train Loss: 1.5269 || Validation Loss: 1.5549 || Test Loss: 1.5623\n",
      "     \n",
      "Epoch: 167 of 200 || Train Accuracy: 97.1533 % || Validation Accuracy: 93.1000 % || Test Accuracy: 91.8869 %\n",
      "Train Loss: 1.5266 || Validation Loss: 1.5547 || Test Loss: 1.5622\n",
      "     \n",
      "Epoch: 168 of 200 || Train Accuracy: 97.1867 % || Validation Accuracy: 93.1000 % || Test Accuracy: 91.8869 %\n",
      "Train Loss: 1.5263 || Validation Loss: 1.5546 || Test Loss: 1.5621\n",
      "     \n",
      "Epoch: 169 of 200 || Train Accuracy: 97.1933 % || Validation Accuracy: 93.1000 % || Test Accuracy: 91.8869 %\n",
      "Train Loss: 1.5260 || Validation Loss: 1.5545 || Test Loss: 1.5619\n",
      "     \n",
      "Epoch: 170 of 200 || Train Accuracy: 97.2533 % || Validation Accuracy: 93.1000 % || Test Accuracy: 91.8869 %\n",
      "Train Loss: 1.5257 || Validation Loss: 1.5543 || Test Loss: 1.5618\n",
      "     \n",
      "Epoch: 171 of 200 || Train Accuracy: 97.2933 % || Validation Accuracy: 93.1000 % || Test Accuracy: 91.8869 %\n",
      "Train Loss: 1.5254 || Validation Loss: 1.5542 || Test Loss: 1.5617\n",
      "     \n",
      "Epoch: 172 of 200 || Train Accuracy: 97.3067 % || Validation Accuracy: 93.2000 % || Test Accuracy: 91.8869 %\n",
      "Train Loss: 1.5250 || Validation Loss: 1.5541 || Test Loss: 1.5616\n",
      "     \n",
      "Epoch: 173 of 200 || Train Accuracy: 97.3267 % || Validation Accuracy: 93.2000 % || Test Accuracy: 91.8502 %\n",
      "Train Loss: 1.5247 || Validation Loss: 1.5539 || Test Loss: 1.5615\n",
      "     \n",
      "Epoch: 174 of 200 || Train Accuracy: 97.3333 % || Validation Accuracy: 93.2000 % || Test Accuracy: 91.8502 %\n",
      "Train Loss: 1.5244 || Validation Loss: 1.5538 || Test Loss: 1.5614\n",
      "     \n",
      "Epoch: 175 of 200 || Train Accuracy: 97.3533 % || Validation Accuracy: 93.2000 % || Test Accuracy: 91.8502 %\n",
      "Train Loss: 1.5241 || Validation Loss: 1.5537 || Test Loss: 1.5613\n",
      "     \n",
      "Epoch: 176 of 200 || Train Accuracy: 97.4000 % || Validation Accuracy: 93.2000 % || Test Accuracy: 91.8869 %\n",
      "Train Loss: 1.5238 || Validation Loss: 1.5535 || Test Loss: 1.5612\n",
      "     \n",
      "Epoch: 177 of 200 || Train Accuracy: 97.4333 % || Validation Accuracy: 93.2000 % || Test Accuracy: 91.9236 %\n",
      "Train Loss: 1.5235 || Validation Loss: 1.5534 || Test Loss: 1.5611\n",
      "     \n",
      "Epoch: 178 of 200 || Train Accuracy: 97.4667 % || Validation Accuracy: 93.2000 % || Test Accuracy: 91.9236 %\n",
      "Train Loss: 1.5232 || Validation Loss: 1.5533 || Test Loss: 1.5609\n",
      "     \n",
      "Epoch: 179 of 200 || Train Accuracy: 97.4800 % || Validation Accuracy: 93.2000 % || Test Accuracy: 91.9236 %\n",
      "Train Loss: 1.5229 || Validation Loss: 1.5531 || Test Loss: 1.5608\n",
      "     \n",
      "Epoch: 180 of 200 || Train Accuracy: 97.5067 % || Validation Accuracy: 93.2000 % || Test Accuracy: 91.8869 %\n",
      "Train Loss: 1.5226 || Validation Loss: 1.5530 || Test Loss: 1.5607\n",
      "     \n",
      "Epoch: 181 of 200 || Train Accuracy: 97.5400 % || Validation Accuracy: 93.2000 % || Test Accuracy: 91.9236 %\n",
      "Train Loss: 1.5223 || Validation Loss: 1.5529 || Test Loss: 1.5606\n",
      "     \n",
      "Epoch: 182 of 200 || Train Accuracy: 97.5600 % || Validation Accuracy: 93.2000 % || Test Accuracy: 91.9236 %\n",
      "Train Loss: 1.5220 || Validation Loss: 1.5528 || Test Loss: 1.5605\n",
      "     \n",
      "Epoch: 183 of 200 || Train Accuracy: 97.5733 % || Validation Accuracy: 93.2000 % || Test Accuracy: 91.9604 %\n",
      "Train Loss: 1.5217 || Validation Loss: 1.5526 || Test Loss: 1.5604\n",
      "     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 184 of 200 || Train Accuracy: 97.6200 % || Validation Accuracy: 93.2000 % || Test Accuracy: 91.9604 %\n",
      "Train Loss: 1.5214 || Validation Loss: 1.5525 || Test Loss: 1.5603\n",
      "     \n",
      "Epoch: 185 of 200 || Train Accuracy: 97.6533 % || Validation Accuracy: 93.2000 % || Test Accuracy: 91.9604 %\n",
      "Train Loss: 1.5211 || Validation Loss: 1.5524 || Test Loss: 1.5602\n",
      "     \n",
      "Epoch: 186 of 200 || Train Accuracy: 97.6800 % || Validation Accuracy: 93.2000 % || Test Accuracy: 91.9236 %\n",
      "Train Loss: 1.5208 || Validation Loss: 1.5523 || Test Loss: 1.5601\n",
      "     \n",
      "Epoch: 187 of 200 || Train Accuracy: 97.6867 % || Validation Accuracy: 93.2000 % || Test Accuracy: 91.9604 %\n",
      "Train Loss: 1.5205 || Validation Loss: 1.5522 || Test Loss: 1.5600\n",
      "     \n",
      "Epoch: 188 of 200 || Train Accuracy: 97.7267 % || Validation Accuracy: 93.2000 % || Test Accuracy: 92.0338 %\n",
      "Train Loss: 1.5202 || Validation Loss: 1.5520 || Test Loss: 1.5599\n",
      "     \n",
      "Epoch: 189 of 200 || Train Accuracy: 97.7600 % || Validation Accuracy: 93.2000 % || Test Accuracy: 92.0338 %\n",
      "Train Loss: 1.5199 || Validation Loss: 1.5519 || Test Loss: 1.5598\n",
      "     \n",
      "Epoch: 190 of 200 || Train Accuracy: 97.7867 % || Validation Accuracy: 93.1000 % || Test Accuracy: 92.0338 %\n",
      "Train Loss: 1.5196 || Validation Loss: 1.5518 || Test Loss: 1.5597\n",
      "     \n",
      "Epoch: 191 of 200 || Train Accuracy: 97.8067 % || Validation Accuracy: 93.1000 % || Test Accuracy: 92.0338 %\n",
      "Train Loss: 1.5193 || Validation Loss: 1.5517 || Test Loss: 1.5596\n",
      "     \n",
      "Epoch: 192 of 200 || Train Accuracy: 97.8333 % || Validation Accuracy: 93.1000 % || Test Accuracy: 92.0705 %\n",
      "Train Loss: 1.5190 || Validation Loss: 1.5516 || Test Loss: 1.5595\n",
      "     \n",
      "Epoch: 193 of 200 || Train Accuracy: 97.8600 % || Validation Accuracy: 93.1000 % || Test Accuracy: 92.0705 %\n",
      "Train Loss: 1.5187 || Validation Loss: 1.5515 || Test Loss: 1.5594\n",
      "     \n",
      "Epoch: 194 of 200 || Train Accuracy: 97.9067 % || Validation Accuracy: 93.2000 % || Test Accuracy: 92.1072 %\n",
      "Train Loss: 1.5184 || Validation Loss: 1.5513 || Test Loss: 1.5593\n",
      "     \n",
      "Epoch: 195 of 200 || Train Accuracy: 97.9200 % || Validation Accuracy: 93.2000 % || Test Accuracy: 92.1072 %\n",
      "Train Loss: 1.5182 || Validation Loss: 1.5512 || Test Loss: 1.5592\n",
      "     \n",
      "Epoch: 196 of 200 || Train Accuracy: 97.9400 % || Validation Accuracy: 93.2000 % || Test Accuracy: 92.1072 %\n",
      "Train Loss: 1.5179 || Validation Loss: 1.5511 || Test Loss: 1.5591\n",
      "     \n",
      "Epoch: 197 of 200 || Train Accuracy: 97.9800 % || Validation Accuracy: 93.2000 % || Test Accuracy: 92.1072 %\n",
      "Train Loss: 1.5176 || Validation Loss: 1.5510 || Test Loss: 1.5590\n",
      "     \n",
      "Epoch: 198 of 200 || Train Accuracy: 98.0000 % || Validation Accuracy: 93.3000 % || Test Accuracy: 92.1072 %\n",
      "Train Loss: 1.5173 || Validation Loss: 1.5509 || Test Loss: 1.5590\n",
      "     \n",
      "Epoch: 199 of 200 || Train Accuracy: 98.0133 % || Validation Accuracy: 93.3000 % || Test Accuracy: 92.1072 %\n",
      "Train Loss: 1.5170 || Validation Loss: 1.5508 || Test Loss: 1.5589\n",
      "     \n",
      "###### TRAINING COMPLETED #######\n",
      "Training Time: 15.999403560161591mins\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "trainData, validData, testData, trainTarget, validTarget, testTarget = loadData()\n",
    "\n",
    "trainData = trainData.reshape((trainData.shape[0], 784))\n",
    "trainData = np.insert(trainData, 0 ,np.ones(trainData.shape[0]), axis = 1)\n",
    "\n",
    "validData = validData.reshape((-1, 784))\n",
    "validData = np.insert(validData, 0 ,np.ones(validData.shape[0]), axis = 1)\n",
    "testData = testData.reshape((-1, 784))\n",
    "testData = np.insert(testData, 0 ,np.ones(testData.shape[0]), axis = 1)\n",
    "\n",
    "###Convert one hot\n",
    "TrainTarget, ValidTarget, TestTarget = convertOneHot(trainTarget, validTarget, testTarget)\n",
    "data_in = (trainData, validData, testData)\n",
    "target_in = (TrainTarget, ValidTarget, TestTarget)\n",
    "\n",
    "n_x = trainData.shape[1]\n",
    "n_h = 1000 #hiddenlayers\n",
    "n_o = 10 #output layers\n",
    "\n",
    "#standard deviation\n",
    "stdev1 = np.sqrt(2/(n_x + n_h))\n",
    "stdev2 = np.sqrt(2/(n_h + n_o))\n",
    "w_hid = np.random.normal(loc = 0, scale = stdev1, size = (n_x, n_h))\n",
    "w_out = np.random.normal(loc = 0, scale = stdev2, size = (n_h + 1, n_o))\n",
    "\n",
    "###\n",
    "#parameters\n",
    "num_iterations = 200\n",
    "eta = 1e-5\n",
    "alpha = 0.9\n",
    "\n",
    "###\n",
    "\n",
    "#time start\n",
    "time_start = time.time()\n",
    "\n",
    "#def network_training(Data, Target,\n",
    "#                    w_hid, w_out, \n",
    "#                     iterations, learning_rate, alpha,  \n",
    "#                     v_out, v_hid):\n",
    "\n",
    "#train the network\n",
    "accuracy_train, accuracy_valid, accuracy_test, dw_out, dw_hid, loss_train, loss_valid, loss_test = network_training(data_in, target_in,\n",
    "                                                                     w_hid, w_out, \n",
    "                                                                     num_iterations, eta, alpha, 1e-5, 1e-5)\n",
    "#time stop\n",
    "time_stop = time.time()\n",
    "\n",
    "#print time it took\n",
    "print(\"Training Time: {}mins\".format((time_stop - time_start) / 60))\n",
    "\n",
    "#plot accuracy\n",
    "plt.figure()\n",
    "plt.subplot(211)\n",
    "plt.plot(accuracy_train)\n",
    "plt.plot(accuracy_valid)\n",
    "plt.plot(accuracy_test)\n",
    "\n",
    "acc_legend = plt.legend([accuracy_train, accuracy_valid, accuracy_test], [\"Train Acc.\", \"Valid Acc.\", \"Test Acc.\"])\n",
    "plt.title(\"Accuracy vs. Iterations\")\n",
    "plt.xlabel(\"Number of Iterations\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "\n",
    "#plot loss\n",
    "plt.subplot(212)\n",
    "plt.plot(loss_train)\n",
    "plt.plot(loss_valid)\n",
    "plt.plot(loss_test)\n",
    "\n",
    "loss_legend = plt.legend([loss_train, loss_valid, loss_test], [\"Train Loss\", \"Valid Loss\", \"Test Loss\"])\n",
    "plt.title(\"Loss vs. Iterations\")\n",
    "plt.xlabel(\"Number of Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()\n",
    "\n",
    "#1000 hidden units\n",
    "#9 output nodes\n",
    "#in_nodes = len(trainData) + 1\n",
    "#out_nodes = 10\n",
    "\n",
    "#200 epochs\n",
    "#alpha = 0.9\n",
    "#eta = 0.1 #10**-5 \n",
    "#num_iterations = 200\n",
    "#hidden_units = 1000\n",
    "\n",
    "########FIX THE FUNCTION INPUT PARAMETERS - DO THIS LATER\n",
    "#######PUT WEIGHTS INTO FUNCTION, INIT IN THIS BLOCK\n",
    "#######PLOT THE TRAINING AND VALIDATION AND TEST ACCURACY CURVES\n",
    "#RUN THE MODEL ON ALL 3 DATA SETS\n",
    "#PLOT ACCURACY CURVES AND STATE THE ACCURACIES\n",
    "\n",
    "#PLOT THE ACCURACY TOTAL, WHICH IS RETURNED FROM TRAINNEURALNETWORK FUNCT\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "de33f35d8e38fe8607e30cc83fc7146c",
     "grade": true,
     "grade_id": "cell-71e0b1ff4567d3c3",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "Answer:\n",
    "\n",
    "On final iteration #200:\n",
    "\n",
    "- Training Accuracy: 98.01333333333334 %\n",
    "\n",
    "- Validation Accuracy: 93.30000000000001 %\n",
    "\n",
    "- Testing Accuracy: 92.1071953010279 %\n",
    "\n",
    "- Total Training Time: 16.823159102598826 mins\n",
    "\n",
    "- Train Loss: 1.5173 || Validation Loss: 1.5509 || Test Loss: 1.5590\n",
    "\n",
    "Output:\n",
    "\n",
    "Epoch: 199 of 200 || Train Accuracy: 98.0133 % || Validation Accuracy: 93.3000 % || Test Accuracy: 92.1071 %\n",
    "Train Loss: 1.5173 || Validation Loss: 1.5509  || Test Loss: 1.5590\n",
    "     \n",
    "*Note: Epoch reported is 199 simply because of printing the index without adding 1 since index starts at 0.\n",
    "#########################\n",
    "\n",
    "\n",
    "\n",
    "Network test accuracy graph from when running network training locally: \n",
    "\n",
    "Accuracy vs. Number of Iterations\n",
    "\n",
    "Please refer to the graph in the submission repository if graph is not displaying here.\n",
    "\n",
    "![network_test_accuracy_graph](\"network_test_accuracy_graph.png\")\n",
    "(network_test_accuracy_graph.png)\n",
    "\n",
    "Diagram: https://drive.google.com/open?id=1FcuI_fPbn-HNXMJPpNSjg4ZNyNfTC_dZ\n",
    "\n",
    "Google Drive for Diagrams: https://drive.google.com/open?id=1hVfllsCnZKxbo9pf_uatfMKBwXMyhV4W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3855c5efdf7fd347c49f1ab4e3c482f6",
     "grade": false,
     "grade_id": "cell-bfd49bf15d3f0b3e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Hyperparameter investigation [3 points]\n",
    "\n",
    "Continue to use $\\alpha=0.9$ and $\\eta=10^{-5}$.\n",
    "\n",
    "Test your network with 500, 1500, 2500 hidden nodes and train for 200 epochs. Comment based on the validation accuracy after how many epochs training could be terminated early. \n",
    "\n",
    "Plot the training and validation accuracy curves for all three network sizes and 200 training epochs, and report the test accuracy for your selected network size and training length. Show the plot and the accuracies in the next markdown cell.\n",
    "\n",
    "(Training of the large network for 200 epochs should take about 30-60 mins.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8adf631ac20e85951543db6f7602e0c5",
     "grade": true,
     "grade_id": "cell-166556fcc63e2168",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### TRAINING BEGINNING #######\n",
      "     \n",
      "Epoch: 0 of 200 || Train Accuracy: 9.4533 % || Validation Accuracy: 26.6000 % || Test Accuracy: 29.2952 %\n",
      "Train Loss: 2.3070 || Validation Loss: 2.2441 || Test Loss: 2.2389\n",
      "     \n",
      "Epoch: 1 of 200 || Train Accuracy: 27.2267 % || Validation Accuracy: 61.8000 % || Test Accuracy: 62.9222 %\n",
      "Train Loss: 2.2429 || Validation Loss: 2.0904 || Test Loss: 2.0814\n",
      "     \n",
      "Epoch: 2 of 200 || Train Accuracy: 62.2800 % || Validation Accuracy: 70.0000 % || Test Accuracy: 72.0999 %\n",
      "Train Loss: 2.0840 || Validation Loss: 1.9600 || Test Loss: 1.9452\n",
      "     \n",
      "Epoch: 3 of 200 || Train Accuracy: 71.4600 % || Validation Accuracy: 75.7000 % || Test Accuracy: 75.8811 %\n",
      "Train Loss: 1.9528 || Validation Loss: 1.8582 || Test Loss: 1.8520\n",
      "     \n",
      "Epoch: 4 of 200 || Train Accuracy: 75.3067 % || Validation Accuracy: 78.1000 % || Test Accuracy: 78.8913 %\n",
      "Train Loss: 1.8556 || Validation Loss: 1.7839 || Test Loss: 1.7766\n",
      "     \n",
      "Epoch: 5 of 200 || Train Accuracy: 78.7133 % || Validation Accuracy: 84.6000 % || Test Accuracy: 85.3891 %\n",
      "Train Loss: 1.7795 || Validation Loss: 1.7085 || Test Loss: 1.6971\n",
      "     \n",
      "Epoch: 6 of 200 || Train Accuracy: 84.1600 % || Validation Accuracy: 80.4000 % || Test Accuracy: 81.9750 %\n",
      "Train Loss: 1.7046 || Validation Loss: 1.7206 || Test Loss: 1.7030\n",
      "     \n",
      "Epoch: 7 of 200 || Train Accuracy: 81.0933 % || Validation Accuracy: 84.7000 % || Test Accuracy: 85.9031 %\n",
      "Train Loss: 1.7108 || Validation Loss: 1.6600 || Test Loss: 1.6538\n",
      "     \n",
      "Epoch: 8 of 200 || Train Accuracy: 85.0667 % || Validation Accuracy: 83.7000 % || Test Accuracy: 84.1777 %\n",
      "Train Loss: 1.6581 || Validation Loss: 1.6589 || Test Loss: 1.6589\n",
      "     \n",
      "Epoch: 9 of 200 || Train Accuracy: 83.9133 % || Validation Accuracy: 86.1000 % || Test Accuracy: 86.1233 %\n",
      "Train Loss: 1.6607 || Validation Loss: 1.6356 || Test Loss: 1.6361\n",
      "     \n",
      "Epoch: 10 of 200 || Train Accuracy: 85.7200 % || Validation Accuracy: 85.3000 % || Test Accuracy: 86.4537 %\n",
      "Train Loss: 1.6390 || Validation Loss: 1.6368 || Test Loss: 1.6309\n",
      "     \n",
      "Epoch: 11 of 200 || Train Accuracy: 86.0933 % || Validation Accuracy: 86.6000 % || Test Accuracy: 86.4170 %\n",
      "Train Loss: 1.6353 || Validation Loss: 1.6317 || Test Loss: 1.6263\n",
      "     \n",
      "Epoch: 12 of 200 || Train Accuracy: 86.0467 % || Validation Accuracy: 85.8000 % || Test Accuracy: 86.1601 %\n",
      "Train Loss: 1.6310 || Validation Loss: 1.6268 || Test Loss: 1.6226\n",
      "     \n",
      "Epoch: 13 of 200 || Train Accuracy: 86.0133 % || Validation Accuracy: 86.3000 % || Test Accuracy: 87.0411 %\n",
      "Train Loss: 1.6250 || Validation Loss: 1.6198 || Test Loss: 1.6167\n",
      "     \n",
      "Epoch: 14 of 200 || Train Accuracy: 86.8600 % || Validation Accuracy: 87.1000 % || Test Accuracy: 88.2159 %\n",
      "Train Loss: 1.6182 || Validation Loss: 1.6150 || Test Loss: 1.6136\n",
      "     \n",
      "Epoch: 15 of 200 || Train Accuracy: 87.6000 % || Validation Accuracy: 87.6000 % || Test Accuracy: 88.0323 %\n",
      "Train Loss: 1.6137 || Validation Loss: 1.6183 || Test Loss: 1.6222\n",
      "     \n",
      "Epoch: 16 of 200 || Train Accuracy: 87.6467 % || Validation Accuracy: 88.3000 % || Test Accuracy: 88.0690 %\n",
      "Train Loss: 1.6208 || Validation Loss: 1.6139 || Test Loss: 1.6203\n",
      "     \n",
      "Epoch: 17 of 200 || Train Accuracy: 87.6467 % || Validation Accuracy: 88.1000 % || Test Accuracy: 88.3627 %\n",
      "Train Loss: 1.6184 || Validation Loss: 1.6076 || Test Loss: 1.6116\n",
      "     \n",
      "Epoch: 18 of 200 || Train Accuracy: 88.0133 % || Validation Accuracy: 88.0000 % || Test Accuracy: 88.3994 %\n",
      "Train Loss: 1.6093 || Validation Loss: 1.6099 || Test Loss: 1.6103\n",
      "     \n",
      "Epoch: 19 of 200 || Train Accuracy: 88.1000 % || Validation Accuracy: 88.1000 % || Test Accuracy: 88.5830 %\n",
      "Train Loss: 1.6087 || Validation Loss: 1.6159 || Test Loss: 1.6142\n",
      "     \n",
      "Epoch: 20 of 200 || Train Accuracy: 88.1667 % || Validation Accuracy: 87.3000 % || Test Accuracy: 88.7665 %\n",
      "Train Loss: 1.6132 || Validation Loss: 1.6229 || Test Loss: 1.6195\n",
      "     \n",
      "Epoch: 21 of 200 || Train Accuracy: 88.3200 % || Validation Accuracy: 88.3000 % || Test Accuracy: 89.0602 %\n",
      "Train Loss: 1.6190 || Validation Loss: 1.6190 || Test Loss: 1.6168\n",
      "     \n",
      "Epoch: 22 of 200 || Train Accuracy: 88.8000 % || Validation Accuracy: 88.1000 % || Test Accuracy: 88.9134 %\n",
      "Train Loss: 1.6156 || Validation Loss: 1.6162 || Test Loss: 1.6165\n",
      "     \n",
      "Epoch: 23 of 200 || Train Accuracy: 88.9267 % || Validation Accuracy: 87.9000 % || Test Accuracy: 88.9868 %\n",
      "Train Loss: 1.6144 || Validation Loss: 1.6171 || Test Loss: 1.6207\n",
      "     \n",
      "Epoch: 24 of 200 || Train Accuracy: 89.0400 % || Validation Accuracy: 89.7000 % || Test Accuracy: 88.8399 %\n",
      "Train Loss: 1.6173 || Validation Loss: 1.6172 || Test Loss: 1.6237\n",
      "     \n",
      "Epoch: 25 of 200 || Train Accuracy: 89.3400 % || Validation Accuracy: 89.9000 % || Test Accuracy: 89.2070 %\n",
      "Train Loss: 1.6195 || Validation Loss: 1.6186 || Test Loss: 1.6254\n",
      "     \n",
      "Epoch: 26 of 200 || Train Accuracy: 89.5600 % || Validation Accuracy: 90.7000 % || Test Accuracy: 89.6109 %\n",
      "Train Loss: 1.6215 || Validation Loss: 1.6142 || Test Loss: 1.6200\n",
      "     \n",
      "Epoch: 27 of 200 || Train Accuracy: 89.9000 % || Validation Accuracy: 89.6000 % || Test Accuracy: 89.6109 %\n",
      "Train Loss: 1.6165 || Validation Loss: 1.6117 || Test Loss: 1.6153\n",
      "     \n",
      "Epoch: 28 of 200 || Train Accuracy: 89.9133 % || Validation Accuracy: 89.4000 % || Test Accuracy: 89.6843 %\n",
      "Train Loss: 1.6123 || Validation Loss: 1.6115 || Test Loss: 1.6134\n",
      "     \n",
      "Epoch: 29 of 200 || Train Accuracy: 89.8200 % || Validation Accuracy: 89.4000 % || Test Accuracy: 89.5007 %\n",
      "Train Loss: 1.6107 || Validation Loss: 1.6104 || Test Loss: 1.6114\n",
      "     \n",
      "Epoch: 30 of 200 || Train Accuracy: 89.9267 % || Validation Accuracy: 89.9000 % || Test Accuracy: 89.5742 %\n",
      "Train Loss: 1.6088 || Validation Loss: 1.6086 || Test Loss: 1.6094\n",
      "     \n",
      "Epoch: 31 of 200 || Train Accuracy: 90.1133 % || Validation Accuracy: 90.4000 % || Test Accuracy: 89.9046 %\n",
      "Train Loss: 1.6067 || Validation Loss: 1.6063 || Test Loss: 1.6074\n",
      "     \n",
      "Epoch: 32 of 200 || Train Accuracy: 90.2333 % || Validation Accuracy: 90.5000 % || Test Accuracy: 90.0881 %\n",
      "Train Loss: 1.6042 || Validation Loss: 1.6026 || Test Loss: 1.6048\n",
      "     \n",
      "Epoch: 33 of 200 || Train Accuracy: 90.4333 % || Validation Accuracy: 90.3000 % || Test Accuracy: 89.9413 %\n",
      "Train Loss: 1.6009 || Validation Loss: 1.5988 || Test Loss: 1.6023\n",
      "     \n",
      "Epoch: 34 of 200 || Train Accuracy: 90.4600 % || Validation Accuracy: 90.5000 % || Test Accuracy: 89.9780 %\n",
      "Train Loss: 1.5977 || Validation Loss: 1.5963 || Test Loss: 1.6010\n",
      "     \n",
      "Epoch: 35 of 200 || Train Accuracy: 90.5133 % || Validation Accuracy: 90.2000 % || Test Accuracy: 90.0881 %\n",
      "Train Loss: 1.5957 || Validation Loss: 1.5943 || Test Loss: 1.6000\n",
      "     \n",
      "Epoch: 36 of 200 || Train Accuracy: 90.6333 % || Validation Accuracy: 90.5000 % || Test Accuracy: 90.0147 %\n",
      "Train Loss: 1.5943 || Validation Loss: 1.5925 || Test Loss: 1.5987\n",
      "     \n",
      "Epoch: 37 of 200 || Train Accuracy: 90.8800 % || Validation Accuracy: 90.7000 % || Test Accuracy: 90.1615 %\n",
      "Train Loss: 1.5927 || Validation Loss: 1.5911 || Test Loss: 1.5971\n",
      "     \n",
      "Epoch: 38 of 200 || Train Accuracy: 91.0600 % || Validation Accuracy: 90.9000 % || Test Accuracy: 90.3084 %\n",
      "Train Loss: 1.5910 || Validation Loss: 1.5902 || Test Loss: 1.5955\n",
      "     \n",
      "Epoch: 39 of 200 || Train Accuracy: 91.0867 % || Validation Accuracy: 90.9000 % || Test Accuracy: 90.4185 %\n",
      "Train Loss: 1.5893 || Validation Loss: 1.5897 || Test Loss: 1.5941\n",
      "     \n",
      "Epoch: 40 of 200 || Train Accuracy: 91.1000 % || Validation Accuracy: 90.7000 % || Test Accuracy: 90.3451 %\n",
      "Train Loss: 1.5879 || Validation Loss: 1.5898 || Test Loss: 1.5932\n",
      "     \n",
      "Epoch: 41 of 200 || Train Accuracy: 91.0800 % || Validation Accuracy: 90.4000 % || Test Accuracy: 90.3084 %\n",
      "Train Loss: 1.5871 || Validation Loss: 1.5899 || Test Loss: 1.5927\n",
      "     \n",
      "Epoch: 42 of 200 || Train Accuracy: 91.0800 % || Validation Accuracy: 90.5000 % || Test Accuracy: 90.6021 %\n",
      "Train Loss: 1.5867 || Validation Loss: 1.5895 || Test Loss: 1.5924\n",
      "     \n",
      "Epoch: 43 of 200 || Train Accuracy: 91.1533 % || Validation Accuracy: 90.8000 % || Test Accuracy: 90.5286 %\n",
      "Train Loss: 1.5861 || Validation Loss: 1.5885 || Test Loss: 1.5921\n",
      "     \n",
      "Epoch: 44 of 200 || Train Accuracy: 91.3000 % || Validation Accuracy: 91.1000 % || Test Accuracy: 90.6021 %\n",
      "Train Loss: 1.5854 || Validation Loss: 1.5874 || Test Loss: 1.5920\n",
      "     \n",
      "Epoch: 45 of 200 || Train Accuracy: 91.5000 % || Validation Accuracy: 91.2000 % || Test Accuracy: 90.7489 %\n",
      "Train Loss: 1.5847 || Validation Loss: 1.5866 || Test Loss: 1.5921\n",
      "     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46 of 200 || Train Accuracy: 91.6133 % || Validation Accuracy: 91.4000 % || Test Accuracy: 90.6388 %\n",
      "Train Loss: 1.5842 || Validation Loss: 1.5859 || Test Loss: 1.5922\n",
      "     \n",
      "Epoch: 47 of 200 || Train Accuracy: 91.7200 % || Validation Accuracy: 91.6000 % || Test Accuracy: 90.6021 %\n",
      "Train Loss: 1.5840 || Validation Loss: 1.5855 || Test Loss: 1.5921\n",
      "     \n",
      "Epoch: 48 of 200 || Train Accuracy: 91.8067 % || Validation Accuracy: 91.5000 % || Test Accuracy: 90.7856 %\n",
      "Train Loss: 1.5836 || Validation Loss: 1.5851 || Test Loss: 1.5916\n",
      "     \n",
      "Epoch: 49 of 200 || Train Accuracy: 91.8267 % || Validation Accuracy: 91.4000 % || Test Accuracy: 90.8957 %\n",
      "Train Loss: 1.5830 || Validation Loss: 1.5849 || Test Loss: 1.5911\n",
      "     \n",
      "Epoch: 50 of 200 || Train Accuracy: 91.8600 % || Validation Accuracy: 91.4000 % || Test Accuracy: 90.8957 %\n",
      "Train Loss: 1.5824 || Validation Loss: 1.5848 || Test Loss: 1.5905\n",
      "     \n",
      "Epoch: 51 of 200 || Train Accuracy: 91.9133 % || Validation Accuracy: 91.5000 % || Test Accuracy: 90.8957 %\n",
      "Train Loss: 1.5818 || Validation Loss: 1.5848 || Test Loss: 1.5901\n",
      "     \n",
      "Epoch: 52 of 200 || Train Accuracy: 91.9600 % || Validation Accuracy: 91.5000 % || Test Accuracy: 90.8223 %\n",
      "Train Loss: 1.5813 || Validation Loss: 1.5846 || Test Loss: 1.5897\n",
      "     \n",
      "Epoch: 53 of 200 || Train Accuracy: 92.1000 % || Validation Accuracy: 91.5000 % || Test Accuracy: 90.7489 %\n",
      "Train Loss: 1.5806 || Validation Loss: 1.5842 || Test Loss: 1.5893\n",
      "     \n",
      "Epoch: 54 of 200 || Train Accuracy: 92.1333 % || Validation Accuracy: 91.6000 % || Test Accuracy: 90.7856 %\n",
      "Train Loss: 1.5799 || Validation Loss: 1.5837 || Test Loss: 1.5888\n",
      "     \n",
      "Epoch: 55 of 200 || Train Accuracy: 92.1800 % || Validation Accuracy: 91.5000 % || Test Accuracy: 90.8957 %\n",
      "Train Loss: 1.5791 || Validation Loss: 1.5829 || Test Loss: 1.5882\n",
      "     \n",
      "Epoch: 56 of 200 || Train Accuracy: 92.3267 % || Validation Accuracy: 91.6000 % || Test Accuracy: 91.0793 %\n",
      "Train Loss: 1.5782 || Validation Loss: 1.5822 || Test Loss: 1.5877\n",
      "     \n",
      "Epoch: 57 of 200 || Train Accuracy: 92.3000 % || Validation Accuracy: 91.6000 % || Test Accuracy: 91.1160 %\n",
      "Train Loss: 1.5775 || Validation Loss: 1.5815 || Test Loss: 1.5872\n",
      "     \n",
      "Epoch: 58 of 200 || Train Accuracy: 92.4200 % || Validation Accuracy: 91.7000 % || Test Accuracy: 90.9692 %\n",
      "Train Loss: 1.5768 || Validation Loss: 1.5807 || Test Loss: 1.5868\n",
      "     \n",
      "Epoch: 59 of 200 || Train Accuracy: 92.4600 % || Validation Accuracy: 91.7000 % || Test Accuracy: 91.0059 %\n",
      "Train Loss: 1.5761 || Validation Loss: 1.5800 || Test Loss: 1.5863\n",
      "     \n",
      "Epoch: 60 of 200 || Train Accuracy: 92.4800 % || Validation Accuracy: 91.9000 % || Test Accuracy: 90.9325 %\n",
      "Train Loss: 1.5754 || Validation Loss: 1.5794 || Test Loss: 1.5857\n",
      "     \n",
      "Epoch: 61 of 200 || Train Accuracy: 92.4933 % || Validation Accuracy: 91.9000 % || Test Accuracy: 91.0059 %\n",
      "Train Loss: 1.5746 || Validation Loss: 1.5789 || Test Loss: 1.5851\n",
      "     \n",
      "Epoch: 62 of 200 || Train Accuracy: 92.5467 % || Validation Accuracy: 91.8000 % || Test Accuracy: 91.0059 %\n",
      "Train Loss: 1.5738 || Validation Loss: 1.5787 || Test Loss: 1.5846\n",
      "     \n",
      "Epoch: 63 of 200 || Train Accuracy: 92.6467 % || Validation Accuracy: 91.6000 % || Test Accuracy: 90.9692 %\n",
      "Train Loss: 1.5732 || Validation Loss: 1.5785 || Test Loss: 1.5841\n",
      "     \n",
      "Epoch: 64 of 200 || Train Accuracy: 92.6600 % || Validation Accuracy: 91.6000 % || Test Accuracy: 91.0059 %\n",
      "Train Loss: 1.5726 || Validation Loss: 1.5783 || Test Loss: 1.5837\n",
      "     \n",
      "Epoch: 65 of 200 || Train Accuracy: 92.6867 % || Validation Accuracy: 91.6000 % || Test Accuracy: 91.0059 %\n",
      "Train Loss: 1.5721 || Validation Loss: 1.5780 || Test Loss: 1.5833\n",
      "     \n",
      "Epoch: 66 of 200 || Train Accuracy: 92.7400 % || Validation Accuracy: 91.6000 % || Test Accuracy: 90.8957 %\n",
      "Train Loss: 1.5715 || Validation Loss: 1.5776 || Test Loss: 1.5830\n",
      "     \n",
      "Epoch: 67 of 200 || Train Accuracy: 92.7800 % || Validation Accuracy: 91.6000 % || Test Accuracy: 90.8957 %\n",
      "Train Loss: 1.5709 || Validation Loss: 1.5771 || Test Loss: 1.5827\n",
      "     \n",
      "Epoch: 68 of 200 || Train Accuracy: 92.8533 % || Validation Accuracy: 91.7000 % || Test Accuracy: 90.9325 %\n",
      "Train Loss: 1.5704 || Validation Loss: 1.5766 || Test Loss: 1.5825\n",
      "     \n",
      "Epoch: 69 of 200 || Train Accuracy: 92.9000 % || Validation Accuracy: 91.7000 % || Test Accuracy: 90.9692 %\n",
      "Train Loss: 1.5699 || Validation Loss: 1.5762 || Test Loss: 1.5823\n",
      "     \n",
      "Epoch: 70 of 200 || Train Accuracy: 93.0000 % || Validation Accuracy: 91.9000 % || Test Accuracy: 90.9692 %\n",
      "Train Loss: 1.5694 || Validation Loss: 1.5759 || Test Loss: 1.5821\n",
      "     \n",
      "Epoch: 71 of 200 || Train Accuracy: 93.0667 % || Validation Accuracy: 91.9000 % || Test Accuracy: 90.9692 %\n",
      "Train Loss: 1.5690 || Validation Loss: 1.5756 || Test Loss: 1.5819\n",
      "     \n",
      "Epoch: 72 of 200 || Train Accuracy: 93.0867 % || Validation Accuracy: 91.8000 % || Test Accuracy: 91.0059 %\n",
      "Train Loss: 1.5686 || Validation Loss: 1.5754 || Test Loss: 1.5816\n",
      "     \n",
      "Epoch: 73 of 200 || Train Accuracy: 93.1333 % || Validation Accuracy: 91.7000 % || Test Accuracy: 91.0793 %\n",
      "Train Loss: 1.5681 || Validation Loss: 1.5752 || Test Loss: 1.5814\n",
      "     \n",
      "Epoch: 74 of 200 || Train Accuracy: 93.1867 % || Validation Accuracy: 91.7000 % || Test Accuracy: 91.0426 %\n",
      "Train Loss: 1.5677 || Validation Loss: 1.5751 || Test Loss: 1.5812\n",
      "     \n",
      "Epoch: 75 of 200 || Train Accuracy: 93.2733 % || Validation Accuracy: 91.6000 % || Test Accuracy: 91.0059 %\n",
      "Train Loss: 1.5672 || Validation Loss: 1.5749 || Test Loss: 1.5810\n",
      "     \n",
      "Epoch: 76 of 200 || Train Accuracy: 93.3000 % || Validation Accuracy: 91.5000 % || Test Accuracy: 90.9692 %\n",
      "Train Loss: 1.5668 || Validation Loss: 1.5747 || Test Loss: 1.5808\n",
      "     \n",
      "Epoch: 77 of 200 || Train Accuracy: 93.3667 % || Validation Accuracy: 91.5000 % || Test Accuracy: 90.8957 %\n",
      "Train Loss: 1.5664 || Validation Loss: 1.5745 || Test Loss: 1.5806\n",
      "     \n",
      "Epoch: 78 of 200 || Train Accuracy: 93.4000 % || Validation Accuracy: 91.5000 % || Test Accuracy: 90.9325 %\n",
      "Train Loss: 1.5660 || Validation Loss: 1.5742 || Test Loss: 1.5803\n",
      "     \n",
      "Epoch: 79 of 200 || Train Accuracy: 93.4333 % || Validation Accuracy: 91.8000 % || Test Accuracy: 90.9692 %\n",
      "Train Loss: 1.5655 || Validation Loss: 1.5739 || Test Loss: 1.5801\n",
      "     \n",
      "Epoch: 80 of 200 || Train Accuracy: 93.4733 % || Validation Accuracy: 91.8000 % || Test Accuracy: 90.9692 %\n",
      "Train Loss: 1.5650 || Validation Loss: 1.5735 || Test Loss: 1.5799\n",
      "     \n",
      "Epoch: 81 of 200 || Train Accuracy: 93.5333 % || Validation Accuracy: 91.8000 % || Test Accuracy: 90.9692 %\n",
      "Train Loss: 1.5645 || Validation Loss: 1.5732 || Test Loss: 1.5797\n",
      "     \n",
      "Epoch: 82 of 200 || Train Accuracy: 93.6000 % || Validation Accuracy: 91.8000 % || Test Accuracy: 90.9325 %\n",
      "Train Loss: 1.5641 || Validation Loss: 1.5728 || Test Loss: 1.5795\n",
      "     \n",
      "Epoch: 83 of 200 || Train Accuracy: 93.6200 % || Validation Accuracy: 91.8000 % || Test Accuracy: 90.9325 %\n",
      "Train Loss: 1.5636 || Validation Loss: 1.5725 || Test Loss: 1.5792\n",
      "     \n",
      "Epoch: 84 of 200 || Train Accuracy: 93.6800 % || Validation Accuracy: 91.8000 % || Test Accuracy: 90.9692 %\n",
      "Train Loss: 1.5632 || Validation Loss: 1.5723 || Test Loss: 1.5789\n",
      "     \n",
      "Epoch: 85 of 200 || Train Accuracy: 93.7000 % || Validation Accuracy: 91.8000 % || Test Accuracy: 90.9692 %\n",
      "Train Loss: 1.5627 || Validation Loss: 1.5720 || Test Loss: 1.5787\n",
      "     \n",
      "Epoch: 86 of 200 || Train Accuracy: 93.7600 % || Validation Accuracy: 91.9000 % || Test Accuracy: 91.0059 %\n",
      "Train Loss: 1.5622 || Validation Loss: 1.5718 || Test Loss: 1.5784\n",
      "     \n",
      "Epoch: 87 of 200 || Train Accuracy: 93.8067 % || Validation Accuracy: 91.9000 % || Test Accuracy: 91.0426 %\n",
      "Train Loss: 1.5618 || Validation Loss: 1.5715 || Test Loss: 1.5781\n",
      "     \n",
      "Epoch: 88 of 200 || Train Accuracy: 93.8467 % || Validation Accuracy: 92.0000 % || Test Accuracy: 91.1160 %\n",
      "Train Loss: 1.5613 || Validation Loss: 1.5712 || Test Loss: 1.5779\n",
      "     \n",
      "Epoch: 89 of 200 || Train Accuracy: 93.9000 % || Validation Accuracy: 92.0000 % || Test Accuracy: 91.0793 %\n",
      "Train Loss: 1.5608 || Validation Loss: 1.5709 || Test Loss: 1.5777\n",
      "     \n",
      "Epoch: 90 of 200 || Train Accuracy: 93.9400 % || Validation Accuracy: 92.1000 % || Test Accuracy: 91.1160 %\n",
      "Train Loss: 1.5604 || Validation Loss: 1.5706 || Test Loss: 1.5775\n",
      "     \n",
      "Epoch: 91 of 200 || Train Accuracy: 93.9733 % || Validation Accuracy: 92.0000 % || Test Accuracy: 91.1894 %\n",
      "Train Loss: 1.5599 || Validation Loss: 1.5704 || Test Loss: 1.5773\n",
      "     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 92 of 200 || Train Accuracy: 94.0000 % || Validation Accuracy: 92.0000 % || Test Accuracy: 91.2261 %\n",
      "Train Loss: 1.5595 || Validation Loss: 1.5701 || Test Loss: 1.5771\n",
      "     \n",
      "Epoch: 93 of 200 || Train Accuracy: 94.0600 % || Validation Accuracy: 92.0000 % || Test Accuracy: 91.2261 %\n",
      "Train Loss: 1.5591 || Validation Loss: 1.5699 || Test Loss: 1.5769\n",
      "     \n",
      "Epoch: 94 of 200 || Train Accuracy: 94.1000 % || Validation Accuracy: 92.0000 % || Test Accuracy: 91.2261 %\n",
      "Train Loss: 1.5587 || Validation Loss: 1.5696 || Test Loss: 1.5767\n",
      "     \n",
      "Epoch: 95 of 200 || Train Accuracy: 94.1333 % || Validation Accuracy: 92.1000 % || Test Accuracy: 91.2261 %\n",
      "Train Loss: 1.5583 || Validation Loss: 1.5694 || Test Loss: 1.5765\n",
      "     \n",
      "Epoch: 96 of 200 || Train Accuracy: 94.1800 % || Validation Accuracy: 92.1000 % || Test Accuracy: 91.2261 %\n",
      "Train Loss: 1.5578 || Validation Loss: 1.5692 || Test Loss: 1.5764\n",
      "     \n",
      "Epoch: 97 of 200 || Train Accuracy: 94.1867 % || Validation Accuracy: 92.1000 % || Test Accuracy: 91.2261 %\n",
      "Train Loss: 1.5574 || Validation Loss: 1.5690 || Test Loss: 1.5762\n",
      "     \n",
      "Epoch: 98 of 200 || Train Accuracy: 94.2533 % || Validation Accuracy: 92.2000 % || Test Accuracy: 91.2261 %\n",
      "Train Loss: 1.5570 || Validation Loss: 1.5688 || Test Loss: 1.5760\n",
      "     \n",
      "Epoch: 99 of 200 || Train Accuracy: 94.2933 % || Validation Accuracy: 92.2000 % || Test Accuracy: 91.2261 %\n",
      "Train Loss: 1.5566 || Validation Loss: 1.5686 || Test Loss: 1.5758\n",
      "     \n",
      "Epoch: 100 of 200 || Train Accuracy: 94.3067 % || Validation Accuracy: 92.2000 % || Test Accuracy: 91.2261 %\n",
      "Train Loss: 1.5562 || Validation Loss: 1.5684 || Test Loss: 1.5756\n",
      "     \n",
      "Epoch: 101 of 200 || Train Accuracy: 94.3667 % || Validation Accuracy: 92.2000 % || Test Accuracy: 91.2261 %\n",
      "Train Loss: 1.5558 || Validation Loss: 1.5681 || Test Loss: 1.5754\n",
      "     \n",
      "Epoch: 102 of 200 || Train Accuracy: 94.3733 % || Validation Accuracy: 92.2000 % || Test Accuracy: 91.2261 %\n",
      "Train Loss: 1.5554 || Validation Loss: 1.5679 || Test Loss: 1.5752\n",
      "     \n",
      "Epoch: 103 of 200 || Train Accuracy: 94.3800 % || Validation Accuracy: 92.3000 % || Test Accuracy: 91.2261 %\n",
      "Train Loss: 1.5550 || Validation Loss: 1.5676 || Test Loss: 1.5750\n",
      "     \n",
      "Epoch: 104 of 200 || Train Accuracy: 94.4400 % || Validation Accuracy: 92.3000 % || Test Accuracy: 91.2261 %\n",
      "Train Loss: 1.5545 || Validation Loss: 1.5674 || Test Loss: 1.5749\n",
      "     \n",
      "Epoch: 105 of 200 || Train Accuracy: 94.4600 % || Validation Accuracy: 92.3000 % || Test Accuracy: 91.2996 %\n",
      "Train Loss: 1.5541 || Validation Loss: 1.5672 || Test Loss: 1.5747\n",
      "     \n",
      "Epoch: 106 of 200 || Train Accuracy: 94.4933 % || Validation Accuracy: 92.3000 % || Test Accuracy: 91.2996 %\n",
      "Train Loss: 1.5537 || Validation Loss: 1.5670 || Test Loss: 1.5745\n",
      "     \n",
      "Epoch: 107 of 200 || Train Accuracy: 94.5467 % || Validation Accuracy: 92.3000 % || Test Accuracy: 91.2996 %\n",
      "Train Loss: 1.5533 || Validation Loss: 1.5667 || Test Loss: 1.5743\n",
      "     \n",
      "Epoch: 108 of 200 || Train Accuracy: 94.5733 % || Validation Accuracy: 92.3000 % || Test Accuracy: 91.2996 %\n",
      "Train Loss: 1.5529 || Validation Loss: 1.5665 || Test Loss: 1.5741\n",
      "     \n",
      "Epoch: 109 of 200 || Train Accuracy: 94.6067 % || Validation Accuracy: 92.3000 % || Test Accuracy: 91.2996 %\n",
      "Train Loss: 1.5525 || Validation Loss: 1.5663 || Test Loss: 1.5739\n",
      "     \n",
      "Epoch: 110 of 200 || Train Accuracy: 94.6467 % || Validation Accuracy: 92.3000 % || Test Accuracy: 91.3730 %\n",
      "Train Loss: 1.5521 || Validation Loss: 1.5660 || Test Loss: 1.5737\n",
      "     \n",
      "Epoch: 111 of 200 || Train Accuracy: 94.6667 % || Validation Accuracy: 92.3000 % || Test Accuracy: 91.4097 %\n",
      "Train Loss: 1.5517 || Validation Loss: 1.5658 || Test Loss: 1.5735\n",
      "     \n",
      "Epoch: 112 of 200 || Train Accuracy: 94.6867 % || Validation Accuracy: 92.3000 % || Test Accuracy: 91.3730 %\n",
      "Train Loss: 1.5513 || Validation Loss: 1.5656 || Test Loss: 1.5734\n",
      "     \n",
      "Epoch: 113 of 200 || Train Accuracy: 94.7200 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.3730 %\n",
      "Train Loss: 1.5509 || Validation Loss: 1.5654 || Test Loss: 1.5732\n",
      "     \n",
      "Epoch: 114 of 200 || Train Accuracy: 94.7600 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.3730 %\n",
      "Train Loss: 1.5505 || Validation Loss: 1.5652 || Test Loss: 1.5730\n",
      "     \n",
      "Epoch: 115 of 200 || Train Accuracy: 94.8200 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.3730 %\n",
      "Train Loss: 1.5501 || Validation Loss: 1.5650 || Test Loss: 1.5728\n",
      "     \n",
      "Epoch: 116 of 200 || Train Accuracy: 94.8667 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.3363 %\n",
      "Train Loss: 1.5497 || Validation Loss: 1.5648 || Test Loss: 1.5727\n",
      "     \n",
      "Epoch: 117 of 200 || Train Accuracy: 94.9000 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.3363 %\n",
      "Train Loss: 1.5493 || Validation Loss: 1.5646 || Test Loss: 1.5725\n",
      "     \n",
      "Epoch: 118 of 200 || Train Accuracy: 94.9533 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.4097 %\n",
      "Train Loss: 1.5489 || Validation Loss: 1.5644 || Test Loss: 1.5723\n",
      "     \n",
      "Epoch: 119 of 200 || Train Accuracy: 95.0067 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.4097 %\n",
      "Train Loss: 1.5486 || Validation Loss: 1.5642 || Test Loss: 1.5722\n",
      "     \n",
      "Epoch: 120 of 200 || Train Accuracy: 95.0400 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.4097 %\n",
      "Train Loss: 1.5482 || Validation Loss: 1.5640 || Test Loss: 1.5720\n",
      "     \n",
      "Epoch: 121 of 200 || Train Accuracy: 95.0533 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.4097 %\n",
      "Train Loss: 1.5478 || Validation Loss: 1.5638 || Test Loss: 1.5718\n",
      "     \n",
      "Epoch: 122 of 200 || Train Accuracy: 95.0600 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.4464 %\n",
      "Train Loss: 1.5474 || Validation Loss: 1.5636 || Test Loss: 1.5717\n",
      "     \n",
      "Epoch: 123 of 200 || Train Accuracy: 95.1067 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.4464 %\n",
      "Train Loss: 1.5470 || Validation Loss: 1.5634 || Test Loss: 1.5715\n",
      "     \n",
      "Epoch: 124 of 200 || Train Accuracy: 95.1267 % || Validation Accuracy: 92.7000 % || Test Accuracy: 91.4464 %\n",
      "Train Loss: 1.5466 || Validation Loss: 1.5632 || Test Loss: 1.5713\n",
      "     \n",
      "Epoch: 125 of 200 || Train Accuracy: 95.1467 % || Validation Accuracy: 92.7000 % || Test Accuracy: 91.4831 %\n",
      "Train Loss: 1.5463 || Validation Loss: 1.5631 || Test Loss: 1.5711\n",
      "     \n",
      "Epoch: 126 of 200 || Train Accuracy: 95.1933 % || Validation Accuracy: 92.8000 % || Test Accuracy: 91.4831 %\n",
      "Train Loss: 1.5459 || Validation Loss: 1.5629 || Test Loss: 1.5710\n",
      "     \n",
      "Epoch: 127 of 200 || Train Accuracy: 95.2400 % || Validation Accuracy: 92.8000 % || Test Accuracy: 91.4831 %\n",
      "Train Loss: 1.5455 || Validation Loss: 1.5627 || Test Loss: 1.5708\n",
      "     \n",
      "Epoch: 128 of 200 || Train Accuracy: 95.2800 % || Validation Accuracy: 92.8000 % || Test Accuracy: 91.5198 %\n",
      "Train Loss: 1.5451 || Validation Loss: 1.5625 || Test Loss: 1.5707\n",
      "     \n",
      "Epoch: 129 of 200 || Train Accuracy: 95.2867 % || Validation Accuracy: 92.8000 % || Test Accuracy: 91.4831 %\n",
      "Train Loss: 1.5448 || Validation Loss: 1.5623 || Test Loss: 1.5705\n",
      "     \n",
      "Epoch: 130 of 200 || Train Accuracy: 95.3400 % || Validation Accuracy: 92.8000 % || Test Accuracy: 91.4831 %\n",
      "Train Loss: 1.5444 || Validation Loss: 1.5621 || Test Loss: 1.5704\n",
      "     \n",
      "Epoch: 131 of 200 || Train Accuracy: 95.3800 % || Validation Accuracy: 92.8000 % || Test Accuracy: 91.5198 %\n",
      "Train Loss: 1.5440 || Validation Loss: 1.5620 || Test Loss: 1.5702\n",
      "     \n",
      "Epoch: 132 of 200 || Train Accuracy: 95.4200 % || Validation Accuracy: 92.7000 % || Test Accuracy: 91.4831 %\n",
      "Train Loss: 1.5437 || Validation Loss: 1.5618 || Test Loss: 1.5700\n",
      "     \n",
      "Epoch: 133 of 200 || Train Accuracy: 95.4533 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.4464 %\n",
      "Train Loss: 1.5433 || Validation Loss: 1.5616 || Test Loss: 1.5699\n",
      "     \n",
      "Epoch: 134 of 200 || Train Accuracy: 95.4733 % || Validation Accuracy: 92.5000 % || Test Accuracy: 91.4831 %\n",
      "Train Loss: 1.5430 || Validation Loss: 1.5615 || Test Loss: 1.5697\n",
      "     \n",
      "Epoch: 135 of 200 || Train Accuracy: 95.5067 % || Validation Accuracy: 92.5000 % || Test Accuracy: 91.4831 %\n",
      "Train Loss: 1.5426 || Validation Loss: 1.5613 || Test Loss: 1.5696\n",
      "     \n",
      "Epoch: 136 of 200 || Train Accuracy: 95.5600 % || Validation Accuracy: 92.5000 % || Test Accuracy: 91.4831 %\n",
      "Train Loss: 1.5422 || Validation Loss: 1.5611 || Test Loss: 1.5695\n",
      "     \n",
      "Epoch: 137 of 200 || Train Accuracy: 95.5933 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.4464 %\n",
      "Train Loss: 1.5419 || Validation Loss: 1.5610 || Test Loss: 1.5693\n",
      "     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 138 of 200 || Train Accuracy: 95.6267 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.4464 %\n",
      "Train Loss: 1.5415 || Validation Loss: 1.5608 || Test Loss: 1.5692\n",
      "     \n",
      "Epoch: 139 of 200 || Train Accuracy: 95.6667 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.4464 %\n",
      "Train Loss: 1.5412 || Validation Loss: 1.5607 || Test Loss: 1.5690\n",
      "     \n",
      "Epoch: 140 of 200 || Train Accuracy: 95.7200 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.4831 %\n",
      "Train Loss: 1.5408 || Validation Loss: 1.5605 || Test Loss: 1.5689\n",
      "     \n",
      "Epoch: 141 of 200 || Train Accuracy: 95.7600 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.5198 %\n",
      "Train Loss: 1.5405 || Validation Loss: 1.5603 || Test Loss: 1.5688\n",
      "     \n",
      "Epoch: 142 of 200 || Train Accuracy: 95.7800 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.5198 %\n",
      "Train Loss: 1.5401 || Validation Loss: 1.5602 || Test Loss: 1.5686\n",
      "     \n",
      "Epoch: 143 of 200 || Train Accuracy: 95.8333 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.5198 %\n",
      "Train Loss: 1.5398 || Validation Loss: 1.5600 || Test Loss: 1.5685\n",
      "     \n",
      "Epoch: 144 of 200 || Train Accuracy: 95.9000 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.5198 %\n",
      "Train Loss: 1.5394 || Validation Loss: 1.5599 || Test Loss: 1.5683\n",
      "     \n",
      "Epoch: 145 of 200 || Train Accuracy: 95.9267 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.5198 %\n",
      "Train Loss: 1.5391 || Validation Loss: 1.5597 || Test Loss: 1.5682\n",
      "     \n",
      "Epoch: 146 of 200 || Train Accuracy: 95.9667 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.5198 %\n",
      "Train Loss: 1.5388 || Validation Loss: 1.5596 || Test Loss: 1.5681\n",
      "     \n",
      "Epoch: 147 of 200 || Train Accuracy: 95.9733 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.4464 %\n",
      "Train Loss: 1.5384 || Validation Loss: 1.5594 || Test Loss: 1.5680\n",
      "     \n",
      "Epoch: 148 of 200 || Train Accuracy: 96.0200 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.4831 %\n",
      "Train Loss: 1.5381 || Validation Loss: 1.5593 || Test Loss: 1.5678\n",
      "     \n",
      "Epoch: 149 of 200 || Train Accuracy: 96.0333 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.4831 %\n",
      "Train Loss: 1.5377 || Validation Loss: 1.5591 || Test Loss: 1.5677\n",
      "     \n",
      "Epoch: 150 of 200 || Train Accuracy: 96.0600 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.4464 %\n",
      "Train Loss: 1.5374 || Validation Loss: 1.5590 || Test Loss: 1.5676\n",
      "     \n",
      "Epoch: 151 of 200 || Train Accuracy: 96.0800 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.4831 %\n",
      "Train Loss: 1.5371 || Validation Loss: 1.5589 || Test Loss: 1.5674\n",
      "     \n",
      "Epoch: 152 of 200 || Train Accuracy: 96.1067 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.4831 %\n",
      "Train Loss: 1.5367 || Validation Loss: 1.5587 || Test Loss: 1.5673\n",
      "     \n",
      "Epoch: 153 of 200 || Train Accuracy: 96.1333 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.4831 %\n",
      "Train Loss: 1.5364 || Validation Loss: 1.5586 || Test Loss: 1.5672\n",
      "     \n",
      "Epoch: 154 of 200 || Train Accuracy: 96.1733 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.4831 %\n",
      "Train Loss: 1.5361 || Validation Loss: 1.5584 || Test Loss: 1.5671\n",
      "     \n",
      "Epoch: 155 of 200 || Train Accuracy: 96.2000 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.5565 %\n",
      "Train Loss: 1.5357 || Validation Loss: 1.5583 || Test Loss: 1.5669\n",
      "     \n",
      "Epoch: 156 of 200 || Train Accuracy: 96.2467 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.5565 %\n",
      "Train Loss: 1.5354 || Validation Loss: 1.5581 || Test Loss: 1.5668\n",
      "     \n",
      "Epoch: 157 of 200 || Train Accuracy: 96.2867 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.5565 %\n",
      "Train Loss: 1.5351 || Validation Loss: 1.5580 || Test Loss: 1.5667\n",
      "     \n",
      "Epoch: 158 of 200 || Train Accuracy: 96.3200 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.5565 %\n",
      "Train Loss: 1.5347 || Validation Loss: 1.5578 || Test Loss: 1.5666\n",
      "     \n",
      "Epoch: 159 of 200 || Train Accuracy: 96.3733 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.5565 %\n",
      "Train Loss: 1.5344 || Validation Loss: 1.5577 || Test Loss: 1.5665\n",
      "     \n",
      "Epoch: 160 of 200 || Train Accuracy: 96.4200 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.5565 %\n",
      "Train Loss: 1.5341 || Validation Loss: 1.5576 || Test Loss: 1.5663\n",
      "     \n",
      "Epoch: 161 of 200 || Train Accuracy: 96.4600 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.5932 %\n",
      "Train Loss: 1.5338 || Validation Loss: 1.5574 || Test Loss: 1.5662\n",
      "     \n",
      "Epoch: 162 of 200 || Train Accuracy: 96.5000 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.5565 %\n",
      "Train Loss: 1.5334 || Validation Loss: 1.5573 || Test Loss: 1.5661\n",
      "     \n",
      "Epoch: 163 of 200 || Train Accuracy: 96.5133 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.5565 %\n",
      "Train Loss: 1.5331 || Validation Loss: 1.5571 || Test Loss: 1.5660\n",
      "     \n",
      "Epoch: 164 of 200 || Train Accuracy: 96.5267 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.5198 %\n",
      "Train Loss: 1.5328 || Validation Loss: 1.5570 || Test Loss: 1.5659\n",
      "     \n",
      "Epoch: 165 of 200 || Train Accuracy: 96.5733 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.5198 %\n",
      "Train Loss: 1.5325 || Validation Loss: 1.5569 || Test Loss: 1.5657\n",
      "     \n",
      "Epoch: 166 of 200 || Train Accuracy: 96.6067 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.5932 %\n",
      "Train Loss: 1.5321 || Validation Loss: 1.5567 || Test Loss: 1.5656\n",
      "     \n",
      "Epoch: 167 of 200 || Train Accuracy: 96.6333 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.5932 %\n",
      "Train Loss: 1.5318 || Validation Loss: 1.5566 || Test Loss: 1.5655\n",
      "     \n",
      "Epoch: 168 of 200 || Train Accuracy: 96.6733 % || Validation Accuracy: 92.7000 % || Test Accuracy: 91.5932 %\n",
      "Train Loss: 1.5315 || Validation Loss: 1.5564 || Test Loss: 1.5654\n",
      "     \n",
      "Epoch: 169 of 200 || Train Accuracy: 96.6800 % || Validation Accuracy: 92.7000 % || Test Accuracy: 91.5932 %\n",
      "Train Loss: 1.5312 || Validation Loss: 1.5563 || Test Loss: 1.5653\n",
      "     \n",
      "Epoch: 170 of 200 || Train Accuracy: 96.7133 % || Validation Accuracy: 92.7000 % || Test Accuracy: 91.5565 %\n",
      "Train Loss: 1.5309 || Validation Loss: 1.5561 || Test Loss: 1.5652\n",
      "     \n",
      "Epoch: 171 of 200 || Train Accuracy: 96.7467 % || Validation Accuracy: 92.7000 % || Test Accuracy: 91.5565 %\n",
      "Train Loss: 1.5306 || Validation Loss: 1.5560 || Test Loss: 1.5651\n",
      "     \n",
      "Epoch: 172 of 200 || Train Accuracy: 96.7800 % || Validation Accuracy: 92.7000 % || Test Accuracy: 91.5565 %\n",
      "Train Loss: 1.5303 || Validation Loss: 1.5559 || Test Loss: 1.5650\n",
      "     \n",
      "Epoch: 173 of 200 || Train Accuracy: 96.8067 % || Validation Accuracy: 92.7000 % || Test Accuracy: 91.5565 %\n",
      "Train Loss: 1.5299 || Validation Loss: 1.5558 || Test Loss: 1.5649\n",
      "     \n",
      "Epoch: 174 of 200 || Train Accuracy: 96.8467 % || Validation Accuracy: 92.7000 % || Test Accuracy: 91.5565 %\n",
      "Train Loss: 1.5296 || Validation Loss: 1.5556 || Test Loss: 1.5648\n",
      "     \n",
      "Epoch: 175 of 200 || Train Accuracy: 96.8867 % || Validation Accuracy: 92.7000 % || Test Accuracy: 91.5932 %\n",
      "Train Loss: 1.5293 || Validation Loss: 1.5555 || Test Loss: 1.5647\n",
      "     \n",
      "Epoch: 176 of 200 || Train Accuracy: 96.9000 % || Validation Accuracy: 92.7000 % || Test Accuracy: 91.5932 %\n",
      "Train Loss: 1.5290 || Validation Loss: 1.5554 || Test Loss: 1.5646\n",
      "     \n",
      "Epoch: 177 of 200 || Train Accuracy: 96.8933 % || Validation Accuracy: 92.7000 % || Test Accuracy: 91.5932 %\n",
      "Train Loss: 1.5287 || Validation Loss: 1.5552 || Test Loss: 1.5645\n",
      "     \n",
      "Epoch: 178 of 200 || Train Accuracy: 96.9333 % || Validation Accuracy: 92.7000 % || Test Accuracy: 91.5932 %\n",
      "Train Loss: 1.5284 || Validation Loss: 1.5551 || Test Loss: 1.5644\n",
      "     \n",
      "Epoch: 179 of 200 || Train Accuracy: 96.9400 % || Validation Accuracy: 92.7000 % || Test Accuracy: 91.5932 %\n",
      "Train Loss: 1.5281 || Validation Loss: 1.5550 || Test Loss: 1.5643\n",
      "     \n",
      "Epoch: 180 of 200 || Train Accuracy: 96.9667 % || Validation Accuracy: 92.7000 % || Test Accuracy: 91.5565 %\n",
      "Train Loss: 1.5278 || Validation Loss: 1.5548 || Test Loss: 1.5642\n",
      "     \n",
      "Epoch: 181 of 200 || Train Accuracy: 96.9867 % || Validation Accuracy: 92.7000 % || Test Accuracy: 91.5565 %\n",
      "Train Loss: 1.5275 || Validation Loss: 1.5547 || Test Loss: 1.5641\n",
      "     \n",
      "Epoch: 182 of 200 || Train Accuracy: 97.0067 % || Validation Accuracy: 92.7000 % || Test Accuracy: 91.5198 %\n",
      "Train Loss: 1.5272 || Validation Loss: 1.5546 || Test Loss: 1.5640\n",
      "     \n",
      "Epoch: 183 of 200 || Train Accuracy: 97.0200 % || Validation Accuracy: 92.7000 % || Test Accuracy: 91.5198 %\n",
      "Train Loss: 1.5269 || Validation Loss: 1.5545 || Test Loss: 1.5639\n",
      "     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 184 of 200 || Train Accuracy: 97.0533 % || Validation Accuracy: 92.7000 % || Test Accuracy: 91.5198 %\n",
      "Train Loss: 1.5266 || Validation Loss: 1.5543 || Test Loss: 1.5638\n",
      "     \n",
      "Epoch: 185 of 200 || Train Accuracy: 97.0733 % || Validation Accuracy: 92.7000 % || Test Accuracy: 91.5198 %\n",
      "Train Loss: 1.5263 || Validation Loss: 1.5542 || Test Loss: 1.5637\n",
      "     \n",
      "Epoch: 186 of 200 || Train Accuracy: 97.1000 % || Validation Accuracy: 92.7000 % || Test Accuracy: 91.5198 %\n",
      "Train Loss: 1.5260 || Validation Loss: 1.5541 || Test Loss: 1.5636\n",
      "     \n",
      "Epoch: 187 of 200 || Train Accuracy: 97.1200 % || Validation Accuracy: 92.7000 % || Test Accuracy: 91.4831 %\n",
      "Train Loss: 1.5257 || Validation Loss: 1.5540 || Test Loss: 1.5635\n",
      "     \n",
      "Epoch: 188 of 200 || Train Accuracy: 97.1467 % || Validation Accuracy: 92.7000 % || Test Accuracy: 91.4831 %\n",
      "Train Loss: 1.5254 || Validation Loss: 1.5538 || Test Loss: 1.5634\n",
      "     \n",
      "Epoch: 189 of 200 || Train Accuracy: 97.1667 % || Validation Accuracy: 92.7000 % || Test Accuracy: 91.4831 %\n",
      "Train Loss: 1.5251 || Validation Loss: 1.5537 || Test Loss: 1.5633\n",
      "     \n",
      "Epoch: 190 of 200 || Train Accuracy: 97.1733 % || Validation Accuracy: 92.7000 % || Test Accuracy: 91.4831 %\n",
      "Train Loss: 1.5248 || Validation Loss: 1.5536 || Test Loss: 1.5633\n",
      "     \n",
      "Epoch: 191 of 200 || Train Accuracy: 97.1867 % || Validation Accuracy: 92.7000 % || Test Accuracy: 91.4831 %\n",
      "Train Loss: 1.5245 || Validation Loss: 1.5535 || Test Loss: 1.5632\n",
      "     \n",
      "Epoch: 192 of 200 || Train Accuracy: 97.2067 % || Validation Accuracy: 92.7000 % || Test Accuracy: 91.4831 %\n",
      "Train Loss: 1.5243 || Validation Loss: 1.5534 || Test Loss: 1.5631\n",
      "     \n",
      "Epoch: 193 of 200 || Train Accuracy: 97.2200 % || Validation Accuracy: 92.8000 % || Test Accuracy: 91.4831 %\n",
      "Train Loss: 1.5240 || Validation Loss: 1.5532 || Test Loss: 1.5630\n",
      "     \n",
      "Epoch: 194 of 200 || Train Accuracy: 97.2467 % || Validation Accuracy: 92.8000 % || Test Accuracy: 91.4831 %\n",
      "Train Loss: 1.5237 || Validation Loss: 1.5531 || Test Loss: 1.5629\n",
      "     \n",
      "Epoch: 195 of 200 || Train Accuracy: 97.2533 % || Validation Accuracy: 92.8000 % || Test Accuracy: 91.4831 %\n",
      "Train Loss: 1.5234 || Validation Loss: 1.5530 || Test Loss: 1.5628\n",
      "     \n",
      "Epoch: 196 of 200 || Train Accuracy: 97.2933 % || Validation Accuracy: 92.8000 % || Test Accuracy: 91.5198 %\n",
      "Train Loss: 1.5231 || Validation Loss: 1.5529 || Test Loss: 1.5627\n",
      "     \n",
      "Epoch: 197 of 200 || Train Accuracy: 97.3000 % || Validation Accuracy: 92.8000 % || Test Accuracy: 91.5198 %\n",
      "Train Loss: 1.5228 || Validation Loss: 1.5528 || Test Loss: 1.5626\n",
      "     \n",
      "Epoch: 198 of 200 || Train Accuracy: 97.3333 % || Validation Accuracy: 92.8000 % || Test Accuracy: 91.5198 %\n",
      "Train Loss: 1.5225 || Validation Loss: 1.5527 || Test Loss: 1.5625\n",
      "     \n",
      "Epoch: 199 of 200 || Train Accuracy: 97.3800 % || Validation Accuracy: 92.8000 % || Test Accuracy: 91.5198 %\n",
      "Train Loss: 1.5222 || Validation Loss: 1.5526 || Test Loss: 1.5624\n",
      "     \n",
      "###### TRAINING COMPLETED #######\n",
      "###### TRAINING BEGINNING #######\n",
      "     \n",
      "Epoch: 0 of 200 || Train Accuracy: 8.3000 % || Validation Accuracy: 23.7000 % || Test Accuracy: 23.0910 %\n",
      "Train Loss: 2.3094 || Validation Loss: 2.2291 || Test Loss: 2.2263\n",
      "     \n",
      "Epoch: 1 of 200 || Train Accuracy: 22.5733 % || Validation Accuracy: 55.0000 % || Test Accuracy: 57.0485 %\n",
      "Train Loss: 2.2254 || Validation Loss: 2.0878 || Test Loss: 2.0780\n",
      "     \n",
      "Epoch: 2 of 200 || Train Accuracy: 54.5600 % || Validation Accuracy: 63.1000 % || Test Accuracy: 64.8311 %\n",
      "Train Loss: 2.0886 || Validation Loss: 1.9610 || Test Loss: 1.9516\n",
      "     \n",
      "Epoch: 3 of 200 || Train Accuracy: 63.8000 % || Validation Accuracy: 63.6000 % || Test Accuracy: 64.7944 %\n",
      "Train Loss: 1.9546 || Validation Loss: 1.9071 || Test Loss: 1.8903\n",
      "     \n",
      "Epoch: 4 of 200 || Train Accuracy: 64.0067 % || Validation Accuracy: 76.3000 % || Test Accuracy: 75.0000 %\n",
      "Train Loss: 1.8954 || Validation Loss: 1.8083 || Test Loss: 1.8052\n",
      "     \n",
      "Epoch: 5 of 200 || Train Accuracy: 74.0467 % || Validation Accuracy: 72.7000 % || Test Accuracy: 72.9442 %\n",
      "Train Loss: 1.8098 || Validation Loss: 1.8128 || Test Loss: 1.8100\n",
      "     \n",
      "Epoch: 6 of 200 || Train Accuracy: 71.5067 % || Validation Accuracy: 74.0000 % || Test Accuracy: 75.4405 %\n",
      "Train Loss: 1.8169 || Validation Loss: 1.7779 || Test Loss: 1.7702\n",
      "     \n",
      "Epoch: 7 of 200 || Train Accuracy: 73.7133 % || Validation Accuracy: 81.6000 % || Test Accuracy: 81.6079 %\n",
      "Train Loss: 1.7799 || Validation Loss: 1.7451 || Test Loss: 1.7364\n",
      "     \n",
      "Epoch: 8 of 200 || Train Accuracy: 81.7600 % || Validation Accuracy: 77.9000 % || Test Accuracy: 78.5609 %\n",
      "Train Loss: 1.7410 || Validation Loss: 1.7398 || Test Loss: 1.7299\n",
      "     \n",
      "Epoch: 9 of 200 || Train Accuracy: 78.1133 % || Validation Accuracy: 81.3000 % || Test Accuracy: 80.9838 %\n",
      "Train Loss: 1.7329 || Validation Loss: 1.7131 || Test Loss: 1.7105\n",
      "     \n",
      "Epoch: 10 of 200 || Train Accuracy: 81.0467 % || Validation Accuracy: 85.3000 % || Test Accuracy: 84.9119 %\n",
      "Train Loss: 1.7117 || Validation Loss: 1.6760 || Test Loss: 1.6760\n",
      "     \n",
      "Epoch: 11 of 200 || Train Accuracy: 84.4667 % || Validation Accuracy: 84.5000 % || Test Accuracy: 85.0954 %\n",
      "Train Loss: 1.6792 || Validation Loss: 1.6707 || Test Loss: 1.6726\n",
      "     \n",
      "Epoch: 12 of 200 || Train Accuracy: 84.0000 % || Validation Accuracy: 86.7000 % || Test Accuracy: 87.1145 %\n",
      "Train Loss: 1.6759 || Validation Loss: 1.6494 || Test Loss: 1.6505\n",
      "     \n",
      "Epoch: 13 of 200 || Train Accuracy: 86.0267 % || Validation Accuracy: 87.0000 % || Test Accuracy: 87.5918 %\n",
      "Train Loss: 1.6538 || Validation Loss: 1.6422 || Test Loss: 1.6422\n",
      "     \n",
      "Epoch: 14 of 200 || Train Accuracy: 87.3000 % || Validation Accuracy: 86.1000 % || Test Accuracy: 86.7474 %\n",
      "Train Loss: 1.6433 || Validation Loss: 1.6517 || Test Loss: 1.6508\n",
      "     \n",
      "Epoch: 15 of 200 || Train Accuracy: 87.0000 % || Validation Accuracy: 86.8000 % || Test Accuracy: 87.2981 %\n",
      "Train Loss: 1.6513 || Validation Loss: 1.6440 || Test Loss: 1.6419\n",
      "     \n",
      "Epoch: 16 of 200 || Train Accuracy: 87.1867 % || Validation Accuracy: 87.2000 % || Test Accuracy: 87.8855 %\n",
      "Train Loss: 1.6423 || Validation Loss: 1.6300 || Test Loss: 1.6264\n",
      "     \n",
      "Epoch: 17 of 200 || Train Accuracy: 87.6133 % || Validation Accuracy: 87.9000 % || Test Accuracy: 88.0690 %\n",
      "Train Loss: 1.6273 || Validation Loss: 1.6224 || Test Loss: 1.6184\n",
      "     \n",
      "Epoch: 18 of 200 || Train Accuracy: 87.7933 % || Validation Accuracy: 88.1000 % || Test Accuracy: 87.7753 %\n",
      "Train Loss: 1.6200 || Validation Loss: 1.6189 || Test Loss: 1.6161\n",
      "     \n",
      "Epoch: 19 of 200 || Train Accuracy: 87.8133 % || Validation Accuracy: 88.2000 % || Test Accuracy: 87.9956 %\n",
      "Train Loss: 1.6177 || Validation Loss: 1.6171 || Test Loss: 1.6166\n",
      "     \n",
      "Epoch: 20 of 200 || Train Accuracy: 87.8667 % || Validation Accuracy: 88.5000 % || Test Accuracy: 88.1791 %\n",
      "Train Loss: 1.6180 || Validation Loss: 1.6127 || Test Loss: 1.6144\n",
      "     \n",
      "Epoch: 21 of 200 || Train Accuracy: 88.2533 % || Validation Accuracy: 89.0000 % || Test Accuracy: 88.8032 %\n",
      "Train Loss: 1.6155 || Validation Loss: 1.6088 || Test Loss: 1.6113\n",
      "     \n",
      "Epoch: 22 of 200 || Train Accuracy: 88.7800 % || Validation Accuracy: 88.5000 % || Test Accuracy: 88.9868 %\n",
      "Train Loss: 1.6115 || Validation Loss: 1.6084 || Test Loss: 1.6113\n",
      "     \n",
      "Epoch: 23 of 200 || Train Accuracy: 89.0667 % || Validation Accuracy: 88.9000 % || Test Accuracy: 89.0969 %\n",
      "Train Loss: 1.6101 || Validation Loss: 1.6084 || Test Loss: 1.6114\n",
      "     \n",
      "Epoch: 24 of 200 || Train Accuracy: 89.2733 % || Validation Accuracy: 88.9000 % || Test Accuracy: 89.0969 %\n",
      "Train Loss: 1.6090 || Validation Loss: 1.6071 || Test Loss: 1.6095\n",
      "     \n",
      "Epoch: 25 of 200 || Train Accuracy: 89.5733 % || Validation Accuracy: 89.5000 % || Test Accuracy: 89.5742 %\n",
      "Train Loss: 1.6066 || Validation Loss: 1.6071 || Test Loss: 1.6082\n",
      "     \n",
      "Epoch: 26 of 200 || Train Accuracy: 89.5933 % || Validation Accuracy: 89.5000 % || Test Accuracy: 89.5742 %\n",
      "Train Loss: 1.6054 || Validation Loss: 1.6093 || Test Loss: 1.6092\n",
      "     \n",
      "Epoch: 27 of 200 || Train Accuracy: 89.4000 % || Validation Accuracy: 88.9000 % || Test Accuracy: 89.7944 %\n",
      "Train Loss: 1.6067 || Validation Loss: 1.6112 || Test Loss: 1.6105\n",
      "     \n",
      "Epoch: 28 of 200 || Train Accuracy: 89.5533 % || Validation Accuracy: 89.1000 % || Test Accuracy: 89.9046 %\n",
      "Train Loss: 1.6079 || Validation Loss: 1.6092 || Test Loss: 1.6087\n",
      "     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29 of 200 || Train Accuracy: 89.7600 % || Validation Accuracy: 89.9000 % || Test Accuracy: 90.0514 %\n",
      "Train Loss: 1.6057 || Validation Loss: 1.6046 || Test Loss: 1.6047\n",
      "     \n",
      "Epoch: 30 of 200 || Train Accuracy: 90.0067 % || Validation Accuracy: 90.5000 % || Test Accuracy: 90.0147 %\n",
      "Train Loss: 1.6013 || Validation Loss: 1.6010 || Test Loss: 1.6019\n",
      "     \n",
      "Epoch: 31 of 200 || Train Accuracy: 90.3933 % || Validation Accuracy: 90.1000 % || Test Accuracy: 90.2349 %\n",
      "Train Loss: 1.5980 || Validation Loss: 1.5991 || Test Loss: 1.6008\n",
      "     \n",
      "Epoch: 32 of 200 || Train Accuracy: 90.6200 % || Validation Accuracy: 89.7000 % || Test Accuracy: 90.1982 %\n",
      "Train Loss: 1.5967 || Validation Loss: 1.5978 || Test Loss: 1.6001\n",
      "     \n",
      "Epoch: 33 of 200 || Train Accuracy: 90.7067 % || Validation Accuracy: 89.9000 % || Test Accuracy: 90.3451 %\n",
      "Train Loss: 1.5959 || Validation Loss: 1.5957 || Test Loss: 1.5987\n",
      "     \n",
      "Epoch: 34 of 200 || Train Accuracy: 90.7800 % || Validation Accuracy: 90.2000 % || Test Accuracy: 90.6388 %\n",
      "Train Loss: 1.5941 || Validation Loss: 1.5931 || Test Loss: 1.5967\n",
      "     \n",
      "Epoch: 35 of 200 || Train Accuracy: 90.8133 % || Validation Accuracy: 90.1000 % || Test Accuracy: 90.7856 %\n",
      "Train Loss: 1.5918 || Validation Loss: 1.5910 || Test Loss: 1.5950\n",
      "     \n",
      "Epoch: 36 of 200 || Train Accuracy: 90.9733 % || Validation Accuracy: 90.3000 % || Test Accuracy: 90.5653 %\n",
      "Train Loss: 1.5898 || Validation Loss: 1.5896 || Test Loss: 1.5936\n",
      "     \n",
      "Epoch: 37 of 200 || Train Accuracy: 91.0533 % || Validation Accuracy: 90.3000 % || Test Accuracy: 90.6388 %\n",
      "Train Loss: 1.5882 || Validation Loss: 1.5890 || Test Loss: 1.5926\n",
      "     \n",
      "Epoch: 38 of 200 || Train Accuracy: 91.1333 % || Validation Accuracy: 90.3000 % || Test Accuracy: 90.6755 %\n",
      "Train Loss: 1.5870 || Validation Loss: 1.5888 || Test Loss: 1.5918\n",
      "     \n",
      "Epoch: 39 of 200 || Train Accuracy: 91.1667 % || Validation Accuracy: 90.4000 % || Test Accuracy: 90.7122 %\n",
      "Train Loss: 1.5861 || Validation Loss: 1.5884 || Test Loss: 1.5912\n",
      "     \n",
      "Epoch: 40 of 200 || Train Accuracy: 91.2933 % || Validation Accuracy: 90.3000 % || Test Accuracy: 90.5653 %\n",
      "Train Loss: 1.5851 || Validation Loss: 1.5877 || Test Loss: 1.5906\n",
      "     \n",
      "Epoch: 41 of 200 || Train Accuracy: 91.3467 % || Validation Accuracy: 90.6000 % || Test Accuracy: 90.5653 %\n",
      "Train Loss: 1.5840 || Validation Loss: 1.5865 || Test Loss: 1.5899\n",
      "     \n",
      "Epoch: 42 of 200 || Train Accuracy: 91.4467 % || Validation Accuracy: 90.8000 % || Test Accuracy: 90.5653 %\n",
      "Train Loss: 1.5828 || Validation Loss: 1.5852 || Test Loss: 1.5892\n",
      "     \n",
      "Epoch: 43 of 200 || Train Accuracy: 91.6400 % || Validation Accuracy: 90.9000 % || Test Accuracy: 90.8223 %\n",
      "Train Loss: 1.5816 || Validation Loss: 1.5839 || Test Loss: 1.5885\n",
      "     \n",
      "Epoch: 44 of 200 || Train Accuracy: 91.8000 % || Validation Accuracy: 91.2000 % || Test Accuracy: 90.7122 %\n",
      "Train Loss: 1.5807 || Validation Loss: 1.5832 || Test Loss: 1.5882\n",
      "     \n",
      "Epoch: 45 of 200 || Train Accuracy: 91.8867 % || Validation Accuracy: 90.9000 % || Test Accuracy: 90.8223 %\n",
      "Train Loss: 1.5802 || Validation Loss: 1.5827 || Test Loss: 1.5881\n",
      "     \n",
      "Epoch: 46 of 200 || Train Accuracy: 91.9667 % || Validation Accuracy: 91.2000 % || Test Accuracy: 90.8590 %\n",
      "Train Loss: 1.5799 || Validation Loss: 1.5823 || Test Loss: 1.5877\n",
      "     \n",
      "Epoch: 47 of 200 || Train Accuracy: 92.0133 % || Validation Accuracy: 91.0000 % || Test Accuracy: 90.8590 %\n",
      "Train Loss: 1.5794 || Validation Loss: 1.5820 || Test Loss: 1.5872\n",
      "     \n",
      "Epoch: 48 of 200 || Train Accuracy: 92.0933 % || Validation Accuracy: 91.0000 % || Test Accuracy: 90.8223 %\n",
      "Train Loss: 1.5787 || Validation Loss: 1.5818 || Test Loss: 1.5867\n",
      "     \n",
      "Epoch: 49 of 200 || Train Accuracy: 92.2133 % || Validation Accuracy: 91.1000 % || Test Accuracy: 90.7856 %\n",
      "Train Loss: 1.5779 || Validation Loss: 1.5817 || Test Loss: 1.5862\n",
      "     \n",
      "Epoch: 50 of 200 || Train Accuracy: 92.2800 % || Validation Accuracy: 90.9000 % || Test Accuracy: 90.8957 %\n",
      "Train Loss: 1.5771 || Validation Loss: 1.5816 || Test Loss: 1.5859\n",
      "     \n",
      "Epoch: 51 of 200 || Train Accuracy: 92.2867 % || Validation Accuracy: 90.9000 % || Test Accuracy: 90.9325 %\n",
      "Train Loss: 1.5766 || Validation Loss: 1.5813 || Test Loss: 1.5856\n",
      "     \n",
      "Epoch: 52 of 200 || Train Accuracy: 92.3533 % || Validation Accuracy: 90.9000 % || Test Accuracy: 91.0059 %\n",
      "Train Loss: 1.5760 || Validation Loss: 1.5806 || Test Loss: 1.5852\n",
      "     \n",
      "Epoch: 53 of 200 || Train Accuracy: 92.4400 % || Validation Accuracy: 91.1000 % || Test Accuracy: 91.0426 %\n",
      "Train Loss: 1.5753 || Validation Loss: 1.5797 || Test Loss: 1.5847\n",
      "     \n",
      "Epoch: 54 of 200 || Train Accuracy: 92.4867 % || Validation Accuracy: 91.0000 % || Test Accuracy: 90.9692 %\n",
      "Train Loss: 1.5744 || Validation Loss: 1.5788 || Test Loss: 1.5842\n",
      "     \n",
      "Epoch: 55 of 200 || Train Accuracy: 92.5933 % || Validation Accuracy: 91.2000 % || Test Accuracy: 91.0793 %\n",
      "Train Loss: 1.5736 || Validation Loss: 1.5779 || Test Loss: 1.5837\n",
      "     \n",
      "Epoch: 56 of 200 || Train Accuracy: 92.6400 % || Validation Accuracy: 91.3000 % || Test Accuracy: 91.0059 %\n",
      "Train Loss: 1.5729 || Validation Loss: 1.5771 || Test Loss: 1.5833\n",
      "     \n",
      "Epoch: 57 of 200 || Train Accuracy: 92.6800 % || Validation Accuracy: 91.2000 % || Test Accuracy: 91.0793 %\n",
      "Train Loss: 1.5721 || Validation Loss: 1.5765 || Test Loss: 1.5827\n",
      "     \n",
      "Epoch: 58 of 200 || Train Accuracy: 92.7333 % || Validation Accuracy: 91.4000 % || Test Accuracy: 91.0793 %\n",
      "Train Loss: 1.5714 || Validation Loss: 1.5761 || Test Loss: 1.5822\n",
      "     \n",
      "Epoch: 59 of 200 || Train Accuracy: 92.7733 % || Validation Accuracy: 91.4000 % || Test Accuracy: 91.0426 %\n",
      "Train Loss: 1.5707 || Validation Loss: 1.5758 || Test Loss: 1.5818\n",
      "     \n",
      "Epoch: 60 of 200 || Train Accuracy: 92.7867 % || Validation Accuracy: 91.6000 % || Test Accuracy: 91.1160 %\n",
      "Train Loss: 1.5700 || Validation Loss: 1.5756 || Test Loss: 1.5814\n",
      "     \n",
      "Epoch: 61 of 200 || Train Accuracy: 92.8200 % || Validation Accuracy: 91.6000 % || Test Accuracy: 91.0426 %\n",
      "Train Loss: 1.5694 || Validation Loss: 1.5754 || Test Loss: 1.5810\n",
      "     \n",
      "Epoch: 62 of 200 || Train Accuracy: 92.8800 % || Validation Accuracy: 91.7000 % || Test Accuracy: 91.1527 %\n",
      "Train Loss: 1.5689 || Validation Loss: 1.5751 || Test Loss: 1.5807\n",
      "     \n",
      "Epoch: 63 of 200 || Train Accuracy: 92.9600 % || Validation Accuracy: 91.8000 % || Test Accuracy: 91.2261 %\n",
      "Train Loss: 1.5684 || Validation Loss: 1.5748 || Test Loss: 1.5805\n",
      "     \n",
      "Epoch: 64 of 200 || Train Accuracy: 92.9933 % || Validation Accuracy: 92.0000 % || Test Accuracy: 91.1894 %\n",
      "Train Loss: 1.5680 || Validation Loss: 1.5743 || Test Loss: 1.5803\n",
      "     \n",
      "Epoch: 65 of 200 || Train Accuracy: 93.0600 % || Validation Accuracy: 92.0000 % || Test Accuracy: 91.2261 %\n",
      "Train Loss: 1.5675 || Validation Loss: 1.5738 || Test Loss: 1.5800\n",
      "     \n",
      "Epoch: 66 of 200 || Train Accuracy: 93.1067 % || Validation Accuracy: 92.0000 % || Test Accuracy: 91.2261 %\n",
      "Train Loss: 1.5669 || Validation Loss: 1.5733 || Test Loss: 1.5798\n",
      "     \n",
      "Epoch: 67 of 200 || Train Accuracy: 93.1800 % || Validation Accuracy: 92.1000 % || Test Accuracy: 91.2628 %\n",
      "Train Loss: 1.5663 || Validation Loss: 1.5729 || Test Loss: 1.5795\n",
      "     \n",
      "Epoch: 68 of 200 || Train Accuracy: 93.1800 % || Validation Accuracy: 92.1000 % || Test Accuracy: 91.1894 %\n",
      "Train Loss: 1.5658 || Validation Loss: 1.5726 || Test Loss: 1.5792\n",
      "     \n",
      "Epoch: 69 of 200 || Train Accuracy: 93.2467 % || Validation Accuracy: 92.0000 % || Test Accuracy: 91.2628 %\n",
      "Train Loss: 1.5652 || Validation Loss: 1.5723 || Test Loss: 1.5789\n",
      "     \n",
      "Epoch: 70 of 200 || Train Accuracy: 93.3200 % || Validation Accuracy: 92.1000 % || Test Accuracy: 91.2261 %\n",
      "Train Loss: 1.5647 || Validation Loss: 1.5720 || Test Loss: 1.5786\n",
      "     \n",
      "Epoch: 71 of 200 || Train Accuracy: 93.3600 % || Validation Accuracy: 92.1000 % || Test Accuracy: 91.2261 %\n",
      "Train Loss: 1.5642 || Validation Loss: 1.5717 || Test Loss: 1.5782\n",
      "     \n",
      "Epoch: 72 of 200 || Train Accuracy: 93.4000 % || Validation Accuracy: 92.1000 % || Test Accuracy: 91.2628 %\n",
      "Train Loss: 1.5637 || Validation Loss: 1.5714 || Test Loss: 1.5779\n",
      "     \n",
      "Epoch: 73 of 200 || Train Accuracy: 93.4667 % || Validation Accuracy: 92.1000 % || Test Accuracy: 91.3363 %\n",
      "Train Loss: 1.5632 || Validation Loss: 1.5711 || Test Loss: 1.5776\n",
      "     \n",
      "Epoch: 74 of 200 || Train Accuracy: 93.5267 % || Validation Accuracy: 92.2000 % || Test Accuracy: 91.2261 %\n",
      "Train Loss: 1.5627 || Validation Loss: 1.5708 || Test Loss: 1.5774\n",
      "     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 75 of 200 || Train Accuracy: 93.5400 % || Validation Accuracy: 92.2000 % || Test Accuracy: 91.2261 %\n",
      "Train Loss: 1.5623 || Validation Loss: 1.5705 || Test Loss: 1.5771\n",
      "     \n",
      "Epoch: 76 of 200 || Train Accuracy: 93.6067 % || Validation Accuracy: 92.2000 % || Test Accuracy: 91.2261 %\n",
      "Train Loss: 1.5618 || Validation Loss: 1.5701 || Test Loss: 1.5769\n",
      "     \n",
      "Epoch: 77 of 200 || Train Accuracy: 93.6467 % || Validation Accuracy: 92.2000 % || Test Accuracy: 91.2261 %\n",
      "Train Loss: 1.5613 || Validation Loss: 1.5698 || Test Loss: 1.5767\n",
      "     \n",
      "Epoch: 78 of 200 || Train Accuracy: 93.6800 % || Validation Accuracy: 92.2000 % || Test Accuracy: 91.2261 %\n",
      "Train Loss: 1.5608 || Validation Loss: 1.5695 || Test Loss: 1.5764\n",
      "     \n",
      "Epoch: 79 of 200 || Train Accuracy: 93.7200 % || Validation Accuracy: 92.2000 % || Test Accuracy: 91.2996 %\n",
      "Train Loss: 1.5602 || Validation Loss: 1.5692 || Test Loss: 1.5762\n",
      "     \n",
      "Epoch: 80 of 200 || Train Accuracy: 93.7600 % || Validation Accuracy: 92.2000 % || Test Accuracy: 91.2628 %\n",
      "Train Loss: 1.5597 || Validation Loss: 1.5689 || Test Loss: 1.5759\n",
      "     \n",
      "Epoch: 81 of 200 || Train Accuracy: 93.7933 % || Validation Accuracy: 92.2000 % || Test Accuracy: 91.2996 %\n",
      "Train Loss: 1.5592 || Validation Loss: 1.5686 || Test Loss: 1.5757\n",
      "     \n",
      "Epoch: 82 of 200 || Train Accuracy: 93.8667 % || Validation Accuracy: 92.2000 % || Test Accuracy: 91.2996 %\n",
      "Train Loss: 1.5588 || Validation Loss: 1.5683 || Test Loss: 1.5754\n",
      "     \n",
      "Epoch: 83 of 200 || Train Accuracy: 93.8867 % || Validation Accuracy: 92.2000 % || Test Accuracy: 91.2628 %\n",
      "Train Loss: 1.5583 || Validation Loss: 1.5681 || Test Loss: 1.5752\n",
      "     \n",
      "Epoch: 84 of 200 || Train Accuracy: 93.9600 % || Validation Accuracy: 92.2000 % || Test Accuracy: 91.2261 %\n",
      "Train Loss: 1.5578 || Validation Loss: 1.5678 || Test Loss: 1.5750\n",
      "     \n",
      "Epoch: 85 of 200 || Train Accuracy: 94.0467 % || Validation Accuracy: 92.3000 % || Test Accuracy: 91.2628 %\n",
      "Train Loss: 1.5574 || Validation Loss: 1.5675 || Test Loss: 1.5747\n",
      "     \n",
      "Epoch: 86 of 200 || Train Accuracy: 94.1000 % || Validation Accuracy: 92.3000 % || Test Accuracy: 91.2261 %\n",
      "Train Loss: 1.5569 || Validation Loss: 1.5672 || Test Loss: 1.5745\n",
      "     \n",
      "Epoch: 87 of 200 || Train Accuracy: 94.1600 % || Validation Accuracy: 92.3000 % || Test Accuracy: 91.2261 %\n",
      "Train Loss: 1.5565 || Validation Loss: 1.5670 || Test Loss: 1.5743\n",
      "     \n",
      "Epoch: 88 of 200 || Train Accuracy: 94.2333 % || Validation Accuracy: 92.3000 % || Test Accuracy: 91.2261 %\n",
      "Train Loss: 1.5560 || Validation Loss: 1.5667 || Test Loss: 1.5741\n",
      "     \n",
      "Epoch: 89 of 200 || Train Accuracy: 94.2533 % || Validation Accuracy: 92.3000 % || Test Accuracy: 91.2261 %\n",
      "Train Loss: 1.5556 || Validation Loss: 1.5665 || Test Loss: 1.5738\n",
      "     \n",
      "Epoch: 90 of 200 || Train Accuracy: 94.2933 % || Validation Accuracy: 92.3000 % || Test Accuracy: 91.2628 %\n",
      "Train Loss: 1.5551 || Validation Loss: 1.5662 || Test Loss: 1.5736\n",
      "     \n",
      "Epoch: 91 of 200 || Train Accuracy: 94.3467 % || Validation Accuracy: 92.5000 % || Test Accuracy: 91.3363 %\n",
      "Train Loss: 1.5547 || Validation Loss: 1.5659 || Test Loss: 1.5734\n",
      "     \n",
      "Epoch: 92 of 200 || Train Accuracy: 94.4000 % || Validation Accuracy: 92.5000 % || Test Accuracy: 91.2996 %\n",
      "Train Loss: 1.5542 || Validation Loss: 1.5657 || Test Loss: 1.5732\n",
      "     \n",
      "Epoch: 93 of 200 || Train Accuracy: 94.4467 % || Validation Accuracy: 92.5000 % || Test Accuracy: 91.2628 %\n",
      "Train Loss: 1.5538 || Validation Loss: 1.5654 || Test Loss: 1.5730\n",
      "     \n",
      "Epoch: 94 of 200 || Train Accuracy: 94.5133 % || Validation Accuracy: 92.5000 % || Test Accuracy: 91.2628 %\n",
      "Train Loss: 1.5533 || Validation Loss: 1.5652 || Test Loss: 1.5729\n",
      "     \n",
      "Epoch: 95 of 200 || Train Accuracy: 94.5533 % || Validation Accuracy: 92.5000 % || Test Accuracy: 91.2996 %\n",
      "Train Loss: 1.5529 || Validation Loss: 1.5650 || Test Loss: 1.5727\n",
      "     \n",
      "Epoch: 96 of 200 || Train Accuracy: 94.5867 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.2996 %\n",
      "Train Loss: 1.5525 || Validation Loss: 1.5647 || Test Loss: 1.5725\n",
      "     \n",
      "Epoch: 97 of 200 || Train Accuracy: 94.6200 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.2996 %\n",
      "Train Loss: 1.5521 || Validation Loss: 1.5645 || Test Loss: 1.5723\n",
      "     \n",
      "Epoch: 98 of 200 || Train Accuracy: 94.6600 % || Validation Accuracy: 92.5000 % || Test Accuracy: 91.2996 %\n",
      "Train Loss: 1.5517 || Validation Loss: 1.5643 || Test Loss: 1.5721\n",
      "     \n",
      "Epoch: 99 of 200 || Train Accuracy: 94.7133 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.2996 %\n",
      "Train Loss: 1.5513 || Validation Loss: 1.5641 || Test Loss: 1.5719\n",
      "     \n",
      "Epoch: 100 of 200 || Train Accuracy: 94.7733 % || Validation Accuracy: 92.7000 % || Test Accuracy: 91.2628 %\n",
      "Train Loss: 1.5508 || Validation Loss: 1.5639 || Test Loss: 1.5717\n",
      "     \n",
      "Epoch: 101 of 200 || Train Accuracy: 94.8200 % || Validation Accuracy: 92.7000 % || Test Accuracy: 91.2628 %\n",
      "Train Loss: 1.5504 || Validation Loss: 1.5636 || Test Loss: 1.5715\n",
      "     \n",
      "Epoch: 102 of 200 || Train Accuracy: 94.8600 % || Validation Accuracy: 92.7000 % || Test Accuracy: 91.2628 %\n",
      "Train Loss: 1.5500 || Validation Loss: 1.5634 || Test Loss: 1.5713\n",
      "     \n",
      "Epoch: 103 of 200 || Train Accuracy: 94.9133 % || Validation Accuracy: 92.8000 % || Test Accuracy: 91.2261 %\n",
      "Train Loss: 1.5496 || Validation Loss: 1.5632 || Test Loss: 1.5711\n",
      "     \n",
      "Epoch: 104 of 200 || Train Accuracy: 94.9467 % || Validation Accuracy: 92.8000 % || Test Accuracy: 91.2261 %\n",
      "Train Loss: 1.5491 || Validation Loss: 1.5630 || Test Loss: 1.5710\n",
      "     \n",
      "Epoch: 105 of 200 || Train Accuracy: 94.9867 % || Validation Accuracy: 92.8000 % || Test Accuracy: 91.2261 %\n",
      "Train Loss: 1.5487 || Validation Loss: 1.5628 || Test Loss: 1.5708\n",
      "     \n",
      "Epoch: 106 of 200 || Train Accuracy: 95.0333 % || Validation Accuracy: 92.8000 % || Test Accuracy: 91.2628 %\n",
      "Train Loss: 1.5483 || Validation Loss: 1.5625 || Test Loss: 1.5706\n",
      "     \n",
      "Epoch: 107 of 200 || Train Accuracy: 95.0733 % || Validation Accuracy: 92.8000 % || Test Accuracy: 91.2628 %\n",
      "Train Loss: 1.5479 || Validation Loss: 1.5623 || Test Loss: 1.5704\n",
      "     \n",
      "Epoch: 108 of 200 || Train Accuracy: 95.1133 % || Validation Accuracy: 92.7000 % || Test Accuracy: 91.2628 %\n",
      "Train Loss: 1.5475 || Validation Loss: 1.5621 || Test Loss: 1.5702\n",
      "     \n",
      "Epoch: 109 of 200 || Train Accuracy: 95.1733 % || Validation Accuracy: 92.7000 % || Test Accuracy: 91.2628 %\n",
      "Train Loss: 1.5471 || Validation Loss: 1.5619 || Test Loss: 1.5700\n",
      "     \n",
      "Epoch: 110 of 200 || Train Accuracy: 95.2133 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.2628 %\n",
      "Train Loss: 1.5467 || Validation Loss: 1.5617 || Test Loss: 1.5699\n",
      "     \n",
      "Epoch: 111 of 200 || Train Accuracy: 95.2467 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.2996 %\n",
      "Train Loss: 1.5463 || Validation Loss: 1.5615 || Test Loss: 1.5697\n",
      "     \n",
      "Epoch: 112 of 200 || Train Accuracy: 95.2600 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.2996 %\n",
      "Train Loss: 1.5459 || Validation Loss: 1.5613 || Test Loss: 1.5695\n",
      "     \n",
      "Epoch: 113 of 200 || Train Accuracy: 95.3133 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.2996 %\n",
      "Train Loss: 1.5455 || Validation Loss: 1.5611 || Test Loss: 1.5693\n",
      "     \n",
      "Epoch: 114 of 200 || Train Accuracy: 95.3667 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.3730 %\n",
      "Train Loss: 1.5451 || Validation Loss: 1.5609 || Test Loss: 1.5692\n",
      "     \n",
      "Epoch: 115 of 200 || Train Accuracy: 95.4067 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.3730 %\n",
      "Train Loss: 1.5447 || Validation Loss: 1.5607 || Test Loss: 1.5690\n",
      "     \n",
      "Epoch: 116 of 200 || Train Accuracy: 95.4533 % || Validation Accuracy: 92.7000 % || Test Accuracy: 91.3363 %\n",
      "Train Loss: 1.5443 || Validation Loss: 1.5605 || Test Loss: 1.5688\n",
      "     \n",
      "Epoch: 117 of 200 || Train Accuracy: 95.4933 % || Validation Accuracy: 92.7000 % || Test Accuracy: 91.3363 %\n",
      "Train Loss: 1.5439 || Validation Loss: 1.5603 || Test Loss: 1.5687\n",
      "     \n",
      "Epoch: 118 of 200 || Train Accuracy: 95.5333 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.4464 %\n",
      "Train Loss: 1.5435 || Validation Loss: 1.5601 || Test Loss: 1.5685\n",
      "     \n",
      "Epoch: 119 of 200 || Train Accuracy: 95.5733 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.4464 %\n",
      "Train Loss: 1.5431 || Validation Loss: 1.5599 || Test Loss: 1.5683\n",
      "     \n",
      "Epoch: 120 of 200 || Train Accuracy: 95.6333 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.4464 %\n",
      "Train Loss: 1.5427 || Validation Loss: 1.5597 || Test Loss: 1.5682\n",
      "     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 121 of 200 || Train Accuracy: 95.6800 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.4464 %\n",
      "Train Loss: 1.5423 || Validation Loss: 1.5595 || Test Loss: 1.5680\n",
      "     \n",
      "Epoch: 122 of 200 || Train Accuracy: 95.7133 % || Validation Accuracy: 92.7000 % || Test Accuracy: 91.5198 %\n",
      "Train Loss: 1.5419 || Validation Loss: 1.5593 || Test Loss: 1.5678\n",
      "     \n",
      "Epoch: 123 of 200 || Train Accuracy: 95.7533 % || Validation Accuracy: 92.7000 % || Test Accuracy: 91.5198 %\n",
      "Train Loss: 1.5415 || Validation Loss: 1.5591 || Test Loss: 1.5677\n",
      "     \n",
      "Epoch: 124 of 200 || Train Accuracy: 95.7800 % || Validation Accuracy: 92.7000 % || Test Accuracy: 91.5198 %\n",
      "Train Loss: 1.5411 || Validation Loss: 1.5589 || Test Loss: 1.5675\n",
      "     \n",
      "Epoch: 125 of 200 || Train Accuracy: 95.8133 % || Validation Accuracy: 92.7000 % || Test Accuracy: 91.5932 %\n",
      "Train Loss: 1.5408 || Validation Loss: 1.5587 || Test Loss: 1.5673\n",
      "     \n",
      "Epoch: 126 of 200 || Train Accuracy: 95.8733 % || Validation Accuracy: 92.8000 % || Test Accuracy: 91.5932 %\n",
      "Train Loss: 1.5404 || Validation Loss: 1.5586 || Test Loss: 1.5672\n",
      "     \n",
      "Epoch: 127 of 200 || Train Accuracy: 95.8867 % || Validation Accuracy: 92.9000 % || Test Accuracy: 91.5932 %\n",
      "Train Loss: 1.5400 || Validation Loss: 1.5584 || Test Loss: 1.5670\n",
      "     \n",
      "Epoch: 128 of 200 || Train Accuracy: 95.9200 % || Validation Accuracy: 92.9000 % || Test Accuracy: 91.5932 %\n",
      "Train Loss: 1.5396 || Validation Loss: 1.5582 || Test Loss: 1.5669\n",
      "     \n",
      "Epoch: 129 of 200 || Train Accuracy: 95.9533 % || Validation Accuracy: 92.9000 % || Test Accuracy: 91.6300 %\n",
      "Train Loss: 1.5392 || Validation Loss: 1.5580 || Test Loss: 1.5667\n",
      "     \n",
      "Epoch: 130 of 200 || Train Accuracy: 95.9867 % || Validation Accuracy: 92.9000 % || Test Accuracy: 91.6300 %\n",
      "Train Loss: 1.5389 || Validation Loss: 1.5579 || Test Loss: 1.5666\n",
      "     \n",
      "Epoch: 131 of 200 || Train Accuracy: 96.0333 % || Validation Accuracy: 93.0000 % || Test Accuracy: 91.6300 %\n",
      "Train Loss: 1.5385 || Validation Loss: 1.5577 || Test Loss: 1.5664\n",
      "     \n",
      "Epoch: 132 of 200 || Train Accuracy: 96.0733 % || Validation Accuracy: 93.0000 % || Test Accuracy: 91.6667 %\n",
      "Train Loss: 1.5381 || Validation Loss: 1.5575 || Test Loss: 1.5663\n",
      "     \n",
      "Epoch: 133 of 200 || Train Accuracy: 96.0933 % || Validation Accuracy: 93.0000 % || Test Accuracy: 91.6667 %\n",
      "Train Loss: 1.5377 || Validation Loss: 1.5573 || Test Loss: 1.5661\n",
      "     \n",
      "Epoch: 134 of 200 || Train Accuracy: 96.1333 % || Validation Accuracy: 93.0000 % || Test Accuracy: 91.6300 %\n",
      "Train Loss: 1.5374 || Validation Loss: 1.5572 || Test Loss: 1.5660\n",
      "     \n",
      "Epoch: 135 of 200 || Train Accuracy: 96.1800 % || Validation Accuracy: 93.0000 % || Test Accuracy: 91.6300 %\n",
      "Train Loss: 1.5370 || Validation Loss: 1.5570 || Test Loss: 1.5658\n",
      "     \n",
      "Epoch: 136 of 200 || Train Accuracy: 96.2200 % || Validation Accuracy: 93.0000 % || Test Accuracy: 91.7034 %\n",
      "Train Loss: 1.5366 || Validation Loss: 1.5568 || Test Loss: 1.5657\n",
      "     \n",
      "Epoch: 137 of 200 || Train Accuracy: 96.2600 % || Validation Accuracy: 93.0000 % || Test Accuracy: 91.7034 %\n",
      "Train Loss: 1.5363 || Validation Loss: 1.5567 || Test Loss: 1.5656\n",
      "     \n",
      "Epoch: 138 of 200 || Train Accuracy: 96.2867 % || Validation Accuracy: 93.0000 % || Test Accuracy: 91.7401 %\n",
      "Train Loss: 1.5359 || Validation Loss: 1.5565 || Test Loss: 1.5654\n",
      "     \n",
      "Epoch: 139 of 200 || Train Accuracy: 96.3333 % || Validation Accuracy: 93.1000 % || Test Accuracy: 91.7401 %\n",
      "Train Loss: 1.5355 || Validation Loss: 1.5563 || Test Loss: 1.5653\n",
      "     \n",
      "Epoch: 140 of 200 || Train Accuracy: 96.3533 % || Validation Accuracy: 93.1000 % || Test Accuracy: 91.7401 %\n",
      "Train Loss: 1.5352 || Validation Loss: 1.5562 || Test Loss: 1.5651\n",
      "     \n",
      "Epoch: 141 of 200 || Train Accuracy: 96.3867 % || Validation Accuracy: 93.1000 % || Test Accuracy: 91.7401 %\n",
      "Train Loss: 1.5348 || Validation Loss: 1.5560 || Test Loss: 1.5650\n",
      "     \n",
      "Epoch: 142 of 200 || Train Accuracy: 96.4133 % || Validation Accuracy: 93.1000 % || Test Accuracy: 91.7768 %\n",
      "Train Loss: 1.5345 || Validation Loss: 1.5559 || Test Loss: 1.5649\n",
      "     \n",
      "Epoch: 143 of 200 || Train Accuracy: 96.4267 % || Validation Accuracy: 93.1000 % || Test Accuracy: 91.7768 %\n",
      "Train Loss: 1.5341 || Validation Loss: 1.5557 || Test Loss: 1.5647\n",
      "     \n",
      "Epoch: 144 of 200 || Train Accuracy: 96.4333 % || Validation Accuracy: 93.1000 % || Test Accuracy: 91.7768 %\n",
      "Train Loss: 1.5337 || Validation Loss: 1.5556 || Test Loss: 1.5646\n",
      "     \n",
      "Epoch: 145 of 200 || Train Accuracy: 96.4733 % || Validation Accuracy: 93.1000 % || Test Accuracy: 91.8135 %\n",
      "Train Loss: 1.5334 || Validation Loss: 1.5554 || Test Loss: 1.5645\n",
      "     \n",
      "Epoch: 146 of 200 || Train Accuracy: 96.5200 % || Validation Accuracy: 93.1000 % || Test Accuracy: 91.8135 %\n",
      "Train Loss: 1.5330 || Validation Loss: 1.5553 || Test Loss: 1.5643\n",
      "     \n",
      "Epoch: 147 of 200 || Train Accuracy: 96.5333 % || Validation Accuracy: 93.1000 % || Test Accuracy: 91.8135 %\n",
      "Train Loss: 1.5327 || Validation Loss: 1.5551 || Test Loss: 1.5642\n",
      "     \n",
      "Epoch: 148 of 200 || Train Accuracy: 96.5667 % || Validation Accuracy: 93.1000 % || Test Accuracy: 91.8135 %\n",
      "Train Loss: 1.5324 || Validation Loss: 1.5550 || Test Loss: 1.5641\n",
      "     \n",
      "Epoch: 149 of 200 || Train Accuracy: 96.6067 % || Validation Accuracy: 93.1000 % || Test Accuracy: 91.8135 %\n",
      "Train Loss: 1.5320 || Validation Loss: 1.5548 || Test Loss: 1.5640\n",
      "     \n",
      "Epoch: 150 of 200 || Train Accuracy: 96.6400 % || Validation Accuracy: 93.1000 % || Test Accuracy: 91.8135 %\n",
      "Train Loss: 1.5317 || Validation Loss: 1.5547 || Test Loss: 1.5638\n",
      "     \n",
      "Epoch: 151 of 200 || Train Accuracy: 96.6867 % || Validation Accuracy: 93.1000 % || Test Accuracy: 91.8135 %\n",
      "Train Loss: 1.5313 || Validation Loss: 1.5546 || Test Loss: 1.5637\n",
      "     \n",
      "Epoch: 152 of 200 || Train Accuracy: 96.7067 % || Validation Accuracy: 93.1000 % || Test Accuracy: 91.8502 %\n",
      "Train Loss: 1.5310 || Validation Loss: 1.5544 || Test Loss: 1.5636\n",
      "     \n",
      "Epoch: 153 of 200 || Train Accuracy: 96.7333 % || Validation Accuracy: 93.1000 % || Test Accuracy: 91.8869 %\n",
      "Train Loss: 1.5306 || Validation Loss: 1.5543 || Test Loss: 1.5635\n",
      "     \n",
      "Epoch: 154 of 200 || Train Accuracy: 96.8000 % || Validation Accuracy: 93.1000 % || Test Accuracy: 91.8869 %\n",
      "Train Loss: 1.5303 || Validation Loss: 1.5541 || Test Loss: 1.5633\n",
      "     \n",
      "Epoch: 155 of 200 || Train Accuracy: 96.8667 % || Validation Accuracy: 93.1000 % || Test Accuracy: 91.8502 %\n",
      "Train Loss: 1.5300 || Validation Loss: 1.5540 || Test Loss: 1.5632\n",
      "     \n",
      "Epoch: 156 of 200 || Train Accuracy: 96.9200 % || Validation Accuracy: 93.1000 % || Test Accuracy: 91.8502 %\n",
      "Train Loss: 1.5296 || Validation Loss: 1.5538 || Test Loss: 1.5631\n",
      "     \n",
      "Epoch: 157 of 200 || Train Accuracy: 96.9467 % || Validation Accuracy: 93.1000 % || Test Accuracy: 91.8502 %\n",
      "Train Loss: 1.5293 || Validation Loss: 1.5537 || Test Loss: 1.5630\n",
      "     \n",
      "Epoch: 158 of 200 || Train Accuracy: 96.9533 % || Validation Accuracy: 93.1000 % || Test Accuracy: 91.8502 %\n",
      "Train Loss: 1.5290 || Validation Loss: 1.5536 || Test Loss: 1.5629\n",
      "     \n",
      "Epoch: 159 of 200 || Train Accuracy: 96.9600 % || Validation Accuracy: 93.1000 % || Test Accuracy: 91.8502 %\n",
      "Train Loss: 1.5286 || Validation Loss: 1.5534 || Test Loss: 1.5627\n",
      "     \n",
      "Epoch: 160 of 200 || Train Accuracy: 96.9800 % || Validation Accuracy: 93.2000 % || Test Accuracy: 91.8869 %\n",
      "Train Loss: 1.5283 || Validation Loss: 1.5533 || Test Loss: 1.5626\n",
      "     \n",
      "Epoch: 161 of 200 || Train Accuracy: 97.0333 % || Validation Accuracy: 93.2000 % || Test Accuracy: 91.8869 %\n",
      "Train Loss: 1.5280 || Validation Loss: 1.5531 || Test Loss: 1.5625\n",
      "     \n",
      "Epoch: 162 of 200 || Train Accuracy: 97.0867 % || Validation Accuracy: 93.2000 % || Test Accuracy: 91.8869 %\n",
      "Train Loss: 1.5276 || Validation Loss: 1.5530 || Test Loss: 1.5624\n",
      "     \n",
      "Epoch: 163 of 200 || Train Accuracy: 97.0933 % || Validation Accuracy: 93.2000 % || Test Accuracy: 91.8869 %\n",
      "Train Loss: 1.5273 || Validation Loss: 1.5529 || Test Loss: 1.5623\n",
      "     \n",
      "Epoch: 164 of 200 || Train Accuracy: 97.1067 % || Validation Accuracy: 93.2000 % || Test Accuracy: 91.8869 %\n",
      "Train Loss: 1.5270 || Validation Loss: 1.5527 || Test Loss: 1.5622\n",
      "     \n",
      "Epoch: 165 of 200 || Train Accuracy: 97.1267 % || Validation Accuracy: 93.2000 % || Test Accuracy: 91.8869 %\n",
      "Train Loss: 1.5267 || Validation Loss: 1.5526 || Test Loss: 1.5621\n",
      "     \n",
      "Epoch: 166 of 200 || Train Accuracy: 97.1867 % || Validation Accuracy: 93.2000 % || Test Accuracy: 91.8869 %\n",
      "Train Loss: 1.5264 || Validation Loss: 1.5525 || Test Loss: 1.5619\n",
      "     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 167 of 200 || Train Accuracy: 97.2133 % || Validation Accuracy: 93.2000 % || Test Accuracy: 91.8869 %\n",
      "Train Loss: 1.5260 || Validation Loss: 1.5523 || Test Loss: 1.5618\n",
      "     \n",
      "Epoch: 168 of 200 || Train Accuracy: 97.2667 % || Validation Accuracy: 93.2000 % || Test Accuracy: 91.8869 %\n",
      "Train Loss: 1.5257 || Validation Loss: 1.5522 || Test Loss: 1.5617\n",
      "     \n",
      "Epoch: 169 of 200 || Train Accuracy: 97.3133 % || Validation Accuracy: 93.2000 % || Test Accuracy: 91.9604 %\n",
      "Train Loss: 1.5254 || Validation Loss: 1.5521 || Test Loss: 1.5616\n",
      "     \n",
      "Epoch: 170 of 200 || Train Accuracy: 97.3600 % || Validation Accuracy: 93.2000 % || Test Accuracy: 91.9971 %\n",
      "Train Loss: 1.5251 || Validation Loss: 1.5520 || Test Loss: 1.5615\n",
      "     \n",
      "Epoch: 171 of 200 || Train Accuracy: 97.4000 % || Validation Accuracy: 93.2000 % || Test Accuracy: 91.9971 %\n",
      "Train Loss: 1.5248 || Validation Loss: 1.5518 || Test Loss: 1.5614\n",
      "     \n",
      "Epoch: 172 of 200 || Train Accuracy: 97.4533 % || Validation Accuracy: 93.3000 % || Test Accuracy: 91.9971 %\n",
      "Train Loss: 1.5245 || Validation Loss: 1.5517 || Test Loss: 1.5613\n",
      "     \n",
      "Epoch: 173 of 200 || Train Accuracy: 97.4733 % || Validation Accuracy: 93.4000 % || Test Accuracy: 91.9971 %\n",
      "Train Loss: 1.5242 || Validation Loss: 1.5516 || Test Loss: 1.5612\n",
      "     \n",
      "Epoch: 174 of 200 || Train Accuracy: 97.4733 % || Validation Accuracy: 93.4000 % || Test Accuracy: 91.9604 %\n",
      "Train Loss: 1.5239 || Validation Loss: 1.5515 || Test Loss: 1.5611\n",
      "     \n",
      "Epoch: 175 of 200 || Train Accuracy: 97.5000 % || Validation Accuracy: 93.4000 % || Test Accuracy: 91.9604 %\n",
      "Train Loss: 1.5235 || Validation Loss: 1.5513 || Test Loss: 1.5610\n",
      "     \n",
      "Epoch: 176 of 200 || Train Accuracy: 97.5400 % || Validation Accuracy: 93.4000 % || Test Accuracy: 91.9604 %\n",
      "Train Loss: 1.5232 || Validation Loss: 1.5512 || Test Loss: 1.5609\n",
      "     \n",
      "Epoch: 177 of 200 || Train Accuracy: 97.5533 % || Validation Accuracy: 93.4000 % || Test Accuracy: 91.9604 %\n",
      "Train Loss: 1.5229 || Validation Loss: 1.5511 || Test Loss: 1.5608\n",
      "     \n",
      "Epoch: 178 of 200 || Train Accuracy: 97.5733 % || Validation Accuracy: 93.4000 % || Test Accuracy: 91.9604 %\n",
      "Train Loss: 1.5226 || Validation Loss: 1.5510 || Test Loss: 1.5607\n",
      "     \n",
      "Epoch: 179 of 200 || Train Accuracy: 97.5867 % || Validation Accuracy: 93.4000 % || Test Accuracy: 91.9604 %\n",
      "Train Loss: 1.5223 || Validation Loss: 1.5508 || Test Loss: 1.5606\n",
      "     \n",
      "Epoch: 180 of 200 || Train Accuracy: 97.6133 % || Validation Accuracy: 93.4000 % || Test Accuracy: 91.9236 %\n",
      "Train Loss: 1.5220 || Validation Loss: 1.5507 || Test Loss: 1.5605\n",
      "     \n",
      "Epoch: 181 of 200 || Train Accuracy: 97.6800 % || Validation Accuracy: 93.4000 % || Test Accuracy: 91.8869 %\n",
      "Train Loss: 1.5217 || Validation Loss: 1.5506 || Test Loss: 1.5604\n",
      "     \n",
      "Epoch: 182 of 200 || Train Accuracy: 97.7200 % || Validation Accuracy: 93.4000 % || Test Accuracy: 91.8869 %\n",
      "Train Loss: 1.5214 || Validation Loss: 1.5505 || Test Loss: 1.5603\n",
      "     \n",
      "Epoch: 183 of 200 || Train Accuracy: 97.7333 % || Validation Accuracy: 93.4000 % || Test Accuracy: 91.8869 %\n",
      "Train Loss: 1.5211 || Validation Loss: 1.5503 || Test Loss: 1.5602\n",
      "     \n",
      "Epoch: 184 of 200 || Train Accuracy: 97.7467 % || Validation Accuracy: 93.4000 % || Test Accuracy: 91.8869 %\n",
      "Train Loss: 1.5208 || Validation Loss: 1.5502 || Test Loss: 1.5601\n",
      "     \n",
      "Epoch: 185 of 200 || Train Accuracy: 97.7600 % || Validation Accuracy: 93.4000 % || Test Accuracy: 91.8869 %\n",
      "Train Loss: 1.5205 || Validation Loss: 1.5501 || Test Loss: 1.5600\n",
      "     \n",
      "Epoch: 186 of 200 || Train Accuracy: 97.8000 % || Validation Accuracy: 93.4000 % || Test Accuracy: 91.8869 %\n",
      "Train Loss: 1.5203 || Validation Loss: 1.5500 || Test Loss: 1.5599\n",
      "     \n",
      "Epoch: 187 of 200 || Train Accuracy: 97.8200 % || Validation Accuracy: 93.4000 % || Test Accuracy: 91.8869 %\n",
      "Train Loss: 1.5200 || Validation Loss: 1.5499 || Test Loss: 1.5598\n",
      "     \n",
      "Epoch: 188 of 200 || Train Accuracy: 97.8600 % || Validation Accuracy: 93.4000 % || Test Accuracy: 91.8869 %\n",
      "Train Loss: 1.5197 || Validation Loss: 1.5498 || Test Loss: 1.5597\n",
      "     \n",
      "Epoch: 189 of 200 || Train Accuracy: 97.8667 % || Validation Accuracy: 93.4000 % || Test Accuracy: 91.8869 %\n",
      "Train Loss: 1.5194 || Validation Loss: 1.5497 || Test Loss: 1.5596\n",
      "     \n",
      "Epoch: 190 of 200 || Train Accuracy: 97.8867 % || Validation Accuracy: 93.4000 % || Test Accuracy: 91.8869 %\n",
      "Train Loss: 1.5191 || Validation Loss: 1.5495 || Test Loss: 1.5595\n",
      "     \n",
      "Epoch: 191 of 200 || Train Accuracy: 97.9000 % || Validation Accuracy: 93.4000 % || Test Accuracy: 91.8869 %\n",
      "Train Loss: 1.5188 || Validation Loss: 1.5494 || Test Loss: 1.5594\n",
      "     \n",
      "Epoch: 192 of 200 || Train Accuracy: 97.9400 % || Validation Accuracy: 93.4000 % || Test Accuracy: 91.9236 %\n",
      "Train Loss: 1.5185 || Validation Loss: 1.5493 || Test Loss: 1.5593\n",
      "     \n",
      "Epoch: 193 of 200 || Train Accuracy: 97.9733 % || Validation Accuracy: 93.4000 % || Test Accuracy: 91.9236 %\n",
      "Train Loss: 1.5182 || Validation Loss: 1.5492 || Test Loss: 1.5592\n",
      "     \n",
      "Epoch: 194 of 200 || Train Accuracy: 98.0067 % || Validation Accuracy: 93.4000 % || Test Accuracy: 91.9236 %\n",
      "Train Loss: 1.5180 || Validation Loss: 1.5491 || Test Loss: 1.5591\n",
      "     \n",
      "Epoch: 195 of 200 || Train Accuracy: 98.0067 % || Validation Accuracy: 93.4000 % || Test Accuracy: 91.9236 %\n",
      "Train Loss: 1.5177 || Validation Loss: 1.5490 || Test Loss: 1.5590\n",
      "     \n",
      "Epoch: 196 of 200 || Train Accuracy: 98.0333 % || Validation Accuracy: 93.4000 % || Test Accuracy: 91.9236 %\n",
      "Train Loss: 1.5174 || Validation Loss: 1.5489 || Test Loss: 1.5589\n",
      "     \n",
      "Epoch: 197 of 200 || Train Accuracy: 98.0533 % || Validation Accuracy: 93.4000 % || Test Accuracy: 91.9236 %\n",
      "Train Loss: 1.5171 || Validation Loss: 1.5488 || Test Loss: 1.5588\n",
      "     \n",
      "Epoch: 198 of 200 || Train Accuracy: 98.0800 % || Validation Accuracy: 93.4000 % || Test Accuracy: 91.9236 %\n",
      "Train Loss: 1.5168 || Validation Loss: 1.5487 || Test Loss: 1.5587\n",
      "     \n",
      "Epoch: 199 of 200 || Train Accuracy: 98.1133 % || Validation Accuracy: 93.4000 % || Test Accuracy: 91.9236 %\n",
      "Train Loss: 1.5166 || Validation Loss: 1.5486 || Test Loss: 1.5586\n",
      "     \n",
      "###### TRAINING COMPLETED #######\n",
      "###### TRAINING BEGINNING #######\n",
      "     \n",
      "Epoch: 0 of 200 || Train Accuracy: 9.7000 % || Validation Accuracy: 27.9000 % || Test Accuracy: 26.3216 %\n",
      "Train Loss: 2.3041 || Validation Loss: 2.2296 || Test Loss: 2.2323\n",
      "     \n",
      "Epoch: 1 of 200 || Train Accuracy: 27.1467 % || Validation Accuracy: 56.9000 % || Test Accuracy: 60.5360 %\n",
      "Train Loss: 2.2305 || Validation Loss: 2.0472 || Test Loss: 2.0356\n",
      "     \n",
      "Epoch: 2 of 200 || Train Accuracy: 57.8333 % || Validation Accuracy: 55.3000 % || Test Accuracy: 55.5433 %\n",
      "Train Loss: 2.0421 || Validation Loss: 1.9586 || Test Loss: 1.9507\n",
      "     \n",
      "Epoch: 3 of 200 || Train Accuracy: 53.5000 % || Validation Accuracy: 63.4000 % || Test Accuracy: 64.3172 %\n",
      "Train Loss: 1.9619 || Validation Loss: 1.8768 || Test Loss: 1.8679\n",
      "     \n",
      "Epoch: 4 of 200 || Train Accuracy: 64.1467 % || Validation Accuracy: 61.8000 % || Test Accuracy: 61.3803 %\n",
      "Train Loss: 1.8687 || Validation Loss: 1.8729 || Test Loss: 1.8754\n",
      "     \n",
      "Epoch: 5 of 200 || Train Accuracy: 61.4533 % || Validation Accuracy: 56.3000 % || Test Accuracy: 58.4802 %\n",
      "Train Loss: 1.8730 || Validation Loss: 1.9123 || Test Loss: 1.9061\n",
      "     \n",
      "Epoch: 6 of 200 || Train Accuracy: 57.6267 % || Validation Accuracy: 71.4000 % || Test Accuracy: 72.3201 %\n",
      "Train Loss: 1.9072 || Validation Loss: 1.8049 || Test Loss: 1.7922\n",
      "     \n",
      "Epoch: 7 of 200 || Train Accuracy: 71.8733 % || Validation Accuracy: 74.8000 % || Test Accuracy: 75.0000 %\n",
      "Train Loss: 1.7945 || Validation Loss: 1.7918 || Test Loss: 1.7828\n",
      "     \n",
      "Epoch: 8 of 200 || Train Accuracy: 74.7333 % || Validation Accuracy: 75.5000 % || Test Accuracy: 76.5419 %\n",
      "Train Loss: 1.7899 || Validation Loss: 1.7856 || Test Loss: 1.7777\n",
      "     \n",
      "Epoch: 9 of 200 || Train Accuracy: 75.2133 % || Validation Accuracy: 78.3000 % || Test Accuracy: 77.7166 %\n",
      "Train Loss: 1.7855 || Validation Loss: 1.7702 || Test Loss: 1.7668\n",
      "     \n",
      "Epoch: 10 of 200 || Train Accuracy: 77.8867 % || Validation Accuracy: 85.0000 % || Test Accuracy: 84.9119 %\n",
      "Train Loss: 1.7701 || Validation Loss: 1.7159 || Test Loss: 1.7147\n",
      "     \n",
      "Epoch: 11 of 200 || Train Accuracy: 84.3533 % || Validation Accuracy: 85.2000 % || Test Accuracy: 85.3891 %\n",
      "Train Loss: 1.7144 || Validation Loss: 1.6937 || Test Loss: 1.6947\n",
      "     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 of 200 || Train Accuracy: 85.5867 % || Validation Accuracy: 81.7000 % || Test Accuracy: 81.2775 %\n",
      "Train Loss: 1.6931 || Validation Loss: 1.7163 || Test Loss: 1.7178\n",
      "     \n",
      "Epoch: 13 of 200 || Train Accuracy: 81.9600 % || Validation Accuracy: 83.5000 % || Test Accuracy: 84.0675 %\n",
      "Train Loss: 1.7172 || Validation Loss: 1.6878 || Test Loss: 1.6851\n",
      "     \n",
      "Epoch: 14 of 200 || Train Accuracy: 83.8933 % || Validation Accuracy: 85.6000 % || Test Accuracy: 86.1601 %\n",
      "Train Loss: 1.6863 || Validation Loss: 1.6641 || Test Loss: 1.6569\n",
      "     \n",
      "Epoch: 15 of 200 || Train Accuracy: 85.6400 % || Validation Accuracy: 86.1000 % || Test Accuracy: 87.1145 %\n",
      "Train Loss: 1.6583 || Validation Loss: 1.6456 || Test Loss: 1.6374\n",
      "     \n",
      "Epoch: 16 of 200 || Train Accuracy: 86.5267 % || Validation Accuracy: 87.2000 % || Test Accuracy: 87.5918 %\n",
      "Train Loss: 1.6387 || Validation Loss: 1.6336 || Test Loss: 1.6278\n",
      "     \n",
      "Epoch: 17 of 200 || Train Accuracy: 87.0000 % || Validation Accuracy: 87.6000 % || Test Accuracy: 87.8855 %\n",
      "Train Loss: 1.6294 || Validation Loss: 1.6275 || Test Loss: 1.6258\n",
      "     \n",
      "Epoch: 18 of 200 || Train Accuracy: 87.5133 % || Validation Accuracy: 87.8000 % || Test Accuracy: 87.9222 %\n",
      "Train Loss: 1.6277 || Validation Loss: 1.6242 || Test Loss: 1.6265\n",
      "     \n",
      "Epoch: 19 of 200 || Train Accuracy: 87.4400 % || Validation Accuracy: 88.4000 % || Test Accuracy: 87.7753 %\n",
      "Train Loss: 1.6279 || Validation Loss: 1.6173 || Test Loss: 1.6214\n",
      "     \n",
      "Epoch: 20 of 200 || Train Accuracy: 87.5800 % || Validation Accuracy: 88.3000 % || Test Accuracy: 88.4361 %\n",
      "Train Loss: 1.6221 || Validation Loss: 1.6084 || Test Loss: 1.6110\n",
      "     \n",
      "Epoch: 21 of 200 || Train Accuracy: 88.4000 % || Validation Accuracy: 88.1000 % || Test Accuracy: 88.7298 %\n",
      "Train Loss: 1.6109 || Validation Loss: 1.6044 || Test Loss: 1.6046\n",
      "     \n",
      "Epoch: 22 of 200 || Train Accuracy: 88.8267 % || Validation Accuracy: 88.5000 % || Test Accuracy: 88.5095 %\n",
      "Train Loss: 1.6034 || Validation Loss: 1.6066 || Test Loss: 1.6047\n",
      "     \n",
      "Epoch: 23 of 200 || Train Accuracy: 88.7267 % || Validation Accuracy: 88.3000 % || Test Accuracy: 88.5830 %\n",
      "Train Loss: 1.6035 || Validation Loss: 1.6119 || Test Loss: 1.6087\n",
      "     \n",
      "Epoch: 24 of 200 || Train Accuracy: 88.5067 % || Validation Accuracy: 88.3000 % || Test Accuracy: 88.4728 %\n",
      "Train Loss: 1.6080 || Validation Loss: 1.6141 || Test Loss: 1.6109\n",
      "     \n",
      "Epoch: 25 of 200 || Train Accuracy: 88.3733 % || Validation Accuracy: 88.8000 % || Test Accuracy: 88.5830 %\n",
      "Train Loss: 1.6100 || Validation Loss: 1.6093 || Test Loss: 1.6075\n",
      "     \n",
      "Epoch: 26 of 200 || Train Accuracy: 88.7800 % || Validation Accuracy: 89.2000 % || Test Accuracy: 89.2805 %\n",
      "Train Loss: 1.6057 || Validation Loss: 1.6031 || Test Loss: 1.6030\n",
      "     \n",
      "Epoch: 27 of 200 || Train Accuracy: 89.3467 % || Validation Accuracy: 89.9000 % || Test Accuracy: 89.6843 %\n",
      "Train Loss: 1.6002 || Validation Loss: 1.5995 || Test Loss: 1.6013\n",
      "     \n",
      "Epoch: 28 of 200 || Train Accuracy: 89.8533 % || Validation Accuracy: 90.0000 % || Test Accuracy: 89.9780 %\n",
      "Train Loss: 1.5980 || Validation Loss: 1.5998 || Test Loss: 1.6033\n",
      "     \n",
      "Epoch: 29 of 200 || Train Accuracy: 90.0533 % || Validation Accuracy: 90.0000 % || Test Accuracy: 89.7577 %\n",
      "Train Loss: 1.5999 || Validation Loss: 1.6021 || Test Loss: 1.6065\n",
      "     \n",
      "Epoch: 30 of 200 || Train Accuracy: 90.1333 % || Validation Accuracy: 89.7000 % || Test Accuracy: 90.0147 %\n",
      "Train Loss: 1.6031 || Validation Loss: 1.6028 || Test Loss: 1.6071\n",
      "     \n",
      "Epoch: 31 of 200 || Train Accuracy: 90.2200 % || Validation Accuracy: 89.9000 % || Test Accuracy: 89.9780 %\n",
      "Train Loss: 1.6035 || Validation Loss: 1.6019 || Test Loss: 1.6054\n",
      "     \n",
      "Epoch: 32 of 200 || Train Accuracy: 90.2600 % || Validation Accuracy: 89.9000 % || Test Accuracy: 90.0881 %\n",
      "Train Loss: 1.6013 || Validation Loss: 1.6012 || Test Loss: 1.6037\n",
      "     \n",
      "Epoch: 33 of 200 || Train Accuracy: 90.4333 % || Validation Accuracy: 90.5000 % || Test Accuracy: 89.8678 %\n",
      "Train Loss: 1.5992 || Validation Loss: 1.6009 || Test Loss: 1.6025\n",
      "     \n",
      "Epoch: 34 of 200 || Train Accuracy: 90.5267 % || Validation Accuracy: 90.5000 % || Test Accuracy: 90.2349 %\n",
      "Train Loss: 1.5978 || Validation Loss: 1.6009 || Test Loss: 1.6019\n",
      "     \n",
      "Epoch: 35 of 200 || Train Accuracy: 90.6867 % || Validation Accuracy: 90.5000 % || Test Accuracy: 90.3084 %\n",
      "Train Loss: 1.5970 || Validation Loss: 1.6003 || Test Loss: 1.6014\n",
      "     \n",
      "Epoch: 36 of 200 || Train Accuracy: 90.8467 % || Validation Accuracy: 90.3000 % || Test Accuracy: 90.1615 %\n",
      "Train Loss: 1.5963 || Validation Loss: 1.5982 || Test Loss: 1.6000\n",
      "     \n",
      "Epoch: 37 of 200 || Train Accuracy: 90.8800 % || Validation Accuracy: 90.2000 % || Test Accuracy: 90.1615 %\n",
      "Train Loss: 1.5944 || Validation Loss: 1.5951 || Test Loss: 1.5980\n",
      "     \n",
      "Epoch: 38 of 200 || Train Accuracy: 90.9333 % || Validation Accuracy: 90.2000 % || Test Accuracy: 89.9413 %\n",
      "Train Loss: 1.5917 || Validation Loss: 1.5920 || Test Loss: 1.5960\n",
      "     \n",
      "Epoch: 39 of 200 || Train Accuracy: 91.0267 % || Validation Accuracy: 90.5000 % || Test Accuracy: 90.1248 %\n",
      "Train Loss: 1.5891 || Validation Loss: 1.5891 || Test Loss: 1.5940\n",
      "     \n",
      "Epoch: 40 of 200 || Train Accuracy: 91.2667 % || Validation Accuracy: 91.1000 % || Test Accuracy: 90.1248 %\n",
      "Train Loss: 1.5867 || Validation Loss: 1.5866 || Test Loss: 1.5921\n",
      "     \n",
      "Epoch: 41 of 200 || Train Accuracy: 91.4467 % || Validation Accuracy: 91.3000 % || Test Accuracy: 90.3818 %\n",
      "Train Loss: 1.5848 || Validation Loss: 1.5849 || Test Loss: 1.5907\n",
      "     \n",
      "Epoch: 42 of 200 || Train Accuracy: 91.5067 % || Validation Accuracy: 91.2000 % || Test Accuracy: 90.5653 %\n",
      "Train Loss: 1.5834 || Validation Loss: 1.5838 || Test Loss: 1.5895\n",
      "     \n",
      "Epoch: 43 of 200 || Train Accuracy: 91.5933 % || Validation Accuracy: 90.9000 % || Test Accuracy: 90.6388 %\n",
      "Train Loss: 1.5823 || Validation Loss: 1.5830 || Test Loss: 1.5884\n",
      "     \n",
      "Epoch: 44 of 200 || Train Accuracy: 91.6400 % || Validation Accuracy: 91.0000 % || Test Accuracy: 90.6021 %\n",
      "Train Loss: 1.5812 || Validation Loss: 1.5823 || Test Loss: 1.5875\n",
      "     \n",
      "Epoch: 45 of 200 || Train Accuracy: 91.6867 % || Validation Accuracy: 91.2000 % || Test Accuracy: 90.5653 %\n",
      "Train Loss: 1.5801 || Validation Loss: 1.5819 || Test Loss: 1.5868\n",
      "     \n",
      "Epoch: 46 of 200 || Train Accuracy: 91.8067 % || Validation Accuracy: 91.1000 % || Test Accuracy: 90.6021 %\n",
      "Train Loss: 1.5791 || Validation Loss: 1.5814 || Test Loss: 1.5862\n",
      "     \n",
      "Epoch: 47 of 200 || Train Accuracy: 91.9000 % || Validation Accuracy: 91.1000 % || Test Accuracy: 90.6388 %\n",
      "Train Loss: 1.5782 || Validation Loss: 1.5810 || Test Loss: 1.5858\n",
      "     \n",
      "Epoch: 48 of 200 || Train Accuracy: 91.9933 % || Validation Accuracy: 91.1000 % || Test Accuracy: 90.6388 %\n",
      "Train Loss: 1.5774 || Validation Loss: 1.5807 || Test Loss: 1.5856\n",
      "     \n",
      "Epoch: 49 of 200 || Train Accuracy: 92.1467 % || Validation Accuracy: 91.2000 % || Test Accuracy: 90.6755 %\n",
      "Train Loss: 1.5769 || Validation Loss: 1.5803 || Test Loss: 1.5854\n",
      "     \n",
      "Epoch: 50 of 200 || Train Accuracy: 92.2333 % || Validation Accuracy: 91.3000 % || Test Accuracy: 90.8223 %\n",
      "Train Loss: 1.5763 || Validation Loss: 1.5798 || Test Loss: 1.5852\n",
      "     \n",
      "Epoch: 51 of 200 || Train Accuracy: 92.2067 % || Validation Accuracy: 91.3000 % || Test Accuracy: 90.9325 %\n",
      "Train Loss: 1.5756 || Validation Loss: 1.5794 || Test Loss: 1.5850\n",
      "     \n",
      "Epoch: 52 of 200 || Train Accuracy: 92.2933 % || Validation Accuracy: 91.3000 % || Test Accuracy: 90.9325 %\n",
      "Train Loss: 1.5750 || Validation Loss: 1.5790 || Test Loss: 1.5848\n",
      "     \n",
      "Epoch: 53 of 200 || Train Accuracy: 92.3467 % || Validation Accuracy: 91.4000 % || Test Accuracy: 90.9692 %\n",
      "Train Loss: 1.5745 || Validation Loss: 1.5786 || Test Loss: 1.5845\n",
      "     \n",
      "Epoch: 54 of 200 || Train Accuracy: 92.4400 % || Validation Accuracy: 91.5000 % || Test Accuracy: 91.0059 %\n",
      "Train Loss: 1.5739 || Validation Loss: 1.5782 || Test Loss: 1.5842\n",
      "     \n",
      "Epoch: 55 of 200 || Train Accuracy: 92.5467 % || Validation Accuracy: 91.5000 % || Test Accuracy: 90.9325 %\n",
      "Train Loss: 1.5734 || Validation Loss: 1.5779 || Test Loss: 1.5839\n",
      "     \n",
      "Epoch: 56 of 200 || Train Accuracy: 92.7000 % || Validation Accuracy: 91.6000 % || Test Accuracy: 90.9692 %\n",
      "Train Loss: 1.5729 || Validation Loss: 1.5776 || Test Loss: 1.5835\n",
      "     \n",
      "Epoch: 57 of 200 || Train Accuracy: 92.7333 % || Validation Accuracy: 91.7000 % || Test Accuracy: 90.9692 %\n",
      "Train Loss: 1.5723 || Validation Loss: 1.5773 || Test Loss: 1.5831\n",
      "     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 58 of 200 || Train Accuracy: 92.8000 % || Validation Accuracy: 91.6000 % || Test Accuracy: 91.0059 %\n",
      "Train Loss: 1.5718 || Validation Loss: 1.5769 || Test Loss: 1.5827\n",
      "     \n",
      "Epoch: 59 of 200 || Train Accuracy: 92.8333 % || Validation Accuracy: 91.6000 % || Test Accuracy: 90.9692 %\n",
      "Train Loss: 1.5713 || Validation Loss: 1.5765 || Test Loss: 1.5824\n",
      "     \n",
      "Epoch: 60 of 200 || Train Accuracy: 92.8533 % || Validation Accuracy: 91.6000 % || Test Accuracy: 90.9692 %\n",
      "Train Loss: 1.5707 || Validation Loss: 1.5760 || Test Loss: 1.5820\n",
      "     \n",
      "Epoch: 61 of 200 || Train Accuracy: 92.9267 % || Validation Accuracy: 91.7000 % || Test Accuracy: 90.8590 %\n",
      "Train Loss: 1.5700 || Validation Loss: 1.5754 || Test Loss: 1.5816\n",
      "     \n",
      "Epoch: 62 of 200 || Train Accuracy: 93.0333 % || Validation Accuracy: 91.7000 % || Test Accuracy: 90.9692 %\n",
      "Train Loss: 1.5693 || Validation Loss: 1.5749 || Test Loss: 1.5813\n",
      "     \n",
      "Epoch: 63 of 200 || Train Accuracy: 93.0800 % || Validation Accuracy: 91.7000 % || Test Accuracy: 91.0426 %\n",
      "Train Loss: 1.5686 || Validation Loss: 1.5744 || Test Loss: 1.5809\n",
      "     \n",
      "Epoch: 64 of 200 || Train Accuracy: 93.1467 % || Validation Accuracy: 91.8000 % || Test Accuracy: 91.0793 %\n",
      "Train Loss: 1.5679 || Validation Loss: 1.5741 || Test Loss: 1.5805\n",
      "     \n",
      "Epoch: 65 of 200 || Train Accuracy: 93.1600 % || Validation Accuracy: 91.7000 % || Test Accuracy: 91.1160 %\n",
      "Train Loss: 1.5673 || Validation Loss: 1.5737 || Test Loss: 1.5801\n",
      "     \n",
      "Epoch: 66 of 200 || Train Accuracy: 93.2067 % || Validation Accuracy: 91.7000 % || Test Accuracy: 91.0793 %\n",
      "Train Loss: 1.5666 || Validation Loss: 1.5734 || Test Loss: 1.5797\n",
      "     \n",
      "Epoch: 67 of 200 || Train Accuracy: 93.2867 % || Validation Accuracy: 91.8000 % || Test Accuracy: 91.0793 %\n",
      "Train Loss: 1.5660 || Validation Loss: 1.5730 || Test Loss: 1.5793\n",
      "     \n",
      "Epoch: 68 of 200 || Train Accuracy: 93.3267 % || Validation Accuracy: 91.9000 % || Test Accuracy: 91.0426 %\n",
      "Train Loss: 1.5655 || Validation Loss: 1.5727 || Test Loss: 1.5790\n",
      "     \n",
      "Epoch: 69 of 200 || Train Accuracy: 93.4000 % || Validation Accuracy: 91.8000 % || Test Accuracy: 91.0793 %\n",
      "Train Loss: 1.5650 || Validation Loss: 1.5722 || Test Loss: 1.5786\n",
      "     \n",
      "Epoch: 70 of 200 || Train Accuracy: 93.4133 % || Validation Accuracy: 91.9000 % || Test Accuracy: 91.0059 %\n",
      "Train Loss: 1.5644 || Validation Loss: 1.5718 || Test Loss: 1.5784\n",
      "     \n",
      "Epoch: 71 of 200 || Train Accuracy: 93.4533 % || Validation Accuracy: 92.0000 % || Test Accuracy: 91.0793 %\n",
      "Train Loss: 1.5639 || Validation Loss: 1.5714 || Test Loss: 1.5781\n",
      "     \n",
      "Epoch: 72 of 200 || Train Accuracy: 93.4800 % || Validation Accuracy: 92.0000 % || Test Accuracy: 91.0793 %\n",
      "Train Loss: 1.5634 || Validation Loss: 1.5711 || Test Loss: 1.5778\n",
      "     \n",
      "Epoch: 73 of 200 || Train Accuracy: 93.5400 % || Validation Accuracy: 92.0000 % || Test Accuracy: 91.0793 %\n",
      "Train Loss: 1.5629 || Validation Loss: 1.5708 || Test Loss: 1.5775\n",
      "     \n",
      "Epoch: 74 of 200 || Train Accuracy: 93.6000 % || Validation Accuracy: 92.1000 % || Test Accuracy: 91.1160 %\n",
      "Train Loss: 1.5624 || Validation Loss: 1.5705 || Test Loss: 1.5773\n",
      "     \n",
      "Epoch: 75 of 200 || Train Accuracy: 93.6267 % || Validation Accuracy: 92.1000 % || Test Accuracy: 91.1894 %\n",
      "Train Loss: 1.5619 || Validation Loss: 1.5703 || Test Loss: 1.5771\n",
      "     \n",
      "Epoch: 76 of 200 || Train Accuracy: 93.6667 % || Validation Accuracy: 92.1000 % || Test Accuracy: 91.2628 %\n",
      "Train Loss: 1.5614 || Validation Loss: 1.5700 || Test Loss: 1.5768\n",
      "     \n",
      "Epoch: 77 of 200 || Train Accuracy: 93.6933 % || Validation Accuracy: 92.1000 % || Test Accuracy: 91.2261 %\n",
      "Train Loss: 1.5609 || Validation Loss: 1.5698 || Test Loss: 1.5766\n",
      "     \n",
      "Epoch: 78 of 200 || Train Accuracy: 93.7533 % || Validation Accuracy: 92.2000 % || Test Accuracy: 91.1527 %\n",
      "Train Loss: 1.5604 || Validation Loss: 1.5696 || Test Loss: 1.5764\n",
      "     \n",
      "Epoch: 79 of 200 || Train Accuracy: 93.7800 % || Validation Accuracy: 92.2000 % || Test Accuracy: 91.1527 %\n",
      "Train Loss: 1.5600 || Validation Loss: 1.5693 || Test Loss: 1.5762\n",
      "     \n",
      "Epoch: 80 of 200 || Train Accuracy: 93.8133 % || Validation Accuracy: 92.2000 % || Test Accuracy: 91.1527 %\n",
      "Train Loss: 1.5595 || Validation Loss: 1.5691 || Test Loss: 1.5760\n",
      "     \n",
      "Epoch: 81 of 200 || Train Accuracy: 93.8467 % || Validation Accuracy: 92.2000 % || Test Accuracy: 91.1527 %\n",
      "Train Loss: 1.5591 || Validation Loss: 1.5688 || Test Loss: 1.5758\n",
      "     \n",
      "Epoch: 82 of 200 || Train Accuracy: 93.8867 % || Validation Accuracy: 92.2000 % || Test Accuracy: 91.1160 %\n",
      "Train Loss: 1.5587 || Validation Loss: 1.5685 || Test Loss: 1.5755\n",
      "     \n",
      "Epoch: 83 of 200 || Train Accuracy: 93.9600 % || Validation Accuracy: 92.2000 % || Test Accuracy: 91.2996 %\n",
      "Train Loss: 1.5582 || Validation Loss: 1.5682 || Test Loss: 1.5753\n",
      "     \n",
      "Epoch: 84 of 200 || Train Accuracy: 94.0067 % || Validation Accuracy: 92.2000 % || Test Accuracy: 91.2996 %\n",
      "Train Loss: 1.5577 || Validation Loss: 1.5679 || Test Loss: 1.5750\n",
      "     \n",
      "Epoch: 85 of 200 || Train Accuracy: 94.0533 % || Validation Accuracy: 92.3000 % || Test Accuracy: 91.3363 %\n",
      "Train Loss: 1.5573 || Validation Loss: 1.5676 || Test Loss: 1.5748\n",
      "     \n",
      "Epoch: 86 of 200 || Train Accuracy: 94.1000 % || Validation Accuracy: 92.3000 % || Test Accuracy: 91.2628 %\n",
      "Train Loss: 1.5568 || Validation Loss: 1.5673 || Test Loss: 1.5745\n",
      "     \n",
      "Epoch: 87 of 200 || Train Accuracy: 94.1067 % || Validation Accuracy: 92.3000 % || Test Accuracy: 91.2628 %\n",
      "Train Loss: 1.5563 || Validation Loss: 1.5671 || Test Loss: 1.5743\n",
      "     \n",
      "Epoch: 88 of 200 || Train Accuracy: 94.1667 % || Validation Accuracy: 92.2000 % || Test Accuracy: 91.2261 %\n",
      "Train Loss: 1.5558 || Validation Loss: 1.5668 || Test Loss: 1.5741\n",
      "     \n",
      "Epoch: 89 of 200 || Train Accuracy: 94.2400 % || Validation Accuracy: 92.2000 % || Test Accuracy: 91.2628 %\n",
      "Train Loss: 1.5554 || Validation Loss: 1.5666 || Test Loss: 1.5739\n",
      "     \n",
      "Epoch: 90 of 200 || Train Accuracy: 94.2800 % || Validation Accuracy: 92.2000 % || Test Accuracy: 91.2628 %\n",
      "Train Loss: 1.5549 || Validation Loss: 1.5663 || Test Loss: 1.5737\n",
      "     \n",
      "Epoch: 91 of 200 || Train Accuracy: 94.3067 % || Validation Accuracy: 92.2000 % || Test Accuracy: 91.1894 %\n",
      "Train Loss: 1.5545 || Validation Loss: 1.5661 || Test Loss: 1.5735\n",
      "     \n",
      "Epoch: 92 of 200 || Train Accuracy: 94.3533 % || Validation Accuracy: 92.3000 % || Test Accuracy: 91.1527 %\n",
      "Train Loss: 1.5540 || Validation Loss: 1.5658 || Test Loss: 1.5733\n",
      "     \n",
      "Epoch: 93 of 200 || Train Accuracy: 94.4333 % || Validation Accuracy: 92.3000 % || Test Accuracy: 91.1527 %\n",
      "Train Loss: 1.5536 || Validation Loss: 1.5656 || Test Loss: 1.5731\n",
      "     \n",
      "Epoch: 94 of 200 || Train Accuracy: 94.4667 % || Validation Accuracy: 92.3000 % || Test Accuracy: 91.1527 %\n",
      "Train Loss: 1.5532 || Validation Loss: 1.5654 || Test Loss: 1.5729\n",
      "     \n",
      "Epoch: 95 of 200 || Train Accuracy: 94.5000 % || Validation Accuracy: 92.3000 % || Test Accuracy: 91.1160 %\n",
      "Train Loss: 1.5528 || Validation Loss: 1.5651 || Test Loss: 1.5727\n",
      "     \n",
      "Epoch: 96 of 200 || Train Accuracy: 94.5600 % || Validation Accuracy: 92.5000 % || Test Accuracy: 91.2261 %\n",
      "Train Loss: 1.5523 || Validation Loss: 1.5649 || Test Loss: 1.5725\n",
      "     \n",
      "Epoch: 97 of 200 || Train Accuracy: 94.6267 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.2628 %\n",
      "Train Loss: 1.5519 || Validation Loss: 1.5646 || Test Loss: 1.5723\n",
      "     \n",
      "Epoch: 98 of 200 || Train Accuracy: 94.7200 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.2628 %\n",
      "Train Loss: 1.5514 || Validation Loss: 1.5644 || Test Loss: 1.5721\n",
      "     \n",
      "Epoch: 99 of 200 || Train Accuracy: 94.7867 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.2261 %\n",
      "Train Loss: 1.5510 || Validation Loss: 1.5641 || Test Loss: 1.5719\n",
      "     \n",
      "Epoch: 100 of 200 || Train Accuracy: 94.8267 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.2261 %\n",
      "Train Loss: 1.5506 || Validation Loss: 1.5639 || Test Loss: 1.5717\n",
      "     \n",
      "Epoch: 101 of 200 || Train Accuracy: 94.8800 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.2261 %\n",
      "Train Loss: 1.5502 || Validation Loss: 1.5637 || Test Loss: 1.5716\n",
      "     \n",
      "Epoch: 102 of 200 || Train Accuracy: 94.9333 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.2261 %\n",
      "Train Loss: 1.5498 || Validation Loss: 1.5635 || Test Loss: 1.5714\n",
      "     \n",
      "Epoch: 103 of 200 || Train Accuracy: 94.9733 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.2261 %\n",
      "Train Loss: 1.5493 || Validation Loss: 1.5633 || Test Loss: 1.5712\n",
      "     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 104 of 200 || Train Accuracy: 95.0200 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.2261 %\n",
      "Train Loss: 1.5489 || Validation Loss: 1.5631 || Test Loss: 1.5710\n",
      "     \n",
      "Epoch: 105 of 200 || Train Accuracy: 95.0600 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.2261 %\n",
      "Train Loss: 1.5485 || Validation Loss: 1.5629 || Test Loss: 1.5708\n",
      "     \n",
      "Epoch: 106 of 200 || Train Accuracy: 95.0800 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.2628 %\n",
      "Train Loss: 1.5481 || Validation Loss: 1.5626 || Test Loss: 1.5707\n",
      "     \n",
      "Epoch: 107 of 200 || Train Accuracy: 95.1067 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.2996 %\n",
      "Train Loss: 1.5477 || Validation Loss: 1.5624 || Test Loss: 1.5705\n",
      "     \n",
      "Epoch: 108 of 200 || Train Accuracy: 95.1467 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.2628 %\n",
      "Train Loss: 1.5473 || Validation Loss: 1.5622 || Test Loss: 1.5703\n",
      "     \n",
      "Epoch: 109 of 200 || Train Accuracy: 95.2133 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.2996 %\n",
      "Train Loss: 1.5468 || Validation Loss: 1.5620 || Test Loss: 1.5701\n",
      "     \n",
      "Epoch: 110 of 200 || Train Accuracy: 95.2600 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.2996 %\n",
      "Train Loss: 1.5464 || Validation Loss: 1.5617 || Test Loss: 1.5699\n",
      "     \n",
      "Epoch: 111 of 200 || Train Accuracy: 95.2933 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.2628 %\n",
      "Train Loss: 1.5460 || Validation Loss: 1.5615 || Test Loss: 1.5698\n",
      "     \n",
      "Epoch: 112 of 200 || Train Accuracy: 95.3200 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.2628 %\n",
      "Train Loss: 1.5456 || Validation Loss: 1.5613 || Test Loss: 1.5696\n",
      "     \n",
      "Epoch: 113 of 200 || Train Accuracy: 95.3733 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.2628 %\n",
      "Train Loss: 1.5452 || Validation Loss: 1.5611 || Test Loss: 1.5694\n",
      "     \n",
      "Epoch: 114 of 200 || Train Accuracy: 95.3933 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.2628 %\n",
      "Train Loss: 1.5448 || Validation Loss: 1.5609 || Test Loss: 1.5692\n",
      "     \n",
      "Epoch: 115 of 200 || Train Accuracy: 95.4267 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.2628 %\n",
      "Train Loss: 1.5444 || Validation Loss: 1.5607 || Test Loss: 1.5691\n",
      "     \n",
      "Epoch: 116 of 200 || Train Accuracy: 95.4600 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.2996 %\n",
      "Train Loss: 1.5440 || Validation Loss: 1.5605 || Test Loss: 1.5689\n",
      "     \n",
      "Epoch: 117 of 200 || Train Accuracy: 95.4933 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.2996 %\n",
      "Train Loss: 1.5436 || Validation Loss: 1.5603 || Test Loss: 1.5688\n",
      "     \n",
      "Epoch: 118 of 200 || Train Accuracy: 95.5200 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.3363 %\n",
      "Train Loss: 1.5432 || Validation Loss: 1.5601 || Test Loss: 1.5686\n",
      "     \n",
      "Epoch: 119 of 200 || Train Accuracy: 95.5467 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.3363 %\n",
      "Train Loss: 1.5428 || Validation Loss: 1.5599 || Test Loss: 1.5684\n",
      "     \n",
      "Epoch: 120 of 200 || Train Accuracy: 95.5800 % || Validation Accuracy: 92.6000 % || Test Accuracy: 91.3363 %\n",
      "Train Loss: 1.5424 || Validation Loss: 1.5597 || Test Loss: 1.5683\n",
      "     \n",
      "Epoch: 121 of 200 || Train Accuracy: 95.6067 % || Validation Accuracy: 92.7000 % || Test Accuracy: 91.3363 %\n",
      "Train Loss: 1.5420 || Validation Loss: 1.5595 || Test Loss: 1.5681\n",
      "     \n",
      "Epoch: 122 of 200 || Train Accuracy: 95.6267 % || Validation Accuracy: 92.7000 % || Test Accuracy: 91.3730 %\n",
      "Train Loss: 1.5416 || Validation Loss: 1.5594 || Test Loss: 1.5679\n",
      "     \n",
      "Epoch: 123 of 200 || Train Accuracy: 95.6600 % || Validation Accuracy: 92.8000 % || Test Accuracy: 91.4464 %\n",
      "Train Loss: 1.5412 || Validation Loss: 1.5592 || Test Loss: 1.5678\n",
      "     \n",
      "Epoch: 124 of 200 || Train Accuracy: 95.7000 % || Validation Accuracy: 92.8000 % || Test Accuracy: 91.4464 %\n",
      "Train Loss: 1.5408 || Validation Loss: 1.5590 || Test Loss: 1.5676\n",
      "     \n",
      "Epoch: 125 of 200 || Train Accuracy: 95.7467 % || Validation Accuracy: 92.8000 % || Test Accuracy: 91.4464 %\n",
      "Train Loss: 1.5405 || Validation Loss: 1.5588 || Test Loss: 1.5675\n",
      "     \n",
      "Epoch: 126 of 200 || Train Accuracy: 95.8000 % || Validation Accuracy: 92.8000 % || Test Accuracy: 91.4464 %\n",
      "Train Loss: 1.5401 || Validation Loss: 1.5586 || Test Loss: 1.5673\n",
      "     \n",
      "Epoch: 127 of 200 || Train Accuracy: 95.8533 % || Validation Accuracy: 92.8000 % || Test Accuracy: 91.4464 %\n",
      "Train Loss: 1.5397 || Validation Loss: 1.5584 || Test Loss: 1.5672\n",
      "     \n",
      "Epoch: 128 of 200 || Train Accuracy: 95.8800 % || Validation Accuracy: 92.9000 % || Test Accuracy: 91.4464 %\n",
      "Train Loss: 1.5393 || Validation Loss: 1.5583 || Test Loss: 1.5670\n",
      "     \n",
      "Epoch: 129 of 200 || Train Accuracy: 95.8933 % || Validation Accuracy: 92.9000 % || Test Accuracy: 91.4831 %\n",
      "Train Loss: 1.5389 || Validation Loss: 1.5581 || Test Loss: 1.5669\n",
      "     \n",
      "Epoch: 130 of 200 || Train Accuracy: 95.9200 % || Validation Accuracy: 93.1000 % || Test Accuracy: 91.4831 %\n",
      "Train Loss: 1.5385 || Validation Loss: 1.5579 || Test Loss: 1.5667\n",
      "     \n",
      "Epoch: 131 of 200 || Train Accuracy: 95.9800 % || Validation Accuracy: 93.1000 % || Test Accuracy: 91.5198 %\n",
      "Train Loss: 1.5382 || Validation Loss: 1.5577 || Test Loss: 1.5666\n",
      "     \n",
      "Epoch: 132 of 200 || Train Accuracy: 96.0133 % || Validation Accuracy: 93.1000 % || Test Accuracy: 91.5565 %\n",
      "Train Loss: 1.5378 || Validation Loss: 1.5576 || Test Loss: 1.5664\n",
      "     \n",
      "Epoch: 133 of 200 || Train Accuracy: 96.0467 % || Validation Accuracy: 93.1000 % || Test Accuracy: 91.5565 %\n",
      "Train Loss: 1.5374 || Validation Loss: 1.5574 || Test Loss: 1.5663\n",
      "     \n",
      "Epoch: 134 of 200 || Train Accuracy: 96.0800 % || Validation Accuracy: 93.1000 % || Test Accuracy: 91.5565 %\n",
      "Train Loss: 1.5370 || Validation Loss: 1.5572 || Test Loss: 1.5662\n",
      "     \n",
      "Epoch: 135 of 200 || Train Accuracy: 96.1533 % || Validation Accuracy: 93.1000 % || Test Accuracy: 91.5565 %\n",
      "Train Loss: 1.5367 || Validation Loss: 1.5571 || Test Loss: 1.5660\n",
      "     \n",
      "Epoch: 136 of 200 || Train Accuracy: 96.1667 % || Validation Accuracy: 93.1000 % || Test Accuracy: 91.5565 %\n",
      "Train Loss: 1.5363 || Validation Loss: 1.5569 || Test Loss: 1.5659\n",
      "     \n",
      "Epoch: 137 of 200 || Train Accuracy: 96.2000 % || Validation Accuracy: 93.0000 % || Test Accuracy: 91.5565 %\n",
      "Train Loss: 1.5359 || Validation Loss: 1.5567 || Test Loss: 1.5658\n",
      "     \n",
      "Epoch: 138 of 200 || Train Accuracy: 96.2267 % || Validation Accuracy: 93.0000 % || Test Accuracy: 91.5932 %\n",
      "Train Loss: 1.5356 || Validation Loss: 1.5566 || Test Loss: 1.5656\n",
      "     \n",
      "Epoch: 139 of 200 || Train Accuracy: 96.2667 % || Validation Accuracy: 93.0000 % || Test Accuracy: 91.5932 %\n",
      "Train Loss: 1.5352 || Validation Loss: 1.5564 || Test Loss: 1.5655\n",
      "     \n",
      "Epoch: 140 of 200 || Train Accuracy: 96.3400 % || Validation Accuracy: 93.0000 % || Test Accuracy: 91.5932 %\n",
      "Train Loss: 1.5349 || Validation Loss: 1.5562 || Test Loss: 1.5653\n",
      "     \n",
      "Epoch: 141 of 200 || Train Accuracy: 96.3667 % || Validation Accuracy: 92.9000 % || Test Accuracy: 91.6300 %\n",
      "Train Loss: 1.5345 || Validation Loss: 1.5561 || Test Loss: 1.5652\n",
      "     \n",
      "Epoch: 142 of 200 || Train Accuracy: 96.3800 % || Validation Accuracy: 92.9000 % || Test Accuracy: 91.6667 %\n",
      "Train Loss: 1.5341 || Validation Loss: 1.5559 || Test Loss: 1.5651\n",
      "     \n",
      "Epoch: 143 of 200 || Train Accuracy: 96.4000 % || Validation Accuracy: 92.9000 % || Test Accuracy: 91.6667 %\n",
      "Train Loss: 1.5338 || Validation Loss: 1.5558 || Test Loss: 1.5649\n",
      "     \n",
      "Epoch: 144 of 200 || Train Accuracy: 96.4333 % || Validation Accuracy: 92.9000 % || Test Accuracy: 91.6667 %\n",
      "Train Loss: 1.5334 || Validation Loss: 1.5556 || Test Loss: 1.5648\n",
      "     \n",
      "Epoch: 145 of 200 || Train Accuracy: 96.4600 % || Validation Accuracy: 92.9000 % || Test Accuracy: 91.6667 %\n",
      "Train Loss: 1.5331 || Validation Loss: 1.5555 || Test Loss: 1.5647\n",
      "     \n",
      "Epoch: 146 of 200 || Train Accuracy: 96.4867 % || Validation Accuracy: 93.0000 % || Test Accuracy: 91.6667 %\n",
      "Train Loss: 1.5327 || Validation Loss: 1.5553 || Test Loss: 1.5646\n",
      "     \n",
      "Epoch: 147 of 200 || Train Accuracy: 96.5200 % || Validation Accuracy: 93.0000 % || Test Accuracy: 91.7401 %\n",
      "Train Loss: 1.5324 || Validation Loss: 1.5551 || Test Loss: 1.5644\n",
      "     \n",
      "Epoch: 148 of 200 || Train Accuracy: 96.5400 % || Validation Accuracy: 93.0000 % || Test Accuracy: 91.7401 %\n",
      "Train Loss: 1.5320 || Validation Loss: 1.5550 || Test Loss: 1.5643\n",
      "     \n",
      "Epoch: 149 of 200 || Train Accuracy: 96.6067 % || Validation Accuracy: 93.0000 % || Test Accuracy: 91.7401 %\n",
      "Train Loss: 1.5317 || Validation Loss: 1.5548 || Test Loss: 1.5642\n",
      "     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 150 of 200 || Train Accuracy: 96.6400 % || Validation Accuracy: 93.0000 % || Test Accuracy: 91.7401 %\n",
      "Train Loss: 1.5313 || Validation Loss: 1.5547 || Test Loss: 1.5641\n",
      "     \n",
      "Epoch: 151 of 200 || Train Accuracy: 96.6600 % || Validation Accuracy: 93.0000 % || Test Accuracy: 91.7401 %\n",
      "Train Loss: 1.5310 || Validation Loss: 1.5545 || Test Loss: 1.5639\n",
      "     \n",
      "Epoch: 152 of 200 || Train Accuracy: 96.6933 % || Validation Accuracy: 93.0000 % || Test Accuracy: 91.7401 %\n",
      "Train Loss: 1.5306 || Validation Loss: 1.5544 || Test Loss: 1.5638\n",
      "     \n",
      "Epoch: 153 of 200 || Train Accuracy: 96.7200 % || Validation Accuracy: 93.0000 % || Test Accuracy: 91.7401 %\n",
      "Train Loss: 1.5303 || Validation Loss: 1.5542 || Test Loss: 1.5637\n",
      "     \n",
      "Epoch: 154 of 200 || Train Accuracy: 96.7467 % || Validation Accuracy: 93.0000 % || Test Accuracy: 91.7401 %\n",
      "Train Loss: 1.5300 || Validation Loss: 1.5541 || Test Loss: 1.5636\n",
      "     \n",
      "Epoch: 155 of 200 || Train Accuracy: 96.7600 % || Validation Accuracy: 93.0000 % || Test Accuracy: 91.7768 %\n",
      "Train Loss: 1.5296 || Validation Loss: 1.5539 || Test Loss: 1.5635\n",
      "     \n",
      "Epoch: 156 of 200 || Train Accuracy: 96.8067 % || Validation Accuracy: 93.0000 % || Test Accuracy: 91.7768 %\n",
      "Train Loss: 1.5293 || Validation Loss: 1.5538 || Test Loss: 1.5633\n",
      "     \n",
      "Epoch: 157 of 200 || Train Accuracy: 96.8667 % || Validation Accuracy: 93.1000 % || Test Accuracy: 91.8502 %\n",
      "Train Loss: 1.5290 || Validation Loss: 1.5536 || Test Loss: 1.5632\n",
      "     \n",
      "Epoch: 158 of 200 || Train Accuracy: 96.9133 % || Validation Accuracy: 93.1000 % || Test Accuracy: 91.8502 %\n",
      "Train Loss: 1.5286 || Validation Loss: 1.5535 || Test Loss: 1.5631\n",
      "     \n",
      "Epoch: 159 of 200 || Train Accuracy: 96.9333 % || Validation Accuracy: 93.1000 % || Test Accuracy: 91.8502 %\n",
      "Train Loss: 1.5283 || Validation Loss: 1.5533 || Test Loss: 1.5630\n",
      "     \n",
      "Epoch: 160 of 200 || Train Accuracy: 96.9667 % || Validation Accuracy: 93.2000 % || Test Accuracy: 91.8502 %\n",
      "Train Loss: 1.5280 || Validation Loss: 1.5532 || Test Loss: 1.5629\n",
      "     \n",
      "Epoch: 161 of 200 || Train Accuracy: 97.0267 % || Validation Accuracy: 93.2000 % || Test Accuracy: 91.8502 %\n",
      "Train Loss: 1.5276 || Validation Loss: 1.5531 || Test Loss: 1.5628\n",
      "     \n",
      "Epoch: 162 of 200 || Train Accuracy: 97.0600 % || Validation Accuracy: 93.2000 % || Test Accuracy: 91.8502 %\n",
      "Train Loss: 1.5273 || Validation Loss: 1.5529 || Test Loss: 1.5626\n",
      "     \n",
      "Epoch: 163 of 200 || Train Accuracy: 97.0733 % || Validation Accuracy: 93.2000 % || Test Accuracy: 91.8502 %\n",
      "Train Loss: 1.5270 || Validation Loss: 1.5528 || Test Loss: 1.5625\n",
      "     \n",
      "Epoch: 164 of 200 || Train Accuracy: 97.1200 % || Validation Accuracy: 93.2000 % || Test Accuracy: 91.8502 %\n",
      "Train Loss: 1.5266 || Validation Loss: 1.5526 || Test Loss: 1.5624\n",
      "     \n",
      "Epoch: 165 of 200 || Train Accuracy: 97.1667 % || Validation Accuracy: 93.2000 % || Test Accuracy: 91.8502 %\n",
      "Train Loss: 1.5263 || Validation Loss: 1.5525 || Test Loss: 1.5623\n",
      "     \n",
      "Epoch: 166 of 200 || Train Accuracy: 97.2000 % || Validation Accuracy: 93.3000 % || Test Accuracy: 91.8869 %\n",
      "Train Loss: 1.5260 || Validation Loss: 1.5524 || Test Loss: 1.5622\n",
      "     \n",
      "Epoch: 167 of 200 || Train Accuracy: 97.2200 % || Validation Accuracy: 93.3000 % || Test Accuracy: 91.9236 %\n",
      "Train Loss: 1.5257 || Validation Loss: 1.5522 || Test Loss: 1.5621\n",
      "     \n",
      "Epoch: 168 of 200 || Train Accuracy: 97.2467 % || Validation Accuracy: 93.3000 % || Test Accuracy: 91.9971 %\n",
      "Train Loss: 1.5254 || Validation Loss: 1.5521 || Test Loss: 1.5620\n",
      "     \n",
      "Epoch: 169 of 200 || Train Accuracy: 97.2600 % || Validation Accuracy: 93.4000 % || Test Accuracy: 91.9971 %\n",
      "Train Loss: 1.5250 || Validation Loss: 1.5520 || Test Loss: 1.5619\n",
      "     \n",
      "Epoch: 170 of 200 || Train Accuracy: 97.2800 % || Validation Accuracy: 93.4000 % || Test Accuracy: 91.9604 %\n",
      "Train Loss: 1.5247 || Validation Loss: 1.5518 || Test Loss: 1.5618\n",
      "     \n",
      "Epoch: 171 of 200 || Train Accuracy: 97.3400 % || Validation Accuracy: 93.4000 % || Test Accuracy: 91.9604 %\n",
      "Train Loss: 1.5244 || Validation Loss: 1.5517 || Test Loss: 1.5617\n",
      "     \n",
      "Epoch: 172 of 200 || Train Accuracy: 97.3933 % || Validation Accuracy: 93.4000 % || Test Accuracy: 91.9236 %\n",
      "Train Loss: 1.5241 || Validation Loss: 1.5516 || Test Loss: 1.5616\n",
      "     \n",
      "Epoch: 173 of 200 || Train Accuracy: 97.4400 % || Validation Accuracy: 93.4000 % || Test Accuracy: 91.9236 %\n",
      "Train Loss: 1.5238 || Validation Loss: 1.5514 || Test Loss: 1.5614\n",
      "     \n",
      "Epoch: 174 of 200 || Train Accuracy: 97.4733 % || Validation Accuracy: 93.4000 % || Test Accuracy: 91.9236 %\n",
      "Train Loss: 1.5235 || Validation Loss: 1.5513 || Test Loss: 1.5613\n",
      "     \n",
      "Epoch: 175 of 200 || Train Accuracy: 97.5333 % || Validation Accuracy: 93.5000 % || Test Accuracy: 91.9236 %\n",
      "Train Loss: 1.5232 || Validation Loss: 1.5512 || Test Loss: 1.5612\n",
      "     \n",
      "Epoch: 176 of 200 || Train Accuracy: 97.5467 % || Validation Accuracy: 93.5000 % || Test Accuracy: 91.9236 %\n",
      "Train Loss: 1.5228 || Validation Loss: 1.5510 || Test Loss: 1.5611\n",
      "     \n",
      "Epoch: 177 of 200 || Train Accuracy: 97.5467 % || Validation Accuracy: 93.6000 % || Test Accuracy: 91.9236 %\n",
      "Train Loss: 1.5225 || Validation Loss: 1.5509 || Test Loss: 1.5610\n",
      "     \n",
      "Epoch: 178 of 200 || Train Accuracy: 97.5533 % || Validation Accuracy: 93.6000 % || Test Accuracy: 91.9236 %\n",
      "Train Loss: 1.5222 || Validation Loss: 1.5508 || Test Loss: 1.5609\n",
      "     \n",
      "Epoch: 179 of 200 || Train Accuracy: 97.5800 % || Validation Accuracy: 93.7000 % || Test Accuracy: 91.9236 %\n",
      "Train Loss: 1.5219 || Validation Loss: 1.5507 || Test Loss: 1.5608\n",
      "     \n",
      "Epoch: 180 of 200 || Train Accuracy: 97.6067 % || Validation Accuracy: 93.7000 % || Test Accuracy: 91.8869 %\n",
      "Train Loss: 1.5216 || Validation Loss: 1.5505 || Test Loss: 1.5607\n",
      "     \n",
      "Epoch: 181 of 200 || Train Accuracy: 97.6400 % || Validation Accuracy: 93.6000 % || Test Accuracy: 91.8869 %\n",
      "Train Loss: 1.5213 || Validation Loss: 1.5504 || Test Loss: 1.5606\n",
      "     \n",
      "Epoch: 182 of 200 || Train Accuracy: 97.6667 % || Validation Accuracy: 93.6000 % || Test Accuracy: 91.8869 %\n",
      "Train Loss: 1.5210 || Validation Loss: 1.5503 || Test Loss: 1.5605\n",
      "     \n",
      "Epoch: 183 of 200 || Train Accuracy: 97.7000 % || Validation Accuracy: 93.6000 % || Test Accuracy: 91.8869 %\n",
      "Train Loss: 1.5207 || Validation Loss: 1.5501 || Test Loss: 1.5604\n",
      "     \n",
      "Epoch: 184 of 200 || Train Accuracy: 97.7200 % || Validation Accuracy: 93.6000 % || Test Accuracy: 91.8869 %\n",
      "Train Loss: 1.5204 || Validation Loss: 1.5500 || Test Loss: 1.5603\n",
      "     \n",
      "Epoch: 185 of 200 || Train Accuracy: 97.7333 % || Validation Accuracy: 93.6000 % || Test Accuracy: 91.8869 %\n",
      "Train Loss: 1.5201 || Validation Loss: 1.5499 || Test Loss: 1.5602\n",
      "     \n",
      "Epoch: 186 of 200 || Train Accuracy: 97.7733 % || Validation Accuracy: 93.6000 % || Test Accuracy: 91.8869 %\n",
      "Train Loss: 1.5198 || Validation Loss: 1.5498 || Test Loss: 1.5601\n",
      "     \n",
      "Epoch: 187 of 200 || Train Accuracy: 97.8067 % || Validation Accuracy: 93.6000 % || Test Accuracy: 91.8869 %\n",
      "Train Loss: 1.5195 || Validation Loss: 1.5496 || Test Loss: 1.5600\n",
      "     \n",
      "Epoch: 188 of 200 || Train Accuracy: 97.8533 % || Validation Accuracy: 93.6000 % || Test Accuracy: 91.9604 %\n",
      "Train Loss: 1.5192 || Validation Loss: 1.5495 || Test Loss: 1.5599\n",
      "     \n",
      "Epoch: 189 of 200 || Train Accuracy: 97.8667 % || Validation Accuracy: 93.6000 % || Test Accuracy: 91.9604 %\n",
      "Train Loss: 1.5189 || Validation Loss: 1.5494 || Test Loss: 1.5598\n",
      "     \n",
      "Epoch: 190 of 200 || Train Accuracy: 97.9067 % || Validation Accuracy: 93.6000 % || Test Accuracy: 91.9604 %\n",
      "Train Loss: 1.5186 || Validation Loss: 1.5493 || Test Loss: 1.5597\n",
      "     \n",
      "Epoch: 191 of 200 || Train Accuracy: 97.9400 % || Validation Accuracy: 93.6000 % || Test Accuracy: 91.9604 %\n",
      "Train Loss: 1.5183 || Validation Loss: 1.5492 || Test Loss: 1.5597\n",
      "     \n",
      "Epoch: 192 of 200 || Train Accuracy: 97.9600 % || Validation Accuracy: 93.6000 % || Test Accuracy: 91.9604 %\n",
      "Train Loss: 1.5180 || Validation Loss: 1.5491 || Test Loss: 1.5596\n",
      "     \n",
      "Epoch: 193 of 200 || Train Accuracy: 97.9800 % || Validation Accuracy: 93.6000 % || Test Accuracy: 91.9604 %\n",
      "Train Loss: 1.5177 || Validation Loss: 1.5489 || Test Loss: 1.5595\n",
      "     \n",
      "Epoch: 194 of 200 || Train Accuracy: 98.0067 % || Validation Accuracy: 93.6000 % || Test Accuracy: 91.9604 %\n",
      "Train Loss: 1.5175 || Validation Loss: 1.5488 || Test Loss: 1.5594\n",
      "     \n",
      "Epoch: 195 of 200 || Train Accuracy: 98.0200 % || Validation Accuracy: 93.6000 % || Test Accuracy: 91.9604 %\n",
      "Train Loss: 1.5172 || Validation Loss: 1.5487 || Test Loss: 1.5593\n",
      "     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 196 of 200 || Train Accuracy: 98.0467 % || Validation Accuracy: 93.6000 % || Test Accuracy: 91.9971 %\n",
      "Train Loss: 1.5169 || Validation Loss: 1.5486 || Test Loss: 1.5592\n",
      "     \n",
      "Epoch: 197 of 200 || Train Accuracy: 98.0800 % || Validation Accuracy: 93.6000 % || Test Accuracy: 91.9971 %\n",
      "Train Loss: 1.5166 || Validation Loss: 1.5485 || Test Loss: 1.5591\n",
      "     \n",
      "Epoch: 198 of 200 || Train Accuracy: 98.0933 % || Validation Accuracy: 93.6000 % || Test Accuracy: 91.9971 %\n",
      "Train Loss: 1.5163 || Validation Loss: 1.5484 || Test Loss: 1.5590\n",
      "     \n",
      "Epoch: 199 of 200 || Train Accuracy: 98.1333 % || Validation Accuracy: 93.6000 % || Test Accuracy: 91.9971 %\n",
      "Train Loss: 1.5160 || Validation Loss: 1.5483 || Test Loss: 1.5589\n",
      "     \n",
      "###### TRAINING COMPLETED #######\n",
      "[1mTraining Time[0m: 69.92189333836238mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:99: UserWarning: Legend does not support [0.09453333333333333, 0.27226666666666666, 0.6228, 0.7146, 0.7530666666666667, 0.7871333333333334, 0.8416, 0.8109333333333333, 0.8506666666666667, 0.8391333333333333, 0.8572, 0.8609333333333333, 0.8604666666666667, 0.8601333333333333, 0.8686, 0.876, 0.8764666666666666, 0.8764666666666666, 0.8801333333333333, 0.881, 0.8816666666666667, 0.8832, 0.888, 0.8892666666666666, 0.8904, 0.8934, 0.8956, 0.899, 0.8991333333333333, 0.8982, 0.8992666666666667, 0.9011333333333333, 0.9023333333333333, 0.9043333333333333, 0.9046, 0.9051333333333333, 0.9063333333333333, 0.9088, 0.9106, 0.9108666666666667, 0.911, 0.9108, 0.9108, 0.9115333333333333, 0.913, 0.915, 0.9161333333333334, 0.9172, 0.9180666666666667, 0.9182666666666667, 0.9186, 0.9191333333333334, 0.9196, 0.921, 0.9213333333333333, 0.9218, 0.9232666666666667, 0.923, 0.9242, 0.9246, 0.9248, 0.9249333333333334, 0.9254666666666667, 0.9264666666666667, 0.9266, 0.9268666666666666, 0.9274, 0.9278, 0.9285333333333333, 0.929, 0.93, 0.9306666666666666, 0.9308666666666666, 0.9313333333333333, 0.9318666666666666, 0.9327333333333333, 0.933, 0.9336666666666666, 0.934, 0.9343333333333333, 0.9347333333333333, 0.9353333333333333, 0.936, 0.9362, 0.9368, 0.937, 0.9376, 0.9380666666666667, 0.9384666666666667, 0.939, 0.9394, 0.9397333333333333, 0.94, 0.9406, 0.941, 0.9413333333333334, 0.9418, 0.9418666666666666, 0.9425333333333333, 0.9429333333333333, 0.9430666666666667, 0.9436666666666667, 0.9437333333333333, 0.9438, 0.9444, 0.9446, 0.9449333333333333, 0.9454666666666667, 0.9457333333333333, 0.9460666666666666, 0.9464666666666667, 0.9466666666666667, 0.9468666666666666, 0.9472, 0.9476, 0.9482, 0.9486666666666667, 0.949, 0.9495333333333333, 0.9500666666666666, 0.9504, 0.9505333333333333, 0.9506, 0.9510666666666666, 0.9512666666666667, 0.9514666666666667, 0.9519333333333333, 0.9524, 0.9528, 0.9528666666666666, 0.9534, 0.9538, 0.9542, 0.9545333333333333, 0.9547333333333333, 0.9550666666666666, 0.9556, 0.9559333333333333, 0.9562666666666667, 0.9566666666666667, 0.9572, 0.9576, 0.9578, 0.9583333333333334, 0.959, 0.9592666666666667, 0.9596666666666667, 0.9597333333333333, 0.9602, 0.9603333333333334, 0.9606, 0.9608, 0.9610666666666666, 0.9613333333333334, 0.9617333333333333, 0.962, 0.9624666666666667, 0.9628666666666666, 0.9632, 0.9637333333333333, 0.9642, 0.9646, 0.965, 0.9651333333333333, 0.9652666666666667, 0.9657333333333333, 0.9660666666666666, 0.9663333333333334, 0.9667333333333333, 0.9668, 0.9671333333333333, 0.9674666666666667, 0.9678, 0.9680666666666666, 0.9684666666666667, 0.9688666666666667, 0.969, 0.9689333333333333, 0.9693333333333334, 0.9694, 0.9696666666666667, 0.9698666666666667, 0.9700666666666666, 0.9702, 0.9705333333333334, 0.9707333333333333, 0.971, 0.9712, 0.9714666666666667, 0.9716666666666667, 0.9717333333333333, 0.9718666666666667, 0.9720666666666666, 0.9722, 0.9724666666666667, 0.9725333333333334, 0.9729333333333333, 0.973, 0.9733333333333334, 0.9738] instances.\n",
      "A proxy artist may be used instead.\n",
      "See: http://matplotlib.org/users/legend_guide.html#creating-artists-specifically-for-adding-to-the-legend-aka-proxy-artists\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:99: UserWarning: Legend does not support [0.266, 0.618, 0.7, 0.757, 0.781, 0.846, 0.804, 0.847, 0.837, 0.861, 0.853, 0.866, 0.858, 0.863, 0.871, 0.876, 0.883, 0.881, 0.88, 0.881, 0.873, 0.883, 0.881, 0.879, 0.897, 0.899, 0.907, 0.896, 0.894, 0.894, 0.899, 0.904, 0.905, 0.903, 0.905, 0.902, 0.905, 0.907, 0.909, 0.909, 0.907, 0.904, 0.905, 0.908, 0.911, 0.912, 0.914, 0.916, 0.915, 0.914, 0.914, 0.915, 0.915, 0.915, 0.916, 0.915, 0.916, 0.916, 0.917, 0.917, 0.919, 0.919, 0.918, 0.916, 0.916, 0.916, 0.916, 0.916, 0.917, 0.917, 0.919, 0.919, 0.918, 0.917, 0.917, 0.916, 0.915, 0.915, 0.915, 0.918, 0.918, 0.918, 0.918, 0.918, 0.918, 0.918, 0.919, 0.919, 0.92, 0.92, 0.921, 0.92, 0.92, 0.92, 0.92, 0.921, 0.921, 0.921, 0.922, 0.922, 0.922, 0.922, 0.922, 0.923, 0.923, 0.923, 0.923, 0.923, 0.923, 0.923, 0.923, 0.923, 0.923, 0.926, 0.926, 0.926, 0.926, 0.926, 0.926, 0.926, 0.926, 0.926, 0.926, 0.926, 0.927, 0.927, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.927, 0.926, 0.925, 0.925, 0.925, 0.926, 0.926, 0.926, 0.926, 0.926, 0.926, 0.926, 0.926, 0.926, 0.926, 0.926, 0.926, 0.926, 0.926, 0.926, 0.926, 0.926, 0.926, 0.926, 0.926, 0.926, 0.926, 0.926, 0.926, 0.926, 0.926, 0.926, 0.926, 0.926, 0.926, 0.926, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.927, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928] instances.\n",
      "A proxy artist may be used instead.\n",
      "See: http://matplotlib.org/users/legend_guide.html#creating-artists-specifically-for-adding-to-the-legend-aka-proxy-artists\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:99: UserWarning: Legend does not support [0.29295154185022027, 0.6292217327459618, 0.7209985315712188, 0.7588105726872246, 0.7889133627019089, 0.8538913362701909, 0.8197503671071953, 0.8590308370044053, 0.841776798825257, 0.8612334801762115, 0.8645374449339207, 0.8641703377386197, 0.8616005873715125, 0.8704111600587372, 0.8821585903083701, 0.8803230543318649, 0.880690161527166, 0.8836270190895742, 0.8839941262848752, 0.8858296622613803, 0.8876651982378855, 0.8906020558002937, 0.8891336270190896, 0.8898678414096917, 0.8883994126284875, 0.8920704845814978, 0.8961086637298091, 0.8961086637298091, 0.8968428781204112, 0.895007342143906, 0.895741556534508, 0.8990455212922174, 0.9008810572687225, 0.8994126284875184, 0.8997797356828194, 0.9008810572687225, 0.9001468428781204, 0.9016152716593245, 0.9030837004405287, 0.9041850220264317, 0.9034508076358296, 0.9030837004405287, 0.9060205580029369, 0.9052863436123348, 0.9060205580029369, 0.9074889867841409, 0.9063876651982379, 0.9060205580029369, 0.907856093979442, 0.908957415565345, 0.908957415565345, 0.908957415565345, 0.908223201174743, 0.9074889867841409, 0.907856093979442, 0.908957415565345, 0.9107929515418502, 0.9111600587371512, 0.9096916299559471, 0.9100587371512482, 0.9093245227606461, 0.9100587371512482, 0.9100587371512482, 0.9096916299559471, 0.9100587371512482, 0.9100587371512482, 0.908957415565345, 0.908957415565345, 0.9093245227606461, 0.9096916299559471, 0.9096916299559471, 0.9096916299559471, 0.9100587371512482, 0.9107929515418502, 0.9104258443465492, 0.9100587371512482, 0.9096916299559471, 0.908957415565345, 0.9093245227606461, 0.9096916299559471, 0.9096916299559471, 0.9096916299559471, 0.9093245227606461, 0.9093245227606461, 0.9096916299559471, 0.9096916299559471, 0.9100587371512482, 0.9104258443465492, 0.9111600587371512, 0.9107929515418502, 0.9111600587371512, 0.9118942731277533, 0.9122613803230544, 0.9122613803230544, 0.9122613803230544, 0.9122613803230544, 0.9122613803230544, 0.9122613803230544, 0.9122613803230544, 0.9122613803230544, 0.9122613803230544, 0.9122613803230544, 0.9122613803230544, 0.9122613803230544, 0.9122613803230544, 0.9129955947136564, 0.9129955947136564, 0.9129955947136564, 0.9129955947136564, 0.9129955947136564, 0.9137298091042585, 0.9140969162995595, 0.9137298091042585, 0.9137298091042585, 0.9137298091042585, 0.9137298091042585, 0.9133627019089574, 0.9133627019089574, 0.9140969162995595, 0.9140969162995595, 0.9140969162995595, 0.9140969162995595, 0.9144640234948604, 0.9144640234948604, 0.9144640234948604, 0.9148311306901615, 0.9148311306901615, 0.9148311306901615, 0.9151982378854625, 0.9148311306901615, 0.9148311306901615, 0.9151982378854625, 0.9148311306901615, 0.9144640234948604, 0.9148311306901615, 0.9148311306901615, 0.9148311306901615, 0.9144640234948604, 0.9144640234948604, 0.9144640234948604, 0.9148311306901615, 0.9151982378854625, 0.9151982378854625, 0.9151982378854625, 0.9151982378854625, 0.9151982378854625, 0.9151982378854625, 0.9144640234948604, 0.9148311306901615, 0.9148311306901615, 0.9144640234948604, 0.9148311306901615, 0.9148311306901615, 0.9148311306901615, 0.9148311306901615, 0.9155653450807636, 0.9155653450807636, 0.9155653450807636, 0.9155653450807636, 0.9155653450807636, 0.9155653450807636, 0.9159324522760646, 0.9155653450807636, 0.9155653450807636, 0.9151982378854625, 0.9151982378854625, 0.9159324522760646, 0.9159324522760646, 0.9159324522760646, 0.9159324522760646, 0.9155653450807636, 0.9155653450807636, 0.9155653450807636, 0.9155653450807636, 0.9155653450807636, 0.9159324522760646, 0.9159324522760646, 0.9159324522760646, 0.9159324522760646, 0.9159324522760646, 0.9155653450807636, 0.9155653450807636, 0.9151982378854625, 0.9151982378854625, 0.9151982378854625, 0.9151982378854625, 0.9151982378854625, 0.9148311306901615, 0.9148311306901615, 0.9148311306901615, 0.9148311306901615, 0.9148311306901615, 0.9148311306901615, 0.9148311306901615, 0.9148311306901615, 0.9148311306901615, 0.9151982378854625, 0.9151982378854625, 0.9151982378854625, 0.9151982378854625] instances.\n",
      "A proxy artist may be used instead.\n",
      "See: http://matplotlib.org/users/legend_guide.html#creating-artists-specifically-for-adding-to-the-legend-aka-proxy-artists\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:110: UserWarning: Legend does not support [0.083, 0.22573333333333334, 0.5456, 0.638, 0.6400666666666667, 0.7404666666666667, 0.7150666666666666, 0.7371333333333333, 0.8176, 0.7811333333333333, 0.8104666666666667, 0.8446666666666667, 0.84, 0.8602666666666666, 0.873, 0.87, 0.8718666666666667, 0.8761333333333333, 0.8779333333333333, 0.8781333333333333, 0.8786666666666667, 0.8825333333333333, 0.8878, 0.8906666666666667, 0.8927333333333334, 0.8957333333333334, 0.8959333333333334, 0.894, 0.8955333333333333, 0.8976, 0.9000666666666667, 0.9039333333333334, 0.9062, 0.9070666666666667, 0.9078, 0.9081333333333333, 0.9097333333333333, 0.9105333333333333, 0.9113333333333333, 0.9116666666666666, 0.9129333333333334, 0.9134666666666666, 0.9144666666666666, 0.9164, 0.918, 0.9188666666666667, 0.9196666666666666, 0.9201333333333334, 0.9209333333333334, 0.9221333333333334, 0.9228, 0.9228666666666666, 0.9235333333333333, 0.9244, 0.9248666666666666, 0.9259333333333334, 0.9264, 0.9268, 0.9273333333333333, 0.9277333333333333, 0.9278666666666666, 0.9282, 0.9288, 0.9296, 0.9299333333333333, 0.9306, 0.9310666666666667, 0.9318, 0.9318, 0.9324666666666667, 0.9332, 0.9336, 0.934, 0.9346666666666666, 0.9352666666666667, 0.9354, 0.9360666666666667, 0.9364666666666667, 0.9368, 0.9372, 0.9376, 0.9379333333333333, 0.9386666666666666, 0.9388666666666666, 0.9396, 0.9404666666666667, 0.941, 0.9416, 0.9423333333333334, 0.9425333333333333, 0.9429333333333333, 0.9434666666666667, 0.944, 0.9444666666666667, 0.9451333333333334, 0.9455333333333333, 0.9458666666666666, 0.9462, 0.9466, 0.9471333333333334, 0.9477333333333333, 0.9482, 0.9486, 0.9491333333333334, 0.9494666666666667, 0.9498666666666666, 0.9503333333333334, 0.9507333333333333, 0.9511333333333334, 0.9517333333333333, 0.9521333333333334, 0.9524666666666667, 0.9526, 0.9531333333333334, 0.9536666666666667, 0.9540666666666666, 0.9545333333333333, 0.9549333333333333, 0.9553333333333334, 0.9557333333333333, 0.9563333333333334, 0.9568, 0.9571333333333333, 0.9575333333333333, 0.9578, 0.9581333333333333, 0.9587333333333333, 0.9588666666666666, 0.9592, 0.9595333333333333, 0.9598666666666666, 0.9603333333333334, 0.9607333333333333, 0.9609333333333333, 0.9613333333333334, 0.9618, 0.9622, 0.9626, 0.9628666666666666, 0.9633333333333334, 0.9635333333333334, 0.9638666666666666, 0.9641333333333333, 0.9642666666666667, 0.9643333333333334, 0.9647333333333333, 0.9652, 0.9653333333333334, 0.9656666666666667, 0.9660666666666666, 0.9664, 0.9668666666666667, 0.9670666666666666, 0.9673333333333334, 0.968, 0.9686666666666667, 0.9692, 0.9694666666666667, 0.9695333333333334, 0.9696, 0.9698, 0.9703333333333334, 0.9708666666666667, 0.9709333333333333, 0.9710666666666666, 0.9712666666666666, 0.9718666666666667, 0.9721333333333333, 0.9726666666666667, 0.9731333333333333, 0.9736, 0.974, 0.9745333333333334, 0.9747333333333333, 0.9747333333333333, 0.975, 0.9754, 0.9755333333333334, 0.9757333333333333, 0.9758666666666667, 0.9761333333333333, 0.9768, 0.9772, 0.9773333333333334, 0.9774666666666667, 0.9776, 0.978, 0.9782, 0.9786, 0.9786666666666667, 0.9788666666666667, 0.979, 0.9794, 0.9797333333333333, 0.9800666666666666, 0.9800666666666666, 0.9803333333333333, 0.9805333333333334, 0.9808, 0.9811333333333333] instances.\n",
      "A proxy artist may be used instead.\n",
      "See: http://matplotlib.org/users/legend_guide.html#creating-artists-specifically-for-adding-to-the-legend-aka-proxy-artists\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:110: UserWarning: Legend does not support [0.237, 0.55, 0.631, 0.636, 0.763, 0.727, 0.74, 0.816, 0.779, 0.813, 0.853, 0.845, 0.867, 0.87, 0.861, 0.868, 0.872, 0.879, 0.881, 0.882, 0.885, 0.89, 0.885, 0.889, 0.889, 0.895, 0.895, 0.889, 0.891, 0.899, 0.905, 0.901, 0.897, 0.899, 0.902, 0.901, 0.903, 0.903, 0.903, 0.904, 0.903, 0.906, 0.908, 0.909, 0.912, 0.909, 0.912, 0.91, 0.91, 0.911, 0.909, 0.909, 0.909, 0.911, 0.91, 0.912, 0.913, 0.912, 0.914, 0.914, 0.916, 0.916, 0.917, 0.918, 0.92, 0.92, 0.92, 0.921, 0.921, 0.92, 0.921, 0.921, 0.921, 0.921, 0.922, 0.922, 0.922, 0.922, 0.922, 0.922, 0.922, 0.922, 0.922, 0.922, 0.922, 0.923, 0.923, 0.923, 0.923, 0.923, 0.923, 0.925, 0.925, 0.925, 0.925, 0.925, 0.926, 0.926, 0.925, 0.926, 0.927, 0.927, 0.927, 0.928, 0.928, 0.928, 0.928, 0.928, 0.927, 0.927, 0.926, 0.926, 0.926, 0.926, 0.926, 0.926, 0.927, 0.927, 0.926, 0.926, 0.926, 0.926, 0.927, 0.927, 0.927, 0.927, 0.928, 0.929, 0.929, 0.929, 0.929, 0.93, 0.93, 0.93, 0.93, 0.93, 0.93, 0.93, 0.93, 0.931, 0.931, 0.931, 0.931, 0.931, 0.931, 0.931, 0.931, 0.931, 0.931, 0.931, 0.931, 0.931, 0.931, 0.931, 0.931, 0.931, 0.931, 0.931, 0.931, 0.931, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.933, 0.934, 0.934, 0.934, 0.934, 0.934, 0.934, 0.934, 0.934, 0.934, 0.934, 0.934, 0.934, 0.934, 0.934, 0.934, 0.934, 0.934, 0.934, 0.934, 0.934, 0.934, 0.934, 0.934, 0.934, 0.934, 0.934, 0.934] instances.\n",
      "A proxy artist may be used instead.\n",
      "See: http://matplotlib.org/users/legend_guide.html#creating-artists-specifically-for-adding-to-the-legend-aka-proxy-artists\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:110: UserWarning: Legend does not support [0.23091042584434654, 0.5704845814977973, 0.6483113069016153, 0.6479441997063142, 0.75, 0.7294419970631424, 0.7544052863436124, 0.816079295154185, 0.7856093979441997, 0.8098384728340675, 0.8491189427312775, 0.8509544787077826, 0.8711453744493393, 0.8759177679882526, 0.867474302496329, 0.8729809104258444, 0.8788546255506607, 0.880690161527166, 0.8777533039647577, 0.8799559471365639, 0.881791483113069, 0.8880323054331865, 0.8898678414096917, 0.8909691629955947, 0.8909691629955947, 0.895741556534508, 0.895741556534508, 0.8979441997063142, 0.8990455212922174, 0.9005139500734214, 0.9001468428781204, 0.9023494860499266, 0.9019823788546255, 0.9034508076358296, 0.9063876651982379, 0.907856093979442, 0.9056534508076358, 0.9063876651982379, 0.906754772393539, 0.9071218795888399, 0.9056534508076358, 0.9056534508076358, 0.9056534508076358, 0.908223201174743, 0.9071218795888399, 0.908223201174743, 0.9085903083700441, 0.9085903083700441, 0.908223201174743, 0.907856093979442, 0.908957415565345, 0.9093245227606461, 0.9100587371512482, 0.9104258443465492, 0.9096916299559471, 0.9107929515418502, 0.9100587371512482, 0.9107929515418502, 0.9107929515418502, 0.9104258443465492, 0.9111600587371512, 0.9104258443465492, 0.9115271659324523, 0.9122613803230544, 0.9118942731277533, 0.9122613803230544, 0.9122613803230544, 0.9126284875183553, 0.9118942731277533, 0.9126284875183553, 0.9122613803230544, 0.9122613803230544, 0.9126284875183553, 0.9133627019089574, 0.9122613803230544, 0.9122613803230544, 0.9122613803230544, 0.9122613803230544, 0.9122613803230544, 0.9129955947136564, 0.9126284875183553, 0.9129955947136564, 0.9129955947136564, 0.9126284875183553, 0.9122613803230544, 0.9126284875183553, 0.9122613803230544, 0.9122613803230544, 0.9122613803230544, 0.9122613803230544, 0.9126284875183553, 0.9133627019089574, 0.9129955947136564, 0.9126284875183553, 0.9126284875183553, 0.9129955947136564, 0.9129955947136564, 0.9129955947136564, 0.9129955947136564, 0.9129955947136564, 0.9126284875183553, 0.9126284875183553, 0.9126284875183553, 0.9122613803230544, 0.9122613803230544, 0.9122613803230544, 0.9126284875183553, 0.9126284875183553, 0.9126284875183553, 0.9126284875183553, 0.9126284875183553, 0.9129955947136564, 0.9129955947136564, 0.9129955947136564, 0.9137298091042585, 0.9137298091042585, 0.9133627019089574, 0.9133627019089574, 0.9144640234948604, 0.9144640234948604, 0.9144640234948604, 0.9144640234948604, 0.9151982378854625, 0.9151982378854625, 0.9151982378854625, 0.9159324522760646, 0.9159324522760646, 0.9159324522760646, 0.9159324522760646, 0.9162995594713657, 0.9162995594713657, 0.9162995594713657, 0.9166666666666666, 0.9166666666666666, 0.9162995594713657, 0.9162995594713657, 0.9170337738619677, 0.9170337738619677, 0.9174008810572687, 0.9174008810572687, 0.9174008810572687, 0.9174008810572687, 0.9177679882525698, 0.9177679882525698, 0.9177679882525698, 0.9181350954478708, 0.9181350954478708, 0.9181350954478708, 0.9181350954478708, 0.9181350954478708, 0.9181350954478708, 0.9181350954478708, 0.9185022026431718, 0.9188693098384728, 0.9188693098384728, 0.9185022026431718, 0.9185022026431718, 0.9185022026431718, 0.9185022026431718, 0.9185022026431718, 0.9188693098384728, 0.9188693098384728, 0.9188693098384728, 0.9188693098384728, 0.9188693098384728, 0.9188693098384728, 0.9188693098384728, 0.9188693098384728, 0.9188693098384728, 0.9196035242290749, 0.919970631424376, 0.919970631424376, 0.919970631424376, 0.919970631424376, 0.9196035242290749, 0.9196035242290749, 0.9196035242290749, 0.9196035242290749, 0.9196035242290749, 0.9196035242290749, 0.9192364170337739, 0.9188693098384728, 0.9188693098384728, 0.9188693098384728, 0.9188693098384728, 0.9188693098384728, 0.9188693098384728, 0.9188693098384728, 0.9188693098384728, 0.9188693098384728, 0.9188693098384728, 0.9188693098384728, 0.9192364170337739, 0.9192364170337739, 0.9192364170337739, 0.9192364170337739, 0.9192364170337739, 0.9192364170337739, 0.9192364170337739, 0.9192364170337739] instances.\n",
      "A proxy artist may be used instead.\n",
      "See: http://matplotlib.org/users/legend_guide.html#creating-artists-specifically-for-adding-to-the-legend-aka-proxy-artists\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:121: UserWarning: Legend does not support [0.097, 0.2714666666666667, 0.5783333333333334, 0.535, 0.6414666666666666, 0.6145333333333334, 0.5762666666666667, 0.7187333333333333, 0.7473333333333333, 0.7521333333333333, 0.7788666666666667, 0.8435333333333334, 0.8558666666666667, 0.8196, 0.8389333333333333, 0.8564, 0.8652666666666666, 0.87, 0.8751333333333333, 0.8744, 0.8758, 0.884, 0.8882666666666666, 0.8872666666666666, 0.8850666666666667, 0.8837333333333334, 0.8878, 0.8934666666666666, 0.8985333333333333, 0.9005333333333333, 0.9013333333333333, 0.9022, 0.9026, 0.9043333333333333, 0.9052666666666667, 0.9068666666666667, 0.9084666666666666, 0.9088, 0.9093333333333333, 0.9102666666666667, 0.9126666666666666, 0.9144666666666666, 0.9150666666666667, 0.9159333333333334, 0.9164, 0.9168666666666667, 0.9180666666666667, 0.919, 0.9199333333333334, 0.9214666666666667, 0.9223333333333333, 0.9220666666666667, 0.9229333333333334, 0.9234666666666667, 0.9244, 0.9254666666666667, 0.927, 0.9273333333333333, 0.928, 0.9283333333333333, 0.9285333333333333, 0.9292666666666667, 0.9303333333333333, 0.9308, 0.9314666666666667, 0.9316, 0.9320666666666667, 0.9328666666666666, 0.9332666666666667, 0.934, 0.9341333333333334, 0.9345333333333333, 0.9348, 0.9354, 0.936, 0.9362666666666667, 0.9366666666666666, 0.9369333333333333, 0.9375333333333333, 0.9378, 0.9381333333333334, 0.9384666666666667, 0.9388666666666666, 0.9396, 0.9400666666666667, 0.9405333333333333, 0.941, 0.9410666666666667, 0.9416666666666667, 0.9424, 0.9428, 0.9430666666666667, 0.9435333333333333, 0.9443333333333334, 0.9446666666666667, 0.945, 0.9456, 0.9462666666666667, 0.9472, 0.9478666666666666, 0.9482666666666667, 0.9488, 0.9493333333333334, 0.9497333333333333, 0.9502, 0.9506, 0.9508, 0.9510666666666666, 0.9514666666666667, 0.9521333333333334, 0.9526, 0.9529333333333333, 0.9532, 0.9537333333333333, 0.9539333333333333, 0.9542666666666667, 0.9546, 0.9549333333333333, 0.9552, 0.9554666666666667, 0.9558, 0.9560666666666666, 0.9562666666666667, 0.9566, 0.957, 0.9574666666666667, 0.958, 0.9585333333333333, 0.9588, 0.9589333333333333, 0.9592, 0.9598, 0.9601333333333333, 0.9604666666666667, 0.9608, 0.9615333333333334, 0.9616666666666667, 0.962, 0.9622666666666667, 0.9626666666666667, 0.9634, 0.9636666666666667, 0.9638, 0.964, 0.9643333333333334, 0.9646, 0.9648666666666667, 0.9652, 0.9654, 0.9660666666666666, 0.9664, 0.9666, 0.9669333333333333, 0.9672, 0.9674666666666667, 0.9676, 0.9680666666666666, 0.9686666666666667, 0.9691333333333333, 0.9693333333333334, 0.9696666666666667, 0.9702666666666667, 0.9706, 0.9707333333333333, 0.9712, 0.9716666666666667, 0.972, 0.9722, 0.9724666666666667, 0.9726, 0.9728, 0.9734, 0.9739333333333333, 0.9744, 0.9747333333333333, 0.9753333333333334, 0.9754666666666667, 0.9754666666666667, 0.9755333333333334, 0.9758, 0.9760666666666666, 0.9764, 0.9766666666666667, 0.977, 0.9772, 0.9773333333333334, 0.9777333333333333, 0.9780666666666666, 0.9785333333333334, 0.9786666666666667, 0.9790666666666666, 0.9794, 0.9796, 0.9798, 0.9800666666666666, 0.9802, 0.9804666666666667, 0.9808, 0.9809333333333333, 0.9813333333333333] instances.\n",
      "A proxy artist may be used instead.\n",
      "See: http://matplotlib.org/users/legend_guide.html#creating-artists-specifically-for-adding-to-the-legend-aka-proxy-artists\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:121: UserWarning: Legend does not support [0.279, 0.569, 0.553, 0.634, 0.618, 0.563, 0.714, 0.748, 0.755, 0.783, 0.85, 0.852, 0.817, 0.835, 0.856, 0.861, 0.872, 0.876, 0.878, 0.884, 0.883, 0.881, 0.885, 0.883, 0.883, 0.888, 0.892, 0.899, 0.9, 0.9, 0.897, 0.899, 0.899, 0.905, 0.905, 0.905, 0.903, 0.902, 0.902, 0.905, 0.911, 0.913, 0.912, 0.909, 0.91, 0.912, 0.911, 0.911, 0.911, 0.912, 0.913, 0.913, 0.913, 0.914, 0.915, 0.915, 0.916, 0.917, 0.916, 0.916, 0.916, 0.917, 0.917, 0.917, 0.918, 0.917, 0.917, 0.918, 0.919, 0.918, 0.919, 0.92, 0.92, 0.92, 0.921, 0.921, 0.921, 0.921, 0.922, 0.922, 0.922, 0.922, 0.922, 0.922, 0.922, 0.923, 0.923, 0.923, 0.922, 0.922, 0.922, 0.922, 0.923, 0.923, 0.923, 0.923, 0.925, 0.926, 0.926, 0.926, 0.926, 0.926, 0.926, 0.926, 0.926, 0.926, 0.926, 0.926, 0.926, 0.926, 0.926, 0.926, 0.926, 0.926, 0.926, 0.926, 0.926, 0.926, 0.926, 0.926, 0.926, 0.927, 0.927, 0.928, 0.928, 0.928, 0.928, 0.928, 0.929, 0.929, 0.931, 0.931, 0.931, 0.931, 0.931, 0.931, 0.931, 0.93, 0.93, 0.93, 0.93, 0.929, 0.929, 0.929, 0.929, 0.929, 0.93, 0.93, 0.93, 0.93, 0.93, 0.93, 0.93, 0.93, 0.93, 0.93, 0.93, 0.931, 0.931, 0.931, 0.932, 0.932, 0.932, 0.932, 0.932, 0.932, 0.933, 0.933, 0.933, 0.934, 0.934, 0.934, 0.934, 0.934, 0.934, 0.935, 0.935, 0.936, 0.936, 0.937, 0.937, 0.936, 0.936, 0.936, 0.936, 0.936, 0.936, 0.936, 0.936, 0.936, 0.936, 0.936, 0.936, 0.936, 0.936, 0.936, 0.936, 0.936, 0.936, 0.936] instances.\n",
      "A proxy artist may be used instead.\n",
      "See: http://matplotlib.org/users/legend_guide.html#creating-artists-specifically-for-adding-to-the-legend-aka-proxy-artists\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:121: UserWarning: Legend does not support [0.263215859030837, 0.605359765051395, 0.5554331864904553, 0.6431718061674009, 0.6138032305433186, 0.5848017621145375, 0.7232011747430249, 0.75, 0.7654185022026432, 0.777165932452276, 0.8491189427312775, 0.8538913362701909, 0.8127753303964758, 0.8406754772393539, 0.8616005873715125, 0.8711453744493393, 0.8759177679882526, 0.8788546255506607, 0.8792217327459618, 0.8777533039647577, 0.8843612334801763, 0.8872980910425844, 0.8850954478707783, 0.8858296622613803, 0.8847283406754772, 0.8858296622613803, 0.8928046989720999, 0.8968428781204112, 0.8997797356828194, 0.8975770925110133, 0.9001468428781204, 0.8997797356828194, 0.9008810572687225, 0.8986784140969163, 0.9023494860499266, 0.9030837004405287, 0.9016152716593245, 0.9016152716593245, 0.8994126284875184, 0.9012481644640234, 0.9012481644640234, 0.9038179148311307, 0.9056534508076358, 0.9063876651982379, 0.9060205580029369, 0.9056534508076358, 0.9060205580029369, 0.9063876651982379, 0.9063876651982379, 0.906754772393539, 0.908223201174743, 0.9093245227606461, 0.9093245227606461, 0.9096916299559471, 0.9100587371512482, 0.9093245227606461, 0.9096916299559471, 0.9096916299559471, 0.9100587371512482, 0.9096916299559471, 0.9096916299559471, 0.9085903083700441, 0.9096916299559471, 0.9104258443465492, 0.9107929515418502, 0.9111600587371512, 0.9107929515418502, 0.9107929515418502, 0.9104258443465492, 0.9107929515418502, 0.9100587371512482, 0.9107929515418502, 0.9107929515418502, 0.9107929515418502, 0.9111600587371512, 0.9118942731277533, 0.9126284875183553, 0.9122613803230544, 0.9115271659324523, 0.9115271659324523, 0.9115271659324523, 0.9115271659324523, 0.9111600587371512, 0.9129955947136564, 0.9129955947136564, 0.9133627019089574, 0.9126284875183553, 0.9126284875183553, 0.9122613803230544, 0.9126284875183553, 0.9126284875183553, 0.9118942731277533, 0.9115271659324523, 0.9115271659324523, 0.9115271659324523, 0.9111600587371512, 0.9122613803230544, 0.9126284875183553, 0.9126284875183553, 0.9122613803230544, 0.9122613803230544, 0.9122613803230544, 0.9122613803230544, 0.9122613803230544, 0.9122613803230544, 0.9122613803230544, 0.9126284875183553, 0.9129955947136564, 0.9126284875183553, 0.9129955947136564, 0.9129955947136564, 0.9126284875183553, 0.9126284875183553, 0.9126284875183553, 0.9126284875183553, 0.9126284875183553, 0.9129955947136564, 0.9129955947136564, 0.9133627019089574, 0.9133627019089574, 0.9133627019089574, 0.9133627019089574, 0.9137298091042585, 0.9144640234948604, 0.9144640234948604, 0.9144640234948604, 0.9144640234948604, 0.9144640234948604, 0.9144640234948604, 0.9148311306901615, 0.9148311306901615, 0.9151982378854625, 0.9155653450807636, 0.9155653450807636, 0.9155653450807636, 0.9155653450807636, 0.9155653450807636, 0.9155653450807636, 0.9159324522760646, 0.9159324522760646, 0.9159324522760646, 0.9162995594713657, 0.9166666666666666, 0.9166666666666666, 0.9166666666666666, 0.9166666666666666, 0.9166666666666666, 0.9174008810572687, 0.9174008810572687, 0.9174008810572687, 0.9174008810572687, 0.9174008810572687, 0.9174008810572687, 0.9174008810572687, 0.9174008810572687, 0.9177679882525698, 0.9177679882525698, 0.9185022026431718, 0.9185022026431718, 0.9185022026431718, 0.9185022026431718, 0.9185022026431718, 0.9185022026431718, 0.9185022026431718, 0.9185022026431718, 0.9185022026431718, 0.9188693098384728, 0.9192364170337739, 0.919970631424376, 0.919970631424376, 0.9196035242290749, 0.9196035242290749, 0.9192364170337739, 0.9192364170337739, 0.9192364170337739, 0.9192364170337739, 0.9192364170337739, 0.9192364170337739, 0.9192364170337739, 0.9192364170337739, 0.9188693098384728, 0.9188693098384728, 0.9188693098384728, 0.9188693098384728, 0.9188693098384728, 0.9188693098384728, 0.9188693098384728, 0.9188693098384728, 0.9196035242290749, 0.9196035242290749, 0.9196035242290749, 0.9196035242290749, 0.9196035242290749, 0.9196035242290749, 0.9196035242290749, 0.9196035242290749, 0.919970631424376, 0.919970631424376, 0.919970631424376, 0.919970631424376] instances.\n",
      "A proxy artist may be used instead.\n",
      "See: http://matplotlib.org/users/legend_guide.html#creating-artists-specifically-for-adding-to-the-legend-aka-proxy-artists\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#1000 hidden units\n",
    "#9 output nodes\n",
    "#in_nodes = len(trainData) + 1\n",
    "#out_nodes = 10\n",
    "\n",
    "import time\n",
    "\n",
    "trainData, validData, testData, trainTarget, validTarget, testTarget = loadData()\n",
    "\n",
    "trainData = trainData.reshape((trainData.shape[0], 784))\n",
    "trainData = np.insert(trainData, 0 ,np.ones(trainData.shape[0]), axis = 1)\n",
    "\n",
    "validData = validData.reshape((-1, 784))\n",
    "validData = np.insert(validData, 0 ,np.ones(validData.shape[0]), axis = 1)\n",
    "testData = testData.reshape((-1, 784))\n",
    "testData = np.insert(testData, 0 ,np.ones(testData.shape[0]), axis = 1)\n",
    "\n",
    "###Convert one hot\n",
    "TrainTarget, ValidTarget, TestTarget = convertOneHot(trainTarget, validTarget, testTarget)\n",
    "\n",
    "Data = (trainData, validData, testData)\n",
    "Target = (TrainTarget, ValidTarget, TestTarget)\n",
    "\n",
    "n_x = trainData.shape[1]\n",
    "\n",
    "#hidden layer units\n",
    "n_y1 = 500 \n",
    "n_y2 = 1500\n",
    "n_y3 = 2500\n",
    "\n",
    "#output layer\n",
    "n_z = 10 \n",
    "\n",
    "#standard deviation and hidden / out layers\n",
    "\n",
    "#500\n",
    "std1 = np.sqrt(2/(n_x + n_y1))\n",
    "std2 = np.sqrt(2/(n_y1 + n_z))\n",
    "\n",
    "w_hid1 = np.random.normal(loc = 0, scale = std1, size = (n_x, n_y1))\n",
    "w_out1 = np.random.normal(loc = 0, scale = std2, size = (n_y1 + 1, n_z))\n",
    "\n",
    "#1500\n",
    "std3 = np.sqrt(2/(n_x + n_y2))\n",
    "std4 = np.sqrt(2/(n_y2 + n_z))\n",
    "\n",
    "w_hid2 = np.random.normal(loc = 0, scale = std3, size = (n_x, n_y2))\n",
    "w_out2 = np.random.normal(loc = 0, scale = std4, size = (n_y2 + 1, n_z))\n",
    "\n",
    "#2500\n",
    "std5 = np.sqrt(2/(n_x + n_y3))\n",
    "std6 = np.sqrt(2/(n_y3 + n_z))\n",
    "\n",
    "w_hid3 = np.random.normal(loc = 0, scale = std5, size = (n_x, n_y3))\n",
    "w_out3 = np.random.normal(loc = 0, scale = std6, size = (n_y3 + 1, n_z))\n",
    "\n",
    "###\n",
    "#parameters\n",
    "num_iterations = 200 #200\n",
    "\n",
    "\n",
    "###\n",
    "\n",
    "#time start\n",
    "time_start = time.time()\n",
    "\n",
    "#train the network\n",
    "#500\n",
    "accuracy_train1, accuracy_valid1, accuracy_test1, dw_out1, dw_hid1, loss_train1, loss_valid1, loss_test1 = network_training(Data, Target,\n",
    "                                                                     w_hid1, w_out1, \n",
    "                                                                     num_iterations, 1e-5, 0.9,  \n",
    "                                                                     1e-5, 1e-5)\n",
    "#1500\n",
    "accuracy_train2, accuracy_valid2, accuracy_test2, dw_out2, dw_hid2, loss_train2, loss_valid2, loss_test2 = network_training(Data, Target,\n",
    "                                                                     w_hid2, w_out2, \n",
    "                                                                     num_iterations, 1e-5, 0.9,  \n",
    "                                                                     1e-5, 1e-5)\n",
    "#2500\n",
    "accuracy_train3, accuracy_valid3, accuracy_test3, dw_out3, dw_hid3, loss_train3, loss_valid3, loss_test3 = network_training(Data, Target,\n",
    "                                                                     w_hid3, w_out3, \n",
    "                                                                     num_iterations, 1e-5, 0.9,  \n",
    "                                                                     1e-5, 1e-5)\n",
    "\n",
    "#time stop\n",
    "time_stop = time.time()\n",
    "\n",
    "#print time it took\n",
    "print(\"Training Time: {}mins\".format((time_stop - time_start) / 60))\n",
    "\n",
    "#plot accuracy\n",
    "###\n",
    "\n",
    "#500\n",
    "plt.figure()\n",
    "plt.subplot(311)\n",
    "plt.plot(accuracy_train1)\n",
    "plt.plot(accuracy_valid1)\n",
    "plt.plot(accuracy_test1)\n",
    "\n",
    "acc_legend = plt.legend([accuracy_train1, accuracy_valid1, accuracy_test1], [\"Train Acc.\", \"Valid Acc.\", \"Test Acc.\"])\n",
    "plt.title(\"Accuracy vs. Iterations (500)\")\n",
    "plt.xlabel(\"Number of Iterations\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "\n",
    "#1500\n",
    "plt.subplot(312)\n",
    "plt.plot(accuracy_train2)\n",
    "plt.plot(accuracy_valid2)\n",
    "plt.plot(accuracy_test2)\n",
    "\n",
    "acc_legend = plt.legend([accuracy_train2, accuracy_valid2, accuracy_test2], [\"Train Acc.\", \"Valid Acc.\", \"Test Acc.\"])\n",
    "plt.title(\"Accuracy vs. Iterations (1500)\")\n",
    "plt.xlabel(\"Number of Iterations\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "\n",
    "#2500\n",
    "plt.subplot(313)\n",
    "plt.plot(accuracy_train3)\n",
    "plt.plot(accuracy_valid3)\n",
    "plt.plot(accuracy_test3)\n",
    "\n",
    "acc_legend = plt.legend([accuracy_train3, accuracy_valid3, accuracy_test3], [\"Train Acc.\", \"Valid Acc.\", \"Test Acc.\"])\n",
    "plt.title(\"Accuracy vs. Iterations (2500)\")\n",
    "plt.xlabel(\"Number of Iterations\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "\n",
    "\n",
    "###\n",
    "plt.show()\n",
    "\n",
    "\n",
    "####### THIS IS THE SAME AS THE CELL PREVIOUS\n",
    "#JUST PLOT THE CURVES WITH THE DIFFERENT HIDDEN NODES NUM\n",
    "#DO THIS FOR 3 TRAININGS OF DIFFERENT NETWORKS WITH DIF NODE NUMS\n",
    "#THEN RUN THE NETWORKS WITH TEST AND VALIDATION CURVES FOR EACH ONE\n",
    "#WILL TAKE A LOT OF TIME, SO TEST WITH CELL ABOVE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f56b4a3a537d340f5e79f2a13c4626bf",
     "grade": true,
     "grade_id": "cell-88bbf03aa902e44e",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "Answer:\n",
    "\n",
    "Validation accuracy after how many epochs training could be terminated early:\n",
    "\n",
    "To prevent overfitting in neural networks, the location where the neural network should stop training can be determined by where the validation loss begins to increase while the training loss continues to decrease. \n",
    "\n",
    "This is around Epoch / Iteration #140 for the 500 hidden layer model. Validation loss seems to stagnate or oscillate around 1.556 while training loss still decreases. This can be determined to be the point of overfitting and a good time for early termination. \n",
    "\n",
    "This stagnation and oscillation doesn't seem to happen with the larger 1500 and 2500 model, though they both experience iterations where there are negligible increases in accuracy and negligible decreases in loss. Before these points occur would be suitable times for early termination to prevent overfitting. \n",
    "\n",
    "#######Results with 500 Hidden Units:#######\n",
    "- Train Accuracy: 97.3800 % \n",
    "- Validation Accuracy: 92.8000 % \n",
    "- Test Accuracy: 91.5198 %\n",
    "- Train Loss: 1.5222 \n",
    "- Validation Loss: 1.5526\n",
    "- Test Loss: 1.5624\n",
    "\n",
    "Output:\n",
    "\n",
    "Epoch: 199 of 200 || Train Accuracy: 97.3800 % || Validation Accuracy: 92.8000 % || Test Accuracy: 91.5198 %\n",
    "Train Loss: 1.5222 || Validation Loss: 1.5526 || Test Loss: 1.5624\n",
    "\n",
    "\n",
    "#######Results with 1500 Hidden Units:#######\n",
    "\n",
    "- Train Accuracy: 98.1133 %\n",
    "- Validation Accuracy: 93.4000 % \n",
    "- Test Accuracy: 91.9236 %\n",
    "- Train Loss: 1.5166\n",
    "- Validation Loss: 1.5486\n",
    "- Test Loss: 1.5586\n",
    "\n",
    "Output:\n",
    "\n",
    "Epoch: 199 of 200 || Train Accuracy: 98.1133 % || Validation Accuracy: 93.4000 % || Test Accuracy: 91.9236 %\n",
    "Train Loss: 1.5166 || Validation Loss: 1.5486 || Test Loss: 1.5586\n",
    "\n",
    "#######Results with 2500 Hidden Units:#######\n",
    "\n",
    "- Train Accuracy: 98.1133 %\n",
    "- Validation Accuracy: 93.6000 % \n",
    "- Test Accuracy: 91.9971 %\n",
    "- Train Loss: 1.5160\n",
    "- Validation Loss: 1.5483\n",
    "- Test Loss: 1.5589\n",
    "\n",
    "Output:\n",
    "\n",
    "Epoch: 199 of 200 || Train Accuracy: 98.1333 % || Validation Accuracy: 93.6000 % || Test Accuracy: 91.9971 %\n",
    "Train Loss: 1.5160 || Validation Loss: 1.5483 || Test Loss: 1.5589\n",
    "\n",
    "Please find the graphs attached to this repository if not being displayed here below.\n",
    "\n",
    "Accuracy vs. Number of Iterations for 500, 1500, 2500 Hidden Nodes:\n",
    "\n",
    "![accuracy_hyperparameters](\"accuracy_hyperparameters.png\")\n",
    "(accuracy_hyperparameters.png)\n",
    "\n",
    "Diagram: https://drive.google.com/open?id=1nrSENLA7Y1jhjoFUDSi5kaCMdPBCeDb-\n",
    "\n",
    "Google Drive for Diagrams: https://drive.google.com/open?id=1hVfllsCnZKxbo9pf_uatfMKBwXMyhV4W\n",
    "\n",
    "\n",
    "To Note: \n",
    "- Error in the graph view in output cell due to legend formatting error, but due to time was not able to fix graph formatting.\n",
    "- Epoch 199 is actually epoch 200; it's just because I forgot to print i+1 when printing the text updates when i is indexed at 0. This does not change the value of any other parameter.\n",
    "\n",
    "Total Training Time: 69.92189333836238 mins"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
